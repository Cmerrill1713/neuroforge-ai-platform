{
  "id": "meta_github_99703433",
  "title": "noise-as-targets",
  "description": "Unsupervised Learning by Predicting Noise",
  "url": "https://github.com/facebookresearch/noise-as-targets",
  "language": "Lua",
  "stars": 90,
  "forks": 11,
  "created_at": "2017-08-08T14:43:12Z",
  "updated_at": "2024-03-25T11:37:29Z",
  "topics": [],
  "readme_content": "# Unsupervised Learning by Predicting Noise\n\nThis is the code used for unsupervised training of convolutional neural networks as described in the ICML 2017 paper Unsupervised Learning by Predicting Noise ([arXiv](https://arxiv.org/abs/1704.05310)).\n\nThe code is composed of two modules, one for unsupervised feature learning, and one for training a supervised classifier on top of them.\n\n## Requirements\n\nThe code is in Lua Torch, and therefore requires a working torch installation.\nIt was tested with a LuaJIT installation obtained using:\n```\ngit clone https://github.com/torch/luajit-rocks.git\ncd luajit-rocks\nmkdir build\ncd build\ncmake .. -DCMAKE_INSTALL_PREFIX=/your/prefix\n```\nwhere `/your/prefix` is the path where you want a local install of LuaJIT and all dependencies.\nIn order to run this code, you will need the following modules:\n```\ntorch\ncutorch\nnn\ncunn\ncudnn\ntorchnet\nimage\n```\nYou can install them using:\n```\n$ /your/prefix/bin/luarocks install [package]\n```\n\n## Compiling the C code\n\nComputing the optimal permutation of targets requires solving an assignment problem.\nWe do so using the Hungarian algorithm, also known as the Kuhn-Munkres algorithm.\nWe provide a C implementation and the corresponding Lua interface (using ffi).\nIn order to use it, please run `$ make` which will compile the C code and create the shared library.\n\n## Getting data\n\nThis code uses an `IndexedDataset` to load data.\nThis is a TorchNet data structure which provides an efficient way to bundle data into a single archive file, associated with an indexed file.\nGiven a copy of ImageNet, you can create the archive using:\n```\n$ ./make-index.sh\n```\nInside this script, please replace the source and destination paths as follows:\n```\nIMAGENET=/data/users/bojanowski/data/imagenet-full-size\nDEST=/data/users/bojanowski/data/imagenet-idx\n```\nWhere `/data/users/bojanowski/data/imagenet-full-size` is where you store your copy of ImageNet images:\n```\n$ ls -1 /data/users/bojanowski/data/imagenet-full-size\nlabels.txt\nsynset_words.txt\ntest\ntrain\nval\n```\nThis will produce indexed archives (roughly 70Gb for training images) in the `${DEST}` folder.\n\n## Running the unsupervised training\n\nUnsupervised training can be launched by running:\n```\n$ ./main.sh\n```\nPlease specify the location of your LuaJIT installation in the script:\n```\nLUAJIT=/data/users/bojanowski/local/bin/luajit\n```\nPlease also provide the path to the data folder where the `imagenet-idx` folder is located:\n```\nDATA=/data/users/bojanowski/data\n```\nFinally, you can specify where you want to save the logs, checkpoints and models using:\n```\nEXP=exp\n```\nDuring training, checkpoints and logs will be saved to the directory specified in `${EXP}`.\nA new directory is created for each new set of parameters.\nThis directory of results contains the following things:\n```\n$ ls -1 exp/unsup-dim-2048-perm-3-lr-1.0e-02\ncheckpoint.bin\ncheckpointModel.bin\nconfig.bin\nlog-20170727-022756.txt\nrcp-0-checkpoint.bin\nrcp-0-checkpointModel.bin\nrcp-1-checkpoint.bin\nrcp-1-checkpointModel.bin\nrcp-2-checkpoint.bin\nrcp-2-checkpointModel.bin\nepoch-00010\nepoch-00020\n```\nWe have implemented rolling checkpoints, where a version of the model and the corresponding codes are saved every epoch, in a rolling fashion.\nThe files `checkpoint.bin` and `checkpointModel.bin` are symbolic links to the latest checkpoint available.\nModels are also saved every other k epochs (set using the `-saveperiod` flag), and can be found in for instance in `epoch-00010'.\n\nA complete list of options can be obtained using:\n```\n$ luajit main.lua -h\n```\n\n## Learning the MLP on the supervised task\n\nOnce the unsupervised training is finished, you can launch the transfer task using:\n```\n$ ./test.sh\n```\nYou need to specify the path to the ImageNet data and the directory in which your model lies.\nThe code should run the supervised training of the MLP in the AlexNet and log the train and val performance along epochs.\nThe output of this code will be saved in a subdirectory of where the model is.\n\nThe full set of parameters for this supervised training can be obtained using:\n```\n$ luajit test.lua -h\n```\n\n## ImageNet classification with a pre-trained model\n\nWe provide a pre-trained model, available for download [here](https://dl.fbaipublicfiles.com/noise-as-targets/model.bin).\nYou can run the transfer task with a pre-trained model by running:\n```\n$ ./test-pretrained.sh\n```\nThis will download the pre-trained model and launch the transfer learning on ImageNet.\n\n## License\n\nThis code is licensed under CC-BY-NC license. See the LICENSE file for more details.\n",
  "source_type": "meta_github_repository",
  "domain": "meta_ai",
  "keywords": [],
  "retrieval_tags": [
    "meta",
    "ai",
    "github",
    "repository",
    "research"
  ]
}