{
  "id": "meta_github_94235039",
  "title": "end-to-end-negotiator",
  "description": "Deal or No Deal? End-to-End Learning for Negotiation Dialogues",
  "url": "https://github.com/facebookresearch/end-to-end-negotiator",
  "language": "Python",
  "stars": 1388,
  "forks": 278,
  "created_at": "2017-06-13T16:41:05Z",
  "updated_at": "2025-09-09T09:09:38Z",
  "topics": [],
  "readme_content": "# Introduction\nThis is a [PyTorch](http://pytorch.org/) implementation of the following research papers:\n * (1) [Hierarchical Text Generation and Planning for Strategic Dialogue](https://arxiv.org/abs/1712.05846)\n * (2) [Deal or No Deal? End-to-End Learning for Negotiation Dialogues](https://arxiv.org/abs/1706.05125)\n\n\nThe code is developed by [Facebook AI Research](http://research.fb.com/category/facebook-ai-research-fair).\n\nThe code trains neural networks to hold negotiations in natural language, and allows reinforcement learning self play and rollout-based planning.\n\n\n# Citation\nIf you want to use this code in your research, please cite:\n```\n@inproceedings{DBLP:conf/icml/YaratsL18,\n  author    = {Denis Yarats and\n               Mike Lewis},\n  title     = {Hierarchical Text Generation and Planning for Strategic Dialogue},\n  booktitle = {Proceedings of the 35th International Conference on Machine Learning,\n               {ICML} 2018, Stockholmsm{\\\"{a}}ssan, Stockholm, Sweden, July\n               10-15, 2018},\n  pages     = {5587--5595},\n  year      = {2018},\n  crossref  = {DBLP:conf/icml/2018},\n  url       = {http://proceedings.mlr.press/v80/yarats18a.html},\n  timestamp = {Fri, 13 Jul 2018 14:58:25 +0200},\n  biburl    = {https://dblp.org/rec/bib/conf/icml/YaratsL18},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n```\n\n\n# Dataset\nWe release our dataset together with the code, you can find it under `data/negotiate`. This dataset consists of 5808 dialogues, based on 2236 unique scenarios. Take a look at ยง2.3 of the paper to learn about data collection.\n\nEach dialogue is converted into two training examples in the dataset, showing the complete conversation from the perspective of each agent. The perspectives differ on their input goals, output choice, and in special tokens marking whether a statement was read or written. See ยง3.1 for the details on data representation.\n```\n# Perspective of Agent 1\n<input> 1 4 4 1 1 2 </input>\n<dialogue> THEM: i would like 4 hats and you can have the rest . <eos> YOU: deal <eos> THEM: <selection> </dialogue>\n<output> item0=1 item1=0 item2=1 item0=0 item1=4 item2=0 </output> \n<partner_input> 1 0 4 2 1 2 </partner_input>\n\n# Perspective of Agent 2\n<input> 1 0 4 2 1 2 </input>\n<dialogue> YOU: i would like 4 hats and you can have the rest . <eos> THEM: deal <eos> YOU: <selection> </dialogue>\n<output> item0=0 item1=4 item2=0 item0=1 item1=0 item2=1 </output>\n<partner_input> 1 4 4 1 1 2 </partner_input>\n```\n\n# Setup\nAll code was developed with Python 3.0 on CentOS Linux 7, and tested on Ubuntu 16.04. In addition, we used PyTorch 1.0.0, CUDA 9.0, and Visdom 0.1.8.4.\n\nWe recommend to use [Anaconda](https://www.continuum.io/why-anaconda). In order to set up a working environment follow the steps below:\n```\n# Install anaconda\nconda create -n py30 python=3 anaconda\n# Activate environment\nsource activate py30\n# Install PyTorch\nconda install pytorch torchvision cuda90 -c pytorch\n# Install Visdom if you want to use visualization\npip install visdom\n```\n\n# Usage\n## Supervised Training\n\n### Action Classifier\nWe use an action classifier to compare performance of various models. The action classifier is described in section 3 of (2). It can be trained by running the following command:\n```\npython train.py \\\n--cuda \\\n--bsz 16 \\\n--clip 2.0 \\\n--decay_every 1 \\\n--decay_rate 5.0 \\\n--domain object_division \\\n--dropout 0.1 \\\n--init_range 0.2 \\\n--lr 0.001 \\\n--max_epoch 7 \\\n--min_lr 1e-05 \\\n--model_type selection_model \\\n--momentum 0.1 \\\n--nembed_ctx 128 \\\n--nembed_word 128 \\\n--nhid_attn 128 \\\n--nhid_ctx 64 \\\n--nhid_lang 128 \\\n--nhid_sel 128 \\\n--nhid_strat 256 \\\n--unk_threshold 20 \\\n--skip_values \\\n--sep_sel \\\n--model_file selection_model.th\n```\n\n### Baseline RNN Model\nThis is the baseline RNN model that we describe in (1):\n```\npython train.py \\\n--cuda \\\n--bsz 16 \\\n--clip 0.5 \\\n--decay_every 1 \\\n--decay_rate 5.0 \\\n--domain object_division \\\n--dropout 0.1 \\\n--model_type rnn_model \\\n--init_range 0.2 \\\n--lr 0.001 \\\n--max_epoch 30 \\\n--min_lr 1e-07 \\\n--momentum 0.1 \\\n--nembed_ctx 64 \\\n--nembed_word 256 \\\n--nhid_attn 64 \\\n--nhid_ctx 64 \\\n--nhid_lang 128 \\\n--nhid_sel 128 \\\n--sel_weight 0.6 \\\n--unk_threshold 20 \\\n--sep_sel \\\n--model_file rnn_model.th\n```\n\n### Hierarchical Latent Model\nIn this section we provide guidelines on how to train the hierarchical latent model from (2). The final model requires two sub-models: the clustering model, which learns compact representations over intents; and the language model, which translates intent representations into language. Please read sections 5 and 6 of (2) for more details.\n\n**Clustering Model**\n```\npython train.py \\\n--cuda \\\n--bsz 16 \\\n--clip 2.0 \\\n--decay_every 1 \\\n--decay_rate 5.0 \\\n--domain object_division \\\n--dropout 0.2 \\\n--init_range 0.3 \\\n--lr 0.001 \\\n--max_epoch 15 \\\n--min_lr 1e-05 \\\n--model_type latent_clustering_model \\\n--momentum 0.1 \\\n--nembed_ctx 64 \\\n--nembed_word 256 \\\n--nhid_ctx 64 \\\n--nhid_lang 256 \\\n--nhid_sel 128 \\\n--nhid_strat 256 \\\n--unk_threshold 20 \\\n--num_clusters 50 \\\n--sep_sel \\\n--skip_values \\\n--nhid_cluster 256 \\\n--selection_model_file selection_model.th \\\n--model_file clustering_model.th\n```\n\n**Language Model**\n```\npython train.py \\\n--cuda \\\n--bsz 16 \\\n--clip 2.0 \\\n--decay_every 1 \\\n--decay_rate 5.0 \\\n--domain object_division \\\n--dropout 0.1 \\\n--init_range 0.2 \\\n--lr 0.001 \\\n--max_epoch 15 \\\n--min_lr 1e-05 \\\n--model_type latent_clustering_language_model \\\n--momentum 0.1 \\\n--nembed_ctx 64 \\\n--nembed_word 256 \\\n--nhid_ctx 64 \\\n--nhid_lang 256 \\\n--nhid_sel 128 \\\n--nhid_strat 256 \\\n--unk_threshold 20 \\\n--num_clusters 50 \\\n--sep_sel \\\n--nhid_cluster 256 \\\n--skip_values \\\n--selection_model_file selection_model.th \\\n--cluster_model_file clustering_model.th \\\n--model_file clustering_language_model.th\n```\n\n**Full Model**\n```\npython train.py \\\n--cuda \\\n--bsz 16 \\\n--clip 2.0 \\\n--decay_every 1 \\\n--decay_rate 5.0 \\\n--domain object_division \\\n--dropout 0.2 \\\n--init_range 0.3 \\\n--lr 0.001 \\\n--max_epoch 10 \\\n--min_lr 1e-05 \\\n--model_type latent_clustering_prediction_model \\\n--momentum 0.2 \\\n--nembed_ctx 64 \\\n--nembed_word 256 \\\n--nhid_ctx 64 \\\n--nhid_lang 256 \\\n--nhid_sel 128 \\\n--nhid_strat 256 \\\n--unk_threshold 20 \\\n--num_clusters 50 \\\n--sep_sel \\\n--selection_model_file selection_model.th \\\n--lang_model_file clustering_language_model.th \\\n--model_file full_model.th\n```\n\n## Selfplay\nIf you want to have two pretrained models to negotiate against each another, use `selfplay.py`. For example, lets have two rnn models to play against each other:\n```\npython selfplay.py \\\n--cuda \\\n--alice_model_file rnn_model.th \\\n--bob_model_file rnn_model.th \\\n--context_file data/negotiate/selfplay.txt  \\\n--temperature 0.5 \\\n--selection_model_file selection_model.th\n```\nThe script will output generated dialogues, as well as some statistics. For example:\n```\n================================================================================\nAlice : book=(count:3 value:1) hat=(count:1 value:5) ball=(count:1 value:2)\nBob   : book=(count:3 value:1) hat=(count:1 value:1) ball=(count:1 value:6)\n--------------------------------------------------------------------------------\nAlice : i would like the hat and the ball . <eos>\nBob   : i need the ball and the hat <eos>\nAlice : i can give you the ball and one book . <eos>\nBob   : i can't make a deal without the ball <eos>\nAlice : okay then i will take the hat and the ball <eos>\nBob   : okay , that's fine . <eos>\nAlice : <selection>\nAlice : book=0 hat=1 ball=1 book=3 hat=0 ball=0\nBob   : book=3 hat=0 ball=0 book=0 hat=1 ball=1\n--------------------------------------------------------------------------------\nAgreement!\nAlice : 7 points\nBob   : 3 points\n--------------------------------------------------------------------------------\ndialog_len=4.47 sent_len=6.93 agree=86.67% advantage=3.14 time=2.069s comb_rew=10.93 alice_rew=6.93 alice_sel=60.00% alice_unique=26 bob_rew=4.00 bob_sel=40.00% bob_unique=25 full_match=0.78 \n--------------------------------------------------------------------------------\ndebug: 3 1 1 5 1 2 item0=0 item1=1 item2=1\ndebug: 3 1 1 1 1 6 item0=3 item1=0 item2=0\n================================================================================\n```\n\n## Reinforcement Learning\nTo fine-tune a pretrained model with RL use the `reinforce.py` script:\n```\npython reinforce.py \\\n--cuda \\\n--alice_model_file rnn_model.th \\\n--bob_model_file rnn_model.th \\\n--output_model_file rnn_rl_model.th \\\n--context_file data/negotiate/selfplay.txt  \\\n--temperature 0.5 \\\n--verbose \\\n--log_file rnn_rl.log \\\n--sv_train_freq 4 \\\n--nepoch 4 \\\n--selection_model_file selection_model.th  \\\n--rl_lr 0.00001 \\\n--rl_clip 0.0001 \\\n--sep_sel\n```\n\n# License\nThis project is licenced under CC-by-NC, see the LICENSE file for details.\n",
  "source_type": "meta_github_repository",
  "domain": "meta_ai",
  "keywords": [],
  "retrieval_tags": [
    "meta",
    "ai",
    "github",
    "repository",
    "research"
  ]
}