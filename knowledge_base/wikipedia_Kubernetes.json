{
  "id": "wikipedia_Kubernetes",
  "title": "Kubernetes",
  "url": "https://en.wikipedia.org/wiki/Kubernetes",
  "content": "Kubernetes (/ˌk(j)uːbərˈnɛtɪs, -ˈneɪtɪs, -ˈneɪtiːz, -ˈnɛtiːz/), also known as K8s is an open-source container orchestration system for automating software deployment, scaling, and management.[3][4] Originally designed by Google, the project is now maintained by a worldwide community of contributors, and the trademark is held by the Cloud Native Computing Foundation.\n\nThe name Kubernetes comes from the Ancient Greek term κυβερνήτης, kubernḗtēs (helmsman, pilot), which is also the origin of the words cybernetics and (through Latin) governor. \"Kubernetes\" is often abbreviated with the numerical contraction \"K8s\", meaning \"the letter K, followed by 8 letters, followed by s\".[5]\n\nKubernetes assembles one or more computers, either virtual machines or bare metal, into a cluster which can run workloads in containers. It works with various container runtimes, such as containerd and CRI-O.[6] Its suitability for running and managing workloads of all sizes and styles has led to its widespread adoption in clouds and data centers. There are multiple distributions of this platform – from independent software vendors (ISVs) as well as hosted-on-cloud offerings from all the major public cloud vendors.[7]\n\nThe software consists of a control plane and nodes on which the actual applications run. It includes tools like kubeadm and kubectl which can be used to interact with its REST-based API.[8]\n\nKubernetes was announced by Google on June 6, 2014.[9] The project was conceived and created by Google employees Joe Beda, Brendan Burns, and Craig McLuckie. Others at Google soon joined to help build the project including Ville Aikas, Dawn Chen, Brian Grant, Tim Hockin, and Daniel Smith.[10][11] Other companies such as Red Hat and CoreOS joined the effort soon after, with notable contributors such as Clayton Coleman and Kelsey Hightower.[9]\n\nThe design and development of Kubernetes was inspired by Google's Borg cluster manager and based on Promise Theory.[12][13] Many of its top contributors had previously worked on Borg;[14][15] they codenamed Kubernetes \"Project 7\" after the Star Trek ex-Borg character Seven of Nine[16] and gave its logo a seven-spoked ship's wheel (designed by Tim Hockin). Unlike Borg, which was written in C++,[14] Kubernetes is written in the Go language.\n\nKubernetes was announced in June, 2014 and version 1.0 was released on July 21, 2015.[17] Google worked with the Linux Foundation to form the Cloud Native Computing Foundation (CNCF)[18] and offered Kubernetes as the seed technology.\n\nGoogle was already offering a managed Kubernetes service, GKE, and Red Hat was supporting Kubernetes as part of OpenShift since the inception of the Kubernetes project in 2014.[19] In 2017, the principal competitors rallied around Kubernetes and announced adding native support for it:\n\nOn March 6, 2018, Kubernetes Project reached ninth place in the list of GitHub projects by the number of commits, and second place in authors and issues, after the Linux kernel.[26]\n\nUntil version 1.18, Kubernetes followed an N-2 support policy, meaning that the three most recent minor versions receive security updates and bug fixes.[27] Starting with version 1.19, Kubernetes follows an N-3 support policy.[28]\n\nKubernetes defines a set of building blocks (\"primitives\") that collectively provide mechanisms that deploy, maintain, and scale applications based on CPU, memory[29] or custom metrics.[30] Kubernetes is loosely coupled and extensible to meet the needs of different workloads. The internal components as well as extensions and containers that run on Kubernetes rely on the Kubernetes API.[31][32]\n\nThe platform exerts its control over compute and storage resources by defining resources as objects, which can then be managed as such.\n\nKubernetes follows the primary/replica architecture. The components of Kubernetes can be divided into those that manage an individual node and those that are part of the control plane.[31][33]\n\nThe Kubernetes master node handles the Kubernetes control plane of the cluster, managing its workload and directing communication across the system. The Kubernetes control plane consists of various components such as TLS encryption, RBAC, and a strong authentication method, network separation, each its own process, that can run both on a single master node or on multiple masters supporting high-availability clusters.[33] The various components of the Kubernetes control plane are as follows.[34]\n\nEtcd[citation needed] is a persistent, lightweight, distributed, key-value data store (originally developed for Container Linux). It reliably stores the configuration data of the cluster, representing the overall state of the cluster at any given point of time. Etcd favors consistency over availability in the event of a network partition (see CAP theorem). The consistency is crucial for correctly scheduling and operating services.\n\nThe API server serves the Kubernetes API using JSON over HTTP, which provides both the internal and external interface to Kubernetes.[31][35] The API server processes, validates REST requests, and updates the state of the API objects in etcd, thereby allowing clients to configure workloads and containers across worker nodes.[36] The API server uses etcd's watch API to monitor the cluster, roll out critical configuration changes, or restore any divergences of the state of the cluster back to the desired state as declared in etcd.\n\nAs an example, a human operator may specify that three instances of a particular \"pod\" (see below) need to be running, and etcd stores this fact. If the Deployment controller finds that only two instances are running (conflicting with the etcd declaration),[37] it schedules the creation of an additional instance of that pod.[33]\n\nThe scheduler is an extensible component that selects the node that an unscheduled pod (the basic unit of workloads to be scheduled) runs on, based on resource availability and other constraints. The scheduler tracks resource allocation on each node to ensure that workload is not scheduled in excess of available resources. For this purpose, the scheduler must know the resource requirements, resource availability, and other user-provided constraints or policy directives such as quality-of-service, affinity/anti-affinity requirements, and data locality. The scheduler's role is to match resource \"supply\" to workload \"demand\".[38]\n\nKubernetes allows running multiple schedulers within a single cluster. As such, scheduler plug-ins may be developed and installed as in-process extensions to the native vanilla scheduler by running it as a separate scheduler, as long as they conform to the Kubernetes scheduling framework.[39] This allows cluster administrators to extend or modify the behavior of the default Kubernetes scheduler according to their needs.\n\nA controller is a reconciliation loop that drives the actual cluster state toward the desired state, communicating with the API server to create, update, and delete the resources it manages (e.g., pods or service endpoints).[40][35]\n\nAn example controller is a ReplicaSet controller, which handles replication and scaling by running a specified number of copies of a pod across the cluster. The controller also handles creating replacement pods if the underlying node fails.[40] Other controllers that are part of the core Kubernetes system include a DaemonSet controller for running exactly one pod on every machine (or some subset of machines), and a Job controller for running pods that run to completion (e.g. as part of a batch job).[41] Labels selectors often form part of the controller's definition that specify the set of pods that a controller manages.[42]\n\nThe controller manager is a single process that manages several core Kubernetes controllers (including the examples described above), is distributed as part of the standard Kubernetes installation and responding to the loss of nodes.[34]\n\nCustom controllers may also be installed in the cluster, further allowing the behavior and API of Kubernetes to be extended when used in conjunction with custom resources (see custom resources, controllers and operators below).\n\nA node, also known as a worker or a minion, is a machine where containers (workloads) are deployed. Every node in the cluster must run a container runtime, as well as the below-mentioned components, for communication with the primary network configuration of these containers.\n\nkubelet is responsible for the running state of each node, ensuring that all containers on the node are healthy. It takes care of starting, stopping, and maintaining application containers organized into pods as directed by the control plane.[31][43] kubelet monitors the state of a pod, and if not in the desired state, the pod re-deploys to the same node. Node status is relayed every few seconds via heartbeat messages to the API server. Once the control plane detects a node failure, a higher-level controller is expected to observe this state change and launch pods on another healthy node.[44]\n\nA container runtime is responsible for the lifecycle of containers, including launching, reconciling and killing of containers. kubelet interacts with container runtimes via the Container Runtime Interface (CRI),[45][46] which decouples the maintenance of core Kubernetes from the actual CRI implementation.\n\nOriginally, kubelet interfaced exclusively with the Docker runtime[47] through a \"dockershim\". However, from November 2020[48] up to April 2022, Kubernetes has deprecated the shim in favor of directly interfacing with the container through containerd, or replacing Docker with a runtime that is compliant with the Container Runtime Interface (CRI).[49][45][50] With the release of v1.24 in May 2022, the \"dockershim\" has been removed entirely.[51]\n\nExamples of popular container runtimes that are compatible with kubelet include containerd (initially supported via Docker) and CRI-O.\n\nkube-proxy is an implementation of a network proxy and a load balanc...",
  "source_type": "wikipedia_article",
  "domain": "general_knowledge",
  "keywords": [
    "wikipedia",
    "ai",
    "programming",
    "technology",
    "kubernetes"
  ],
  "retrieval_tags": [
    "wikipedia",
    "article",
    "ai",
    "programming",
    "knowledge"
  ]
}