{
  "id": "meta_github_96341686",
  "title": "clevr-dataset-gen",
  "description": "A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning",
  "url": "https://github.com/facebookresearch/clevr-dataset-gen",
  "language": "Python",
  "stars": 625,
  "forks": 213,
  "created_at": "2017-07-05T16:54:21Z",
  "updated_at": "2025-09-20T17:12:41Z",
  "topics": [],
  "readme_content": "# CLEVR Dataset Generation\n\nThis is the code used to generate the [CLEVR dataset](http://cs.stanford.edu/people/jcjohns/clevr/) as described in the paper:\n\n**[CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning](http://cs.stanford.edu/people/jcjohns/clevr/)**\n <br>\n <a href='http://cs.stanford.edu/people/jcjohns/'>Justin Johnson</a>,\n <a href='http://home.bharathh.info/'>Bharath Hariharan</a>,\n <a href='https://lvdmaaten.github.io/'>Laurens van der Maaten</a>,\n <a href='http://vision.stanford.edu/feifeili/'>Fei-Fei Li</a>,\n <a href='http://larryzitnick.org/'>Larry Zitnick</a>,\n <a href='http://www.rossgirshick.info/'>Ross Girshick</a>\n <br>\n Presented at [CVPR 2017](http://cvpr2017.thecvf.com/)\n\nCode and pretrained models for the baselines used in the paper [can be found here](https://github.com/facebookresearch/clevr-iep).\n\nYou can use this code to render synthetic images and compositional questions for those images, like this:\n\n<div align=\"center\">\n  <img src=\"images/example1080.png\" width=\"800px\">\n</div>\n\n**Q:** How many small spheres are there? <br>\n**A:** 2\n\n**Q:**  What number of cubes are small things or red metal objects? <br>\n**A:**  2\n\n**Q:** Does the metal sphere have the same color as the metal cylinder? <br>\n**A:** Yes\n\n**Q:** Are there more small cylinders than metal things? <br>\n**A:** No\n\n**Q:**  There is a cylinder that is on the right side of the large yellow object behind the blue ball; is there a shiny cube in front of it? <br>\n**A:**  Yes\n\nIf you find this code useful in your research then please cite\n\n```\n@inproceedings{johnson2017clevr,\n  title={CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning},\n  author={Johnson, Justin and Hariharan, Bharath and van der Maaten, Laurens\n          and Fei-Fei, Li and Zitnick, C Lawrence and Girshick, Ross},\n  booktitle={CVPR},\n  year={2017}\n}\n```\n\nAll code was developed and tested on OSX and Ubuntu 16.04.\n\n## Step 1: Generating Images\nFirst we render synthetic images using [Blender](https://www.blender.org/), outputting both rendered images as well as a JSON file containing ground-truth scene information for each image.\n\nBlender ships with its own installation of Python which is used to execute scripts that interact with Blender; you'll need to add the `image_generation` directory to Python path of Blender's bundled Python. The easiest way to do this is by adding a `.pth` file to the `site-packages` directory of Blender's Python, like this:\n\n```bash\necho $PWD/image_generation >> $BLENDER/$VERSION/python/lib/python3.5/site-packages/clevr.pth\n```\n\nwhere `$BLENDER` is the directory where Blender is installed and `$VERSION` is your Blender version; for example on OSX you might run:\n\n```bash\necho $PWD/image_generation >> /Applications/blender/blender.app/Contents/Resources/2.78/python/lib/python3.5/site-packages/clevr.pth\n```\n\nYou can then render some images like this:\n\n```bash\ncd image_generation\nblender --background --python render_images.py -- --num_images 10\n```\n\nOn OSX the `blender` binary is located inside the blender.app directory; for convenience you may want to\nadd the following alias to your `~/.bash_profile` file:\n\n```bash\nalias blender='/Applications/blender/blender.app/Contents/MacOS/blender'\n```\n\nIf you have an NVIDIA GPU with CUDA installed then you can use the GPU to accelerate rendering like this:\n\n```bash\nblender --background --python render_images.py -- --num_images 10 --use_gpu 1\n```\n\nAfter this command terminates you should have ten freshly rendered images stored in `output/images` like these:\n\n<div align=\"center\">\n  <img src=\"images/img1.png\" width=\"260px\">\n  <img src=\"images/img2.png\" width=\"260px\">\n  <img src=\"images/img3.png\" width=\"260px\">\n  <br>\n  <img src=\"images/img4.png\" width=\"260px\">\n  <img src=\"images/img5.png\" width=\"260px\">\n  <img src=\"images/img6.png\" width=\"260px\">\n</div>\n\nThe file `output/CLEVR_scenes.json` will contain ground-truth scene information for all newly rendered images.\n\nYou can find [more details about image rendering here](image_generation/README.md).\n\n## Step 2: Generating Questions\nNext we generate questions, functional programs, and answers for the rendered images generated in the previous step.\nThis step takes as input the single JSON file containing all ground-truth scene information, and outputs a JSON file \ncontaining questions, answers, and functional programs for the questions in a single JSON file.\n\nYou can generate questions like this:\n\n```bash\ncd question_generation\npython generate_questions.py\n```\n\nThe file `output/CLEVR_questions.json` will then contain questions for the generated images.\n\nYou can [find more details about question generation here](question_generation/README.md).\n",
  "source_type": "meta_github_repository",
  "domain": "meta_ai",
  "keywords": [],
  "retrieval_tags": [
    "meta",
    "ai",
    "github",
    "repository",
    "research"
  ]
}