{
  "id": "meta_github_91736144",
  "title": "SentEval",
  "description": "A python tool for evaluating the quality of sentence embeddings.",
  "url": "https://github.com/facebookresearch/SentEval",
  "language": "Python",
  "stars": 2108,
  "forks": 308,
  "created_at": "2017-05-18T20:44:47Z",
  "updated_at": "2025-08-30T08:47:50Z",
  "topics": [],
  "readme_content": "# SentEval: evaluation toolkit for sentence embeddings\n\nSentEval is a library for evaluating the quality of sentence embeddings. We assess their generalization power by using them as features on a broad and diverse set of \"transfer\" tasks. **SentEval currently includes 17 downstream tasks**. We also include a suite of **10 probing tasks** which evaluate what linguistic properties are encoded in sentence embeddings. Our goal is to ease the study and the development of general-purpose fixed-size sentence representations.\n\n\n**(04/22) SentEval new tasks: Added probing tasks for evaluating what linguistic properties are encoded in sentence embeddings**\n\n**(10/04) SentEval example scripts for three sentence encoders: [SkipThought-LN](https://github.com/ryankiros/layer-norm#skip-thoughts)/[GenSen](https://github.com/Maluuba/gensen)/[Google-USE](https://tfhub.dev/google/universal-sentence-encoder/1)**\n\n## Dependencies\n\nThis code is written in python. The dependencies are:\n\n* Python 2/3 with [NumPy](http://www.numpy.org/)/[SciPy](http://www.scipy.org/)\n* [Pytorch](http://pytorch.org/)>=0.4\n* [scikit-learn](http://scikit-learn.org/stable/index.html)>=0.18.0\n\n## Transfer tasks\n\n### Downstream tasks\nSentEval allows you to evaluate your sentence embeddings as features for the following *downstream* tasks:\n\n| Task     \t| Type                         \t| #train \t| #test \t| needs_train \t| set_classifier |\n|----------\t|------------------------------\t|-----------:|----------:|:-----------:|:----------:|\n| [MR](https://nlp.stanford.edu/~sidaw/home/projects:nbsvm)       \t| movie review                 \t| 11k     \t| 11k    \t| 1 | 1 |\n| [CR](https://nlp.stanford.edu/~sidaw/home/projects:nbsvm)       \t| product review               \t| 4k      \t| 4k     \t| 1 | 1 |\n| [SUBJ](https://nlp.stanford.edu/~sidaw/home/projects:nbsvm)     \t| subjectivity status          \t| 10k     \t| 10k    \t| 1 | 1 |\n| [MPQA](https://nlp.stanford.edu/~sidaw/home/projects:nbsvm)     \t| opinion-polarity  | 11k     \t| 11k    \t| 1 | 1 |\n| [SST](https://nlp.stanford.edu/sentiment/index.html)      \t| binary sentiment analysis  \t| 67k     \t| 1.8k   \t| 1 | 1 |\n| **[SST](https://nlp.stanford.edu/sentiment/index.html)**      \t| **fine-grained sentiment analysis**  \t| 8.5k     \t| 2.2k   \t| 1 | 1 |\n| [TREC](http://cogcomp.cs.illinois.edu/Data/QA/QC/)     \t| question-type classification \t| 6k      \t| 0.5k    \t| 1 | 1 |\n| [SICK-E](http://clic.cimec.unitn.it/composes/sick.html)   \t| natural language inference \t| 4.5k    \t| 4.9k   \t| 1 | 1 |\n| [SNLI](https://nlp.stanford.edu/projects/snli/)     \t| natural language inference   \t| 550k    \t| 9.8k   \t| 1 | 1 |\n| [MRPC](https://aclweb.org/aclwiki/Paraphrase_Identification_(State_of_the_art)) | paraphrase detection  | 4.1k | 1.7k | 1 | 1 |\n| [STS 2012](https://www.cs.york.ac.uk/semeval-2012/task6/) \t| semantic textual similarity  \t| N/A     \t| 3.1k   \t| 0  | 0 |\n| [STS 2013](http://ixa2.si.ehu.es/sts/) \t| semantic textual similarity  \t| N/A     \t| 1.5k   \t| 0  | 0 |\n| [STS 2014](http://alt.qcri.org/semeval2014/task10/) \t| semantic textual similarity  \t| N/A     \t| 3.7k   \t| 0  | 0 |\n| [STS 2015](http://alt.qcri.org/semeval2015/task2/) \t| semantic textual similarity  \t| N/A     \t| 8.5k   \t| 0  | 0 |\n| [STS 2016](http://alt.qcri.org/semeval2016/task1/) \t| semantic textual similarity  \t| N/A     \t| 9.2k   \t| 0  | 0 |\n| [STS B](http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark#Results)    \t| semantic textual similarity  \t| 5.7k    \t| 1.4k   \t| 1 | 0 |\n| [SICK-R](http://clic.cimec.unitn.it/composes/sick.html)   \t| semantic textual similarity | 4.5k    \t| 4.9k   \t| 1 | 0 |\n| [COCO](http://mscoco.org/)     \t| image-caption retrieval      \t| 567k    \t| 5*1k   \t| 1 | 0 |\n\nwhere **needs_train** means a model with parameters is learned on top of the sentence embeddings, and **set_classifier** means you can define the parameters of the classifier in the case of a classification task (see below).\n\nNote: COCO comes with ResNet-101 2048d image embeddings. [More details on the tasks.](https://arxiv.org/pdf/1705.02364.pdf)\n\n### Probing tasks\nSentEval also includes a series of [*probing* tasks](https://github.com/facebookresearch/SentEval/tree/master/data/probing) to evaluate what linguistic properties are encoded in your sentence embeddings:\n\n| Task     \t| Type                         \t| #train \t| #test \t| needs_train \t| set_classifier |\n|----------\t|------------------------------\t|-----------:|----------:|:-----------:|:----------:|\n| [SentLen](https://github.com/facebookresearch/SentEval/tree/master/data/probing)\t| Length prediction\t| 100k     \t| 10k    \t| 1 | 1 |\n| [WC](https://github.com/facebookresearch/SentEval/tree/master/data/probing)\t| Word Content analysis\t| 100k     \t| 10k    \t| 1 | 1 |\n| [TreeDepth](https://github.com/facebookresearch/SentEval/tree/master/data/probing)\t| Tree depth prediction\t| 100k     \t| 10k    \t| 1 | 1 |\n| [TopConst](https://github.com/facebookresearch/SentEval/tree/master/data/probing)\t| Top Constituents prediction\t| 100k     \t| 10k    \t| 1 | 1 |\n| [BShift](https://github.com/facebookresearch/SentEval/tree/master/data/probing)\t| Word order analysis\t| 100k     \t| 10k    \t| 1 | 1 |\n| [Tense](https://github.com/facebookresearch/SentEval/tree/master/data/probing)\t| Verb tense prediction\t| 100k     \t| 10k    \t| 1 | 1 |\n| [SubjNum](https://github.com/facebookresearch/SentEval/tree/master/data/probing)\t| Subject number prediction\t| 100k     \t| 10k    \t| 1 | 1 |\n| [ObjNum](https://github.com/facebookresearch/SentEval/tree/master/data/probing)\t| Object number prediction\t| 100k     \t| 10k    \t| 1 | 1 |\n| [SOMO](https://github.com/facebookresearch/SentEval/tree/master/data/probing)\t| Semantic odd man out\t| 100k     \t| 10k    \t| 1 | 1 |\n| [CoordInv](https://github.com/facebookresearch/SentEval/tree/master/data/probing)\t| Coordination Inversion | 100k     \t| 10k    \t| 1 | 1 |\n\n## Download datasets\nTo get all the transfer tasks datasets, run (in data/downstream/):\n```bash\n./get_transfer_data.bash\n```\nThis will automatically download and preprocess the downstream datasets, and store them in data/downstream (warning: for MacOS users, you may have to use p7zip instead of unzip). The probing tasks are already in data/probing by default.\n\n## How to use SentEval: examples\n\n### examples/bow.py\n\nIn examples/bow.py, we evaluate the quality of the average of word embeddings.\n\nTo download state-of-the-art fastText embeddings:\n\n```bash\ncurl -Lo glove.840B.300d.zip http://nlp.stanford.edu/data/glove.840B.300d.zip\ncurl -Lo crawl-300d-2M.vec.zip https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\n```\n\nTo reproduce the results for bag-of-vectors, run (in examples/):  \n```bash\npython bow.py\n```\n\nAs required by SentEval, this script implements two functions: **prepare** (optional) and **batcher** (required) that turn text sentences into sentence embeddings. Then SentEval takes care of the evaluation on the transfer tasks using the embeddings as features.\n\n### examples/infersent.py\n\nTo get the **[InferSent](https://www.github.com/facebookresearch/InferSent)** model and reproduce our results, download our best models and run infersent.py (in examples/):\n```bash\ncurl -Lo examples/infersent1.pkl https://dl.fbaipublicfiles.com/senteval/infersent/infersent1.pkl\ncurl -Lo examples/infersent2.pkl https://dl.fbaipublicfiles.com/senteval/infersent/infersent2.pkl\n```\n\n### examples/skipthought.py - examples/gensen.py - examples/googleuse.py\n\nWe also provide example scripts for three other encoders:\n\n* [SkipThought with Layer-Normalization](https://github.com/ryankiros/layer-norm#skip-thoughts) in Theano\n* [GenSen encoder](https://github.com/Maluuba/gensen) in Pytorch\n* [Google encoder](https://tfhub.dev/google/universal-sentence-encoder/1) in TensorFlow\n\nNote that for SkipThought and GenSen, following the steps of the associated githubs is necessary.\nThe Google encoder script should work as-is.\n\n## How to use SentEval\n\nTo evaluate your sentence embeddings, SentEval requires that you implement two functions:\n\n1. **prepare** (sees the whole dataset of each task and can thus construct the word vocabulary, the dictionary of word vectors etc)\n2. **batcher** (transforms a batch of text sentences into sentence embeddings)\n\n\n### 1.) prepare(params, samples) (optional)\n\n*batcher* only sees one batch at a time while the *samples* argument of *prepare* contains all the sentences of a task.\n\n```\nprepare(params, samples)\n```\n* *params*: senteval parameters.\n* *samples*: list of all sentences from the tranfer task.\n* *output*: No output. Arguments stored in \"params\" can further be used by *batcher*.\n\n*Example*: in bow.py, prepare is is used to build the vocabulary of words and construct the \"params.word_vect* dictionary of word vectors.\n\n\n### 2.) batcher(params, batch)\n```\nbatcher(params, batch)\n```\n* *params*: senteval parameters.\n* *batch*: numpy array of text sentences (of size params.batch_size)\n* *output*: numpy array of sentence embeddings (of size params.batch_size)\n\n*Example*: in bow.py, batcher is used to compute the mean of the word vectors for each sentence in the batch using params.word_vec. Use your own encoder in that function to encode sentences.\n\n### 3.) evaluation on transfer tasks\n\nAfter having implemented the batch and prepare function for your own sentence encoder,\n\n1) to perform the actual evaluation, first import senteval and set its parameters:\n```python\nimport senteval\nparams = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 10}\n```\n\n2) (optional) set the parameters of the classifier (when applicable):\n```python\nparams['classifier'] = {'nhid': 0, 'optim': 'adam', 'batch_size': 64,\n                                 'tenacity': 5, 'epoch_size': 4}\n```\nYou can choose **nhid=0** (Logistic Regression) or **nhid>0** (MLP) and define the parameters for training.\n\n3) Create an instance of the class SE:\n```python\nse = senteval.engine.SE(params, batcher, prepare)\n```\n\n4) define the set of transfer tasks and run the evaluation:\n```python\ntransfer_tasks = ['MR', 'SICKEntailment', 'STS14', 'STSBenchmark']\nresults = se.eval(transfer_tasks)\n```\nThe current list of available tasks is:\n```python\n['CR', 'MR', 'MPQA', 'SUBJ', 'SST2', 'SST5', 'TREC', 'MRPC', 'SNLI',\n'SICKEntailment', 'SICKRelatedness', 'STSBenchmark', 'ImageCaptionRetrieval',\n'STS12', 'STS13', 'STS14', 'STS15', 'STS16',\n'Length', 'WordContent', 'Depth', 'TopConstituents','BigramShift', 'Tense',\n'SubjNumber', 'ObjNumber', 'OddManOut', 'CoordinationInversion']\n```\n\n## SentEval parameters\nGlobal parameters of SentEval:\n```bash\n# senteval parameters\ntask_path                   # path to SentEval datasets (required)\nseed                        # seed\nusepytorch                  # use cuda-pytorch (else scikit-learn) where possible\nkfold                       # k-fold validation for MR/CR/SUB/MPQA.\n```\n\nParameters of the classifier:\n```bash\nnhid:                       # number of hidden units (0: Logistic Regression, >0: MLP); Default nonlinearity: Tanh\noptim:                      # optimizer (\"sgd,lr=0.1\", \"adam\", \"rmsprop\" ..)\ntenacity:                   # how many times dev acc does not increase before training stops\nepoch_size:                 # each epoch corresponds to epoch_size pass on the train set\nmax_epoch:                  # max number of epoches\ndropout:                    # dropout for MLP\n```\n\nNote that to get a proxy of the results while **dramatically reducing computation time**,\nwe suggest the **prototyping config**:\n```python\nparams = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 5}\nparams['classifier'] = {'nhid': 0, 'optim': 'rmsprop', 'batch_size': 128,\n                                 'tenacity': 3, 'epoch_size': 2}\n```\nwhich will results in a 5 times speedup for classification tasks.\n\nTo produce results that are **comparable to the literature**, use the **default config**:\n```python\nparams = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 10}\nparams['classifier'] = {'nhid': 0, 'optim': 'adam', 'batch_size': 64,\n                                 'tenacity': 5, 'epoch_size': 4}\n```\nwhich takes longer but will produce better and comparable results.\n\nFor probing tasks, we used an MLP with a Sigmoid nonlinearity and and tuned the nhid (in [50, 100, 200]) and dropout (in [0.0, 0.1, 0.2]) on the dev set.\n\n## References\n\nPlease considering citing [[1]](https://arxiv.org/abs/1803.05449) if using this code for evaluating sentence embedding methods.\n\n### SentEval: An Evaluation Toolkit for Universal Sentence Representations\n\n[1] A. Conneau, D. Kiela, [*SentEval: An Evaluation Toolkit for Universal Sentence Representations*](https://arxiv.org/abs/1803.05449)\n\n```\n@article{conneau2018senteval,\n  title={SentEval: An Evaluation Toolkit for Universal Sentence Representations},\n  author={Conneau, Alexis and Kiela, Douwe},\n  journal={arXiv preprint arXiv:1803.05449},\n  year={2018}\n}\n```\n\nContact: [aconneau@fb.com](mailto:aconneau@fb.com), [dkiela@fb.com](mailto:dkiela@fb.com)\n\n### Related work\n* [J. R Kiros, Y. Zhu, R. Salakhutdinov, R. S. Zemel, A. Torralba, R. Urtasun, S. Fidler - SkipThought Vectors, NIPS 2015](https://arxiv.org/abs/1506.06726)\n* [S. Arora, Y. Liang, T. Ma - A Simple but Tough-to-Beat Baseline for Sentence Embeddings, ICLR 2017](https://openreview.net/pdf?id=SyK00v5xx)\n* [Y. Adi, E. Kermany, Y. Belinkov, O. Lavi, Y. Goldberg - Fine-grained analysis of sentence embeddings using auxiliary prediction tasks, ICLR 2017](https://arxiv.org/abs/1608.04207)\n* [A. Conneau, D. Kiela, L. Barrault, H. Schwenk, A. Bordes - Supervised Learning of Universal Sentence Representations from Natural Language Inference Data, EMNLP 2017](https://arxiv.org/abs/1705.02364)\n* [S. Subramanian, A. Trischler, Y. Bengio, C. J Pal - Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning, ICLR 2018](https://arxiv.org/abs/1804.00079)\n* [A. Nie, E. D. Bennett, N. D. Goodman - DisSent: Sentence Representation Learning from Explicit Discourse Relations, 2018](https://arxiv.org/abs/1710.04334)\n* [D. Cer, Y. Yang, S. Kong, N. Hua, N. Limtiaco, R. St. John, N. Constant, M. Guajardo-Cespedes, S. Yuan, C. Tar, Y. Sung, B. Strope, R. Kurzweil - Universal Sentence Encoder, 2018](https://arxiv.org/abs/1803.11175)\n* [A. Conneau, G. Kruszewski, G. Lample, L. Barrault, M. Baroni - What you can cram into a single vector: Probing sentence embeddings for linguistic properties, ACL 2018](https://arxiv.org/abs/1805.01070)\n",
  "source_type": "meta_github_repository",
  "domain": "meta_ai",
  "keywords": [],
  "retrieval_tags": [
    "meta",
    "ai",
    "github",
    "repository",
    "research"
  ]
}