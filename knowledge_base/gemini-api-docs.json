{
  "id": "gemini-api-docs",
  "name": "Gemini Api Docs",
  "url": "https://github.com/google/generative-ai-docs",
  "description": "Gemini API Documentation",
  "source_type": "github_repository",
  "domain": "ai_documentation",
  "keywords": [
    "google",
    "ai",
    "documentation",
    "generative",
    "gemini",
    "api"
  ],
  "retrieval_tags": [
    "github",
    "repository",
    "google",
    "ai",
    "docs"
  ],
  "content": "=== README.md ===\n# Google Gemini API Website & Documentation\n\nThese are the source files for the guide and tutorials on\nthe [Generative AI developer site](https://ai.google.dev/), home to\nthe Gemini API and Gemma.\n\n| Path | Description |\n| ---- | ----------- |\n| [`site/`](site/) | Notebooks and other content used directly on ai.google.dev. |\n| [`demos/`](demos/) | Demos apps. Larger than examples, typically consists of working apps. |\n| [`examples/`](examples/) | Examples. Smaller, single-purpose code for demonstrating specific concepts. |\n\n\n\nTo contribute to the site documentation, please read\n[CONTRIBUTING.md](CONTRIBUTING.md).\n\nTo contribute as a demo app maintainer, please read\n[DEMO_MAINTAINERS.md](DEMO_MAINTAINERS.md).\n\nTo file an issue, please use the\n[GitHub issue tracker](https://github.com/google/generative-ai-docs/issues/new).\n\n## License\n\n[Apache License 2.0](LICENSE)\n\n\n=== LICENSE ===\n\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n\n=== README.md ===\n# Google Gemini API Website & Documentation\n\nThese are the source files for the guide and tutorials on\nthe [Generative AI developer site](https://ai.google.dev/), home to\nthe Gemini API and Gemma.\n\n| Path | Description |\n| ---- | ----------- |\n| [`site/`](site/) | Notebooks and other content used directly on ai.google.dev. |\n| [`demos/`](demos/) | Demos apps. Larger than examples, typically consists of working apps. |\n| [`examples/`](examples/) | Examples. Smaller, single-purpose code for demonstrating specific concepts. |\n\n\n\nTo contribute to the site documentation, please read\n[CONTRIBUTING.md](CONTRIBUTING.md).\n\nTo contribute as a demo app maintainer, please read\n[DEMO_MAINTAINERS.md](DEMO_MAINTAINERS.md).\n\nTo file an issue, please use the\n[GitHub issue tracker](https://github.com/google/generative-ai-docs/issues/new).\n\n## License\n\n[Apache License 2.0](LICENSE)\n\n\n=== CONTRIBUTING.md ===\n# How to Contribute\n\nWe would love to accept your patches and contributions to this project.\n\n## Before you begin\n\n### Sign our Contributor License Agreement\n\nContributions to this project must be accompanied by a\n[Contributor License Agreement](https://cla.developers.google.com/about) (CLA).\nYou (or your employer) retain the copyright to your contribution; this simply\ngives us permission to use and redistribute your contributions as part of the\nproject.\n\nIf you or your current employer have already signed the Google CLA (even if it\nwas for a different project), you probably don't need to do it again.\n\nVisit <https://cla.developers.google.com/> to see your current agreements or to\nsign a new one.\n\n### Review our Community Guidelines\n\nThis project follows [Google's Open Source Community\nGuidelines](https://opensource.google/conduct/).\n\n## Contribution process\n\n### Code Reviews\n\nAll submissions, including submissions by project members, require review. We \nuse [GitHub pull requests](https://docs.github.com/articles/about-pull-requests)\nfor this purpose.\n\n\n=== DEMO_MAINTAINERS.md ===\n# Demo Maintenance\n\nWe have several [demo applications](https://github.com/google/generative-ai-docs/tree/main/demos/palm) hosted in this repository that are referenced in the [AI for Developers](https://ai.google.dev/develop/sample-apps) site. We're looking to the community to help maintain them. \nThank you in advance for your contributions!\n\n## Responsibilities\n\nWhile we would love to accept any meaningful contributions to the demos, some tasks we'd particularly like help with include:\n1. Create a process to verify that the app works as desired after any changes are made (preferably automated, but a manual testing process works well to start)\n2. Get dependencies up-to-date\n3. Review and fix any outstanding issues and PRs (you can filter by the `demos:XYZ` [label](https://github.com/google/generative-ai-docs/labels?q=demos%3A))\n4. Migrate from PaLM to Gemini\n\n## Next Steps\n\nIf you're interested and commited to maintaining one of the demos, please complete the following:\n- Read through the [Contributing Guide](https://github.com/google/generative-ai-docs/blob/main/CONTRIBUTING.md).\n- Start work on the responsibilities above.\n- Once you have some progress demonstrated, submit a PR to add your GitHub handle next to the demo you're interested in maintaining, in the section below.\n- Non-responsive maintainers will be removed without notice.\n\n## Active Maintainers\n\n| Demo  | Maintainers |\n| ------------- | ------------- |\n| [list-it](https://github.com/google/generative-ai-docs/tree/main/demos/palm/web/list-it)  | @bupd |\n| [mood-food](https://github.com/google/generative-ai-docs/tree/main/demos/palm/web/mood-food)  |   |\n| [quick-prompt](https://github.com/google/generative-ai-docs/tree/main/demos/palm/web/quick-prompt)  |   |\n| [talking-character](https://github.com/google/generative-ai-docs/tree/main/demos/palm/web/talking-character)  |   |\n| [textfx](https://github.com/google/generative-ai-docs/tree/main/demos/palm/web/textfx)  |   |\n| [travel-planner](https://github.com/google/generative-ai-docs/tree/main/demos/palm/web/travel-planner)  |  |\n| [docs-agent](https://github.com/google/generative-ai-docs/tree/main/demos/palm/python/docs-agent)  | @nickvander @rundong08 @Meggin @kyolee415  |\n| [pipet-code-agent](https://github.com/google/generative-ai-docs/tree/main/demos/palm/node/pipet-code-agent)  | @joefernandez @shilpakancharla @markmcd  |\n\n\n=== third_party/README.md ===\n# third-party content\n\nEach individual sub-project is managing its own third-party contents. They will\nbe symlinked from here.\n\n\n=== examples/gemini/python/docs-agent/README.md ===\n# Docs Agent\n\nThe Docs Agent project explores applications and use cases that involve using a large\ncorpus of documentation as a knowledge source for AI language models.\n\nDocs Agent provides a set of easy-to-use self-service tools designed to give you and\nyour team access to Google's [Gemini API][genai-doc-site] for learning, experimentation,\nand project deployment.\n\n## Docs Agent MCP integration [NEW]\n\nWith the latest MCP (Model Context Protocol) integration, you can set up and launch\na MCP server and enable the Docs Agent CLI (`agent tools`) to use this MCP server.\n\nThe following example shows Docs Agent interacting with a\n[`git` MCP server][git-mcp-server] on the host machine:\n\n```\n$ agent tools Show me the latest commit in the Docs Agent project.\n\nUsing tools: ['git']\n\nCommit: 082949927e88df429c76e6dbf0a9e216c88fa5b0\nAuthor: Bob Alice\nDate: Tue May 13 11:22:19 2025 -0700\nMessage: Update BeautifulSoup findAll to find_all.\n```\n\nTo enable a MCP server, update the `config.yaml` file in your Docs Agent project,\nfor example:\n\n```\nmcp_servers:\n  - server_type: \"stdio\"\n    command: \"uv\"\n    name: \"git\"\n    args: [\"--directory\",\"/usr/local/home/user01/mcp_servers/servers/src/git\", \"run\", \"mcp-server-git\"]\n```\n\n## Docs Agent web app\n\nDocs Agent uses a technique known as **Retrieval Augmented Generation (RAG)**, which\nallows you to bring your own documents as knowledge sources to AI language models.\nThis approach helps the AI language models to generate relevant and accurate responses\nthat are grounded in the information that you provide and control.\n\n![Docs Agent architecture](docs/images/docs-agent-architecture-01.png)\n\n**Figure 1**. Docs Agent uses a vector database to retrieve context for augmenting prompts.\n\nThe Docs Agent chatbot web app is designed to be easily set up and configured in a Linux\nenvironment. If you want to set up and launch the Docs Agent chat app on your host machine,\ncheck out the [Set up Docs Agent][set-up-docs-agent] section below.\n\n## Docs Agent tasks\n\nDocs Agent's `agent runtask` command allows you to run pre-defined chains of prompts,\nwhich are referred to as **tasks**. These tasks simplify complex interactions by defining\na series of steps that the Docs Agent CLI will execute. The tasks are defined in `.yaml`\nfiles stored in the [`tasks`][tasks-dir] directory of your Docs Agent project. The tasks are\ndesigned to be reusable and can be used to automate common workflows, such as generating\nrelease notes, drafting overview pages, or analyzing complex information.\n\nA task file example:\n\n```yaml\ntasks:\n  - name: \"ExtractWorkflows\"\n    model: \"models/gemini-1.5-flash-latest\"\n    description: \"An agent that extracts workflows from a source doc.\"\n    steps:\n      - prompt: \"Summarize the contents of this document in a concise and informative manner. Focus on the key procedures, steps, or workflows described.\"\n        flags:\n          file: \"<INPUT>\"\n          default_input: \"./README.md\"\n      - prompt: \"Identify and list all key workflows described in the document. Provide a brief description for each workflow, highlighting its purpose and key steps.\"\n      - prompt: \"Identify all command lines used in the workflows described in the document. Focus on command lines that are essential for executing the workflow steps.\"\n      - prompt: \"For each identified command line, provide a detailed description of its function and purpose. Include specific examples of its usage, showcasing how it is integrated within the workflows.\"\n```\n\nTo set up and run the `agent runtask` command, see [Set up Docs Agent CLI][cli-readme].\n\nFor creating a new task, see [Create a new Docs Agent task][create-a-new-task].\n\n## Summary of features\n\nThe list below summarizes the tasks and features supported by Docs Agent:\n\n- **Process Markdown**: Split Markdown files into small plain text chunks. (See\n  [Docs Agent chunking process][chunking-process].)\n- **Generate embeddings**: Use an embedding model to process text chunks into embeddings\n  and store them in a vector database.\n- **Perform semantic search**: Compare embeddings in a vector database to retrieve\n  chunks that are most relevant to user questions.\n- **Add context to a user question**: Add chunks returned from a semantic search as\n  [context][prompt-structure] to a prompt.\n- **Generate related questions**: In addition to answering a question, Docs Agent can\n  [suggest related questions][related-questions-section] based on the context of the\n  question.\n- **Return URLs of source documents**: URLs are stored as chunks' metadata. This enables\n  Docs Agent to return the URLs of the source documents.\n- **Collect feedback from users**: Docs Agent's web app has buttons that allow users\n  to [like responses][like-generated-responses] or [submit rewrites][submit-a-rewrite].\n- **Convert Google Docs, PDF, and Gmail into Markdown files**: This feature uses\n  [Apps Script][apps-script-readme] to convert Google Docs, PDF, and Gmail into\n  Markdown files, which then can be used as input datasets for Docs Agent.\n- **Run benchmark test**: Docs Agent can [run benchmark test][benchmark-test] to measure\n  and compare the quality of text chunks, embeddings, and AI-generated responses.\n- **Use the Semantic Retrieval API and AQA model**: Docs Agent can use Gemini's\n  [Semantic Retrieval API][semantic-api] to upload source documents to online corpora\n  and use the [AQA model][aqa-model] for answering questions.\n- **Manage online corpora using the Docs Agent CLI**: The [Docs Agent CLI][cli-reference]\n  lets you create, update and delete online corpora using the Semantic Retrieval AI.\n- **Prevent duplicate chunks and delete obsolete chunks in databases**: Docs Agent\n  uses [metadata in chunks][chunking-process] to prevent uploading duplicate chunks\n  and delete obsolete chunks that are no longer present in the source.\n- **Run the Docs Agent CLI from anywhere in a terminal**:\n  [Set up the Docs Agent CLI][cli-readme] to make requests to the Gemini models\n  from anywhere in a terminal.\n- **Support the Gemini 1.5 models**: Docs Agent works with the Gemini 1.5 models,\n  `gemini-1.5-pro`, `gemini-1.5-flash`, and `text-embedding-004`. The new\n  [`full`][new-15-mode] web app mode uses all three Gemini models to their strength:\n  AQA (`aqa`), Gemini 1.0 Pro (`gemini-pro`), and Gemini 1.5 Pro (`gemini-1.5-pro`).\n- **Complete a task using the Docs Agent CLI**: The `agent runtask` command allows you\n  to run pre-defined chains of prompts, which are referred to as tasks. These tasks\n  simplify complex interactions by defining a series of steps that the Docs Agent will\n  execute. The tasks are defined in .yaml files stored in the [`tasks`][tasks-dir]\n  directory of your Docs Agent project. To run a task in this directory, for example:\n\n  ```sh\n  agent runtask --task DraftReleaseNotes\n  ```\n\n- **Multi-modal support**: Docs Agent's `agent helpme` command can include image,\n  audio, and video files as part of a prompt to the Gemini 1.5 model, for example:\n\n  ```sh\n  agent helpme Provide a concise, descriptive alt text for this PNG image --file ./my_image_example.png\n  ```\n\n  You can use this feature for creating tasks as well. For example, see the\n  [DescribeImages][describe-images] task.\n\n- **Interact with LLM using external tools**: The `agent tools` command allows\n  you to interact with the Gemini model using configured external tools\n  (through MCP - Model Context Protocol). This enables the agent to perform\n  actions by leveraging specialized tools. (See\n  [Docs Agent CLI reference][cli-reference] and\n  [Docs Agent concepts][docs-agent-concepts]).\n\nFor more information on Docs Agent's architecture and features,\nsee the [Docs Agent concepts][docs-agent-concepts] page.\n\n![Docs Agent chat app](docs/images/docs-agent-chat-app-screenshot-01.png)\n\n**Figure 2**. A screenshot of the Docs Agent chat app launched using Flutter docs.\n\n## Set up Docs Agent\n\n**Note**: For instructions on the Docs Agent CLI setup, see the\n[`README.md`][cli-readme] file in the `docs_agent/interfaces` directory.\n\nThis section provides instructions on how to set up and launch the Docs Agent\nchatbot web app on a Linux host machine.\n\n### 1. Prerequisites\n\nSetting up Docs Agent requires the following prerequisite items:\n\n- A Linux host machine\n\n- A [Google Cloud][google-cloud] project with the setup below:\n\n  - An API key enabled with the Generative Language API (that is,\n    the [Gemini API][genai-doc-site])\n\n  - (**Optional**) [Authenticated OAuth client credentials][oauth-client]\n    stored on the host machine\n\n### 2. Update your host machine's environment\n\nUpdate your host machine's environment to prepare for the Docs Agent setup:\n\n1. Update the Linux package repositories on the host machine:\n\n   ```\n   sudo apt update\n   ```\n\n2. Install the following dependencies:\n\n   ```\n   sudo apt install git pipx python3-venv\n   ```\n\n3. Install `poetry`:\n\n   ```\n   pipx install poetry\n   ```\n\n4. To add `$HOME/.local/bin` to your `PATH` variable, run the following\n   command:\n\n   ```\n   pipx ensurepath\n   ```\n\n5. To set the Google API key as a environment variable, add the following\n   line to your `$HOME/.bashrc` file:\n\n   ```\n   export GOOGLE_API_KEY=<YOUR_API_KEY_HERE>\n   ```\n\n   Replace `<YOUR_API_KEY_HERE>` with the API key to the\n   [Gemini API][genai-doc-site].\n\n6. Update your environment:\n\n   ```\n   source ~/.bashrc\n   ```\n\n### 3. (Optional) Authorize credentials for Docs Agent\n\n**This step is needed only if you plan to use [Gemini's AQA model][aqa-model-concept].**\n\nAuthorize Google Cloud credentials on your host machine:\n\n1. Download the `client_secret.json` file from your\n   [Google Cloud project][authorize-credentials].\n\n2. Copy the `client_secret.json` file to your host machine.\n\n3. Install the Google Cloud SDK on your host machine:\n\n   ```\n   sudo apt install google-cloud-sdk\n   ```\n\n4. To authenticate credentials, run the following command in the directory of\n   the host machine where the `client_secret.json` file is located:\n\n   ```\n   gcloud auth application-default login --client-id-file=client_secret.json --scopes='https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/generative-language.retriever'\n   ```\n\n   This command opens a browser and asks to log in using your Google account.\n\n5. Follow the instructions on the browser and click **Allow** to authenticate.\n\n   This saves the authenticated credentials for Docs Agent\n   (`application_default_credentials.json`) in the `$HOME/.config/gcloud/`\n   directory of your host machine.\n\n### 4. Clone the Docs Agent project\n\n**Note**: This guide assumes that you're creating a new project directory\nfrom your `$HOME` directory.\n\nClone the Docs Agent project and install dependencies:\n\n1. Clone the following repo:\n\n   ```\n   git clone https://github.com/google/generative-ai-docs.git\n   ```\n\n2. Go to the Docs Agent project directory:\n\n   ```\n   cd generative-ai-docs/examples/gemini/python/docs-agent\n   ```\n\n3. Install dependencies using `poetry`:\n\n   ```\n   poetry install\n   ```\n\n4. Set up the Poetry environment:\n\n   ```\n   poetry env activate\n   ```\n\n5. Install the `shell` plugin:\n\n   ```\n   poetry self add poetry-plugin-shell\n   ```\n\n6. Enter the `poetry` shell environment:\n\n   ```\n   poetry shell\n   ```\n\n   **Important**: From this point, all `agent` command lines below need to\n   run in this `poetry shell` environment.\n\n7. (**Optional**) To enable autocomplete commands and flags related to\n   Docs Agent in your shell environment, run the following command:\n\n   ```\n   source scripts/autocomplete.sh\n   ```\n\n### 5. Edit the Docs Agent configuration file\n\nThis guide uses the [open source Flutter documents][flutter-docs-src] as an example dataset,\nwhich are the source Markdown files for the [Flutter website][flutter-docs-site].\n\nTo complete this setup walkthrough, run the command below to download the open source\nFlutter documents somewhere on your host machine (for instance, in your `$HOME` directory):\n\n```\ngit clone --recurse-submodules https://github.com/flutter/website.git\n```\n\nUpdate settings in the Docs Agent project to use your custom dataset:\n\n1. Go to the Docs Agent project home directory, for example:\n\n   ```\n   cd $HOME/generative-ai-docs/examples/gemini/python/docs-agent\n   ```\n\n2. Open the [`config.yaml`][config-yaml] file using a text editor, for example:\n\n   ```\n   nano config.yaml\n   ```\n\n3. Edit the file to update the `product_name` field, for example:\n\n   ```\n   product_name: \"Flutter\"\n   ```\n\n   This product name is displayed on the Docs Agent chat app UI.\n\n4. Under the `inputs` field, define the following entries to specify the directories\n   that contain your source Markdown files.\n\n   - `path`: The directory where the source Markdown files are stored.\n   - `url_prefix`: The prefix used to create URLs for the source Markdown files.\n\n     **Important**: If URLs do not exist for your Markdown files, you still need to\n     provide a placeholder string in the `url_prefix` field.\n\n   The example below shows the entries for the Flutter documents downloaded in the\n  `$HOME/website` directory):\n\n   ```\n   inputs:\n     - path: \"/usr/local/home/user01/website/src/content\"\n       url_prefix: \"https://docs.flutter.dev\"\n   ```\n\n   You can also provide multiple input directories (`path` and `url_prefix` sets) under\n   the `inputs` field, for example:\n\n   ```\n   inputs:\n     - path: \"/usr/local/home/user01/website/src/content/ui\"\n       url_prefix: \"https://docs.flutter.dev/ui\"\n     - path: \"/usr/local/home/user01/website/src/content/tools\"\n       url_prefix: \"https://docs.flutter.dev/tools\"\n   ```\n\n6. If you want to use the `gemini-pro` model with a local vector database setup\n   (`chroma`), use the following settings:\n\n   ```\n   models:\n     - language_model: \"models/gemini-pro\"\n   ...\n   db_type: \"chroma\"\n   ```\n\n   (**Optional**) Or if you want to use the Gemini AQA model and populate\n   a corpus online via the [Semantic Retrieval API][semantic-api], use the\n   following settings (and update the `corpus_name` field):\n\n   ```\n   models:\n     - language_model: \"models/aqa\"\n   ...\n   db_type: \"google_semantic_retriever\"\n   db_configs:\n     ...\n     - db_type: \"google_semantic_retriever\"\n       corpus_name: \"corpora/flutter-dev\"\n   ```\n\n7. Save the `config.yaml` file and exit the text editor.\n\n\n### 6. Populate a new vector database\n\nThe Docs Agent CLI can help you chunk documents, generate embeddings extract metadata,\nand populate a vector database from Markdown files and more.\n\n**Note**: The `agent` commands below need to run within the `poetry shell` environment.\n\nTo populate a new vector database:\n\n1. Go to the Docs Agent project home directory, for example:\n\n   ```\n   cd $HOME/generative-ai-docs/examples/gemini/python/docs-agent\n   ```\n\n2. Process Markdown files into small text chunks:\n\n   ```\n   agent chunk\n   ```\n\n   The command takes documents under the `inputs` fields (specified in your\n   `config.yaml` file), splits the documents into small text chunk files, and\n   stores them in the `output_path` direcoty.\n\n3. Create and populate a new vector database:\n\n   ```\n   agent populate\n   ```\n\n   This command takes the plain text files in the `output_path` directory\n   and creates a new Chroma collection in the `vector_stores/` directory.\n\n### 7. Launch the Docs Agent chat app\n\nDocs Agent's Flask-based chat app lets users interact with the Docs Agent service through\na web browser.\n\n**Note**: The `agent chatbot` command needs to run within the `poetry shell` environment.\n\nTo start the Docs Agent chat app:\n\n1. Go to the Docs Agent project home directory, for example:\n\n   ```\n   cd $HOME/generative-ai-docs/examples/gemini/python/docs-agent\n   ```\n\n2. Launch the Docs Agent chat app:\n\n   ```\n   agent chatbot\n   ```\n\n   The Docs Agent chat app runs on port 5000 by default. If you have an application\n   already running on port 5000 on your host machine, you can use the `--port` flag to\n   specify a different port (for example, `agent chatbot --port 5050`).\n\n   **Note**: If this `agent chatbot` command fails to run, check the `HOSTNAME` environment\n   variable on your host machine (for example, `echo $HOSTNAME`). If this variable is unset,\n   try setting it to `localhost` by running `export HOSTNAME=localhost`\n\n   Once the app starts running, this command prints output similar to the following:\n\n   ```\n   $ agent chatbot\n   Launching the chatbot UI.\n    * Serving Flask app 'docs_agent.interfaces.chatbot'\n    * Debug mode: on\n   INFO:werkzeug:WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n    * Running on http://example.com:5000\n   INFO:werkzeug:Press CTRL+C to quit\n   INFO:werkzeug: * Restarting with stat\n   Launching the chatbot UI.\n   WARNING:werkzeug: * Debugger is active!\n   INFO:werkzeug: * Debugger PIN: 391-260-142\n   ```\n\n   Notice the line that shows the URL of this server (`http://example.com:5000`\n   in the example above).\n\n3. Open the URL above on a browser.\n\n   Now, users can start asking questions related to your product.\n\n**The Docs Agent chat app is all set!**\n\n## Contributors\n\nNick Van der Auwermeulen (`@nickvander`), Rundong Du (`@rundong08`),\nMeggin Kearney (`@Meggin`), and Kyo Lee (`@kyolee415`).\n\n<!-- Reference links -->\n\n[contribute-to-docs-agent]: #contribute-to-docs-agent\n[set-up-docs-agent]: #set-up-docs-agent\n[preprocess-dir]: ./docs_agent/preprocess/\n[populate-vector-database]: ./docs_agent/preprocess/populate_vector_database.py\n[related-questions-section]: ./docs/concepts.md#using-a-language-model-to-suggest-related-questions\n[submit-a-rewrite]: ./docs/concepts.md#enabling-users-to-submit-a-rewrite-of-a-generated-response\n[like-generated-responses]: ./docs/concepts.md#enabling-users-to-like-generated-responses\n[populate-db-steps]: #populate-a-new-vector-database-from-markdown-files\n[start-the-app-steps]: #start-the-docs-agent-chat-app\n[genai-doc-site]: https://ai.google.dev/docs/gemini_api_overview\n[chroma-docs]: https://docs.trychroma.com/\n[flutter-docs-src]: https://github.com/flutter/website/tree/main/src\n[flutter-docs-site]: https://docs.flutter.dev/\n[apps-script-readme]: ./apps_script/README.md\n[scripts-readme]: ./docs_agent/preprocess/README.md\n[config-yaml]: config.yaml\n[benchmark-test]: ./docs_agent/benchmarks/README.md\n[semantic-api]: https://ai.google.dev/docs/semantic_retriever\n[aqa-model]: https://ai.google.dev/models/gemini#model_variations\n[authorize-credentials]: https://ai.google.dev/docs/oauth_quickstart#authorize-credentials\n[aqa-model-concept]: ./docs/concepts.md#using-the-semantic-retrieval-api-and-aqa-model\n[prompt-structure]: ./docs/concepts.md#structure-of-a-prompt-to-a-language-model\n[docs-agent-concepts]: ./docs/concepts.md\n[google-cloud]: https://console.cloud.google.com/\n[oauth-client]: https://ai.google.dev/docs/oauth_quickstart#set-cloud\n[cli-readme]: docs_agent/interfaces/README.md\n[cli-reference]: docs/cli-reference.md\n[chunking-process]: docs/chunking-process.md\n[new-15-mode]: docs/config-reference.md#app_mode\n[tasks-dir]: tasks/\n[describe-images]: tasks/describe-images-for-alt-text-task.yaml\n[create-a-new-task]: docs/create-a-new-task.md\n[git-mcp-server]: https://github.com/modelcontextprotocol/servers/tree/main/src/git\n\n\n=== examples/gemini/python/docs-agent/CONTRIBUTING.md ===\n# How to Contribute\n\nWe would love to accept your patches and contributions to this project.\n\n## Before you begin\n\n### Sign our Contributor License Agreement\n\nContributions to this project must be accompanied by a\n[Contributor License Agreement](https://cla.developers.google.com/about) (CLA).\nYou (or your employer) retain the copyright to your contribution; this simply\ngives us permission to use and redistribute your contributions as part of the\nproject.\n\nIf you or your current employer have already signed the Google CLA (even if it\nwas for a different project), you probably don't need to do it again.\n\nVisit <https://cla.developers.google.com/> to see your current agreements or to\nsign a new one.\n\n### Review our Community Guidelines\n\nThis project follows [Google's Open Source Community\nGuidelines](https://opensource.google/conduct/).\n\n## Contribution process\n\n### Code Reviews\n\nAll submissions, including submissions by project members, require review. We\nuse [GitHub pull requests](https://docs.github.com/articles/about-pull-requests)\nfor this purpose.\n\n\n=== examples/gemini/python/docs-agent/docs/chunking-process.md ===\n# Docs Agent chunking process\n\nThis page describes Docs Agent's chunking process and potential optimizations.\n\nCurrently, Docs Agent utilizes Markdown headings (`#`, `##`, and `###`) to\nsplit documents into smaller, manageable chunks. However, the Docs Agent team\nis actively developing more advanced strategies to improve the quality and\nrelevance of these chunks for retrieval.\n\n## Chunking technique\n\nIn Retrieval Augmented Generation ([RAG][rag]) based systems, ensuring each\nchunk contains the right information and context is crucial for accurate\nretrieval. The goal of an effective chunking process is to ensure that each\nchunk encapsulates a focused topic, which enhances the accuracy of retrieval\nand ultimately leads to better answers. At the same time, the Docs Agent team\nacknowledges the importance of a flexible approach that allows for\ncustomization based on specific datasets and use cases.\n\nKey characteristics in Docs Agent’s chunking process include:\n\n- **Docs Agent splits documents based on Markdown headings.** However,\n  this approach has limitations, especially when dealing with large sections.\n- **Docs Agent chunks are smaller than 5000 bytes (characters).** This size\n  limit is set by the embedding model used in generating embeddings.\n- **Docs Agent enhances chunks with additional metadata.** The metadata helps\n  Docs Agent to execute operations efficiently, such as preventing duplicate\n  chunks in databases and deleting obsolete chunks that are  no longer\n  present in the source.\n- **Docs Agent retrieves the top 5 chunks and displays the top chunk's URL.**\n  However, this is adjustable in Docs Agent’s configuration (see the `widget`\n  and `experimental` app modes).\n\nThe Docs Agent team continues to explore various optimizations to enhance\nthe functionality and effectiveness of the chunking process. These efforts\ninclude refining the chunking algorithm itself and developing advanced\npost-processing techniques, for instance, reconstructing chunks to original\ndocuments after retrieval.\n\nAdditionally, the team has been exploring methods for co-optimizing content\nstructure and chunking strategies, which aims to maximize retrieval\neffectiveness by ensuring the structure of the source document itself\ncomplements the chunking process.\n\n## Chunks retrieval\n\nDocs Agent employs two distinct approaches for storing and retrieving chunks:\n\n- **The local database approach uses a [Chroma][chroma] vector database.**\n  This approach grants greater control over the chunking and retrieval\n  process. This option is recommended for development and experimental\n  setups.\n- **The online corpus approach uses Gemini’s\n  [Semantic Retrieval API][semantic-retrieval].** This approach provides\n  the advantages of centrally hosted online databases, ensuring\n  accessibility for all users throughout the organization. This approach\n  has some drawbacks, as control is reduced because the API may dictate\n  how chunks are selected and where customization can be applied.\n\nChoosing between these approaches depends on the specific needs of the user’s\ndeployment situation, which is to balance control and transparency against\npossible improvements in performance, broader reach and ease of use.\n\n<!-- Reference links -->\n\n[rag]: concepts.md\n[chroma]: https://docs.trychroma.com/\n[semantic-retrieval]: https://ai.google.dev/gemini-api/docs/semantic_retrieval\n\n\n=== examples/gemini/python/docs-agent/docs/concepts.md ===\n# Docs Agent concepts\n\n**Note**: If you want to set up and launch the Docs Agent chat app on your host machine,\nsee the [Set up Docs Agent][set-up-docs-agent] section in README.\n\nThis page describes the architecture and features of Docs Agent.\n\n## Overview\n\nThe Docs Agent chat app is designed to be easily set up and configured in a Linux environment.\nand require that you have access to Google’s [Gemini API][genai-doc-site].\n\nDocs Agent uses a technique known as Retrieval Augmented Generation (RAG), which allows\nyou to bring your own documents as knowledge sources to AI language models. This approach\nhelps the AI language models to generate relevant and accurate responses that are grounded\nin the information that you provide and control.\n\n![Docs Agent architecture](./images/docs-agent-architecture-01.png)\n\n**Figure 1**. Docs Agent uses a vector database to retrieve context for augmenting prompts.\n\n## Main features\n\nThe key features of the Docs Agent chat app are:\n\n- Add contextual information to user questions to augment prompts for AI language models.\n- Process documents into embeddings and store them in a vector database for semnatic retrieval.\n\n![Docs Agent flow](./images/docs-agent-architecture-02.png)\n\n**Figure 2**. A user question is augmented by the Docs Agent server and passed to an LLM.\n\nFor the moment, the Docs Agent project focuses on providing Python scripts that make it\neasy to process Markdown files into embeddings. However, there is no hard requirement that the\nsource documents must exist in Markdown format. What’s important is that the processed content\nis available as embeddings in the vector database.\n\n### Structure of a prompt to a language model\n\nTo enable an LLM to answer questions that are not part of the public knowledge (which the LLM\nis likely trained on), the Docs Agent project applies a mixture of prompt engineering and\nembeddings techniques. That is, we process a set of documents (which contain domain specific\nknowledge) into embeddings and store them in a vector database. This vector database allows\nthe Docs Agent server to perform semantic search on stored embeddings to find the most relevant\ncontent from the source documents given user questions.\n\nOnce the most relevant content is returned, the Docs Agent server uses the prompt structure\nshown in Figure 3 to augment the user question with a preset **condition** and a list of\n**context**. (When the Docs Agent server starts, the condition value is read from the\n[`config.yaml`][config-yaml] file.) Then the Docs Agent server sends this prompt to a\nlanguage model using the Gemini API and receives a response generated by the model.\n\n![Docs Agent prompt strcture](./images/docs-agent-prompt-structure-01.png)\n\n**Figure 3**. Prompt structure for augmenting a user question with related context\n(Context source: [eventhorizontelescope.org][context-source-01])\n\n### Processing of Markdown files into embeddings\n\nTo process information into embeddings using the Python scripts in the project, the\ninformation needs to be stored in Markdown format. Once you have a set of Markdown files\nstored in a directory on your host machine,  you can run the\n[`files_to_plain_text.py`][files-to-plain-text] script to process those Markdown\nfiles into small plain text files – the script splits the content by the top three Markdown\nheaders (`#`, `##`, and `###`).\n\nOnce Markdown files are processed into small plain text files, you can run the\n[`populate_vector_database.py`][populate-vector-database] script to generate embeddings\nfor each text file and store those embeddings into a [Chroma][chroma-docs] vector database\nrunning on the host machine.\n\nThe embeddings in this vector database enable the Docs Agent server to perform semantic search\nand retrieve context related to user questions for augmenting prompts.\n\nFor more information on the processing of Markdown files, see the [`README`][scripts-readme]\nfile in the `scripts` directory.\n\n![Document to embeddings](./images/docs-agent-embeddings-01.png)\n\n**Figure 4**. A document is split into small semantic chunks, which are then used to generate\nembeddings.\n\n![Markdown to embeddings](./images/docs-agent-embeddings-02.png)\n\n**Figure 5**. A Markdown page is split by headers and processed into embeddings.\n\n## Summary of tasks and features\n\nThe following list summarizes the tasks and features of the Docs Agent chat app:\n\n- **Process Markdown**: Split Markdown files into small plain text files. (See the\n  Python scripts in the [`preprocess`][preprocess-dir] directory.)\n- **Generate embeddings**: Use an embedding model to process small plain text files\n  into embeddings, and store them in a vector database. (See the\n  [`populate_vector_database.py`][populate-vector-database] script.)\n- **Perform semantic search**: Compare embeddings in the vector database to retrieve\n  most relevant content given user questions.\n- **Add context to a user question**: Add a list of text chunks returned from\n  a semantic search as context in a prompt.\n- **Generate related questions**: In addition to displaying a response to the user\n  question, the web UI displays 5 questions generated by the language model based on\n  the context of the user question. (See the\n  [Using a language model to suggest related questions][related-questions-section]\n  section.)\n- **Return URLs of documentation sources**: Docs Agent's vector database stores URLs\n  as metadata next to embeddings. Whenever the vector database is used to retrieve\n  text chunks for context, the database can also return the URLs of the sources used\n  to generate the embeddings.\n- **Collect feedback from users**: Docs Agent's chatbot web UI includes buttons that\n  allow users to [like generated responses][like-generated-responses] or\n  [submit rewrites][submit-a-rewrite].\n- **Convert Google Docs, PDF, and Gmail into Markdown files**: This feature uses\n  Apps Script to convert Google Docs, PDF, and Gmail into Markdown files, which then\n  can be used as input datasets for Docs Agent. (See the\n  [`apps_script`][apps-script-readme] directory.)\n- **Run benchmark test to monitor the quality of AI-generated responses**: Using\n  Docs Agent, you can run [benchmark test][benchmark-test] to measure and compare\n  the quality of text chunks, embeddings, and AI-generated responses.\n- **Use the Semantic Retrieval API and AQA model**: You can use Gemini's\n  [Semantic Retrieval API][semantic-api] to upload source documents to an online\n  corpus and use the [AQA model][aqa-model] that is specifically created for answering\n  questions using an online corpus.\n\n## Flow of events\n\nThe following events take place in the Docs Agent chat app:\n\n1. The [`files_to_plain_text.py`][files-to-plain-text] script converts input\n   Markdown documents into small plain text files, split by Markdown headings\n   (`#`, `##`, and `###`).\n2. The [`populate_vector_database.py`][populate-vector-database] script generates\n   embeddings from the small plain text files and populates a vector database.\n3. When the [`agent chatbot`] command is run, it starts the Docs Agent server and\n   vector database, which loads generated embeddings and metadata (URLs and filenames)\n   stored in the `vector_store` directory.\n4. When the user asks a question, the Docs Agent server uses the vector database to\n   perform semantic search on embeddings, which represent content in the source\n   documents.\n5. Using this semantic search capability, the Docs Agent server finds a list of\n   text chunks that are most relevant to the user question.\n6. The Docs Agent server adds this list of text chunks as context (plus a condition\n   for responses) to the user question and constructs them into a prompt.\n7. The system sends the prompt to a language model via the Gemini API.\n8. The language model generates a response and the Docs Agent server renders it on\n   the chat UI.\n\nAdditional events for\n[suggesting 5 questions related to the user question][related-questions-section]:\n\n9. The Docs Agent server prepares another prompt that asks the language model to\n    generate 5 questions based on the context (in step 6).\n10. The language model generates a response that contains a list of questions related\n    to the context.\n11. The Docs Agent server renders the questions on the chat UI.\n\n## Supplementary features\n\nThis section describes additional features implemented on the Docs Agent chat app for\nenhancing the usability of the Q&A experience powered by generative AI.\n\n![Docs Agent UI](./images/docs-agent-ui-screenshot-01.png)\n\n**Figure 6**. A screenshot of the Docs Agent chat UI showing the sections generated by\nthree distinct prompts.\n\n### Using a language model to suggest related questions\n\nThe project‘s latest web UI includes the “Related questions” section, which displays five\nquestions that are related to the user question (see Figure 6). These five questions are also\ngenerated by a language model (via the Gemini API). Using the list of contents returned from the vector\ndatabase as context, the system prepares another prompt asking the language model to generate five\nquestions from the included context.\n\nThe following is the exact structure of this prompt:\n\n- Condition:\n\n  ```\n  Read the context below and answer the question at the end:\n  ```\n\n- Context:\n\n  ```\n  <CONTEXT_USED_IN_THE_PREVIOUS_PROMPT>\n  ```\n\n- Question:\n\n  ```\n  What are 5 questions developers might ask after reading the context?\n  ```\n\n### Enabling users to submit a rewrite of a generated response\n\nThe project‘s latest web UI includes the **Rewrite this response** button at the bottom of\nthe panel (see Figure 6). When this button is clicked, a widget opens up, expanding the\nmain UI panel, and reveals a textarea containing the generated response to the user's question.\nThe user is then allowed to edit this response in the textarea and click the **Submit** button\nto submit the updated response to the system.\n\nThe system stores the submitted response as a Markdown file in the project's local `rewrites`\ndirectory. The user may re-click the **Submit** button to update the submitted rewrite multiple\ntimes.\n\n### Enabling users to like generated responses\n\nThe project's latest web UI includes the **Like this response** button at the bottom of the panel\n(see Figure 6). When this button is clicked, the server logs the event of \"like\" for the response.\nHowever, clicking the **Liked** button again will reset the button. Then the server logs this reset\nevent of \"like\" for the response.\n\nThe user may click this like button multiple times to toggle the state of the like button. But when\nexamining the logs, only the final state of the like button will be considered for the response.\n\n### Using Google Docs, PDF, or Gmail as input sources\n\nThe project includes Apps Script files that allow you to convert various sources of content\n(including Google Docs and PDF) from your Google Drive and Gmail into Markdown files. You can then\nuse these Markdown files as additional input sources for Docs Agent. For more information, see the\n[`README`][apps-script-readme] file in the `apps_script` directory.\n\n![Docs Agent pre-processing flow](./images/docs-agent-pre-processing-01.png)\n\n**Figure 7**. Docs Agent's pre-processing flow for various doc types.\n\n### Using the Semantic Retrieval API and AQA model\n\nDocs Agent provides options to use Gemini's [Semantic Retrieval API][semantic-api] for storing text\nchunks in Google Cloud's online storage (and using this online storage for context retrieval),\nin combination with using the [AQA model][aqa-model] for question-answering.\n\nTo use the Semantic Retrieval API, update the `config.yaml` file to the following settings:\n\n```\nmodels:\n  - language_model: \"models/aqa\"\n\n...\n\ndb_type: \"google_semantic_retriever\"\n```\n\nThe setup above uses both the Semantic Retrieval API and the AQA model.\n\n**Note**: At the moment, when `db_type` is set to `google_semantic_retriever`, running the\n`populate_vector_database.py` script will also create and popluate a local vector database using\nChroma as well as creating and populating an online corpus using the Semantic Retrieval API.\n\nHowever, if you want to use only the AQA model without using an online corpus, update the\n`config.yaml` file to the following settings instead:\n\n```\nmodels:\n  - language_model: \"models/aqa\"\n\n...\n\ndb_type: \"chroma\"\n```\n\nThe setup above uses the AQA model with your local Chroma vector database. For more information,\nsee the [More Options: AQA Using Inline Passages][inline-passages] section on the\n_Semantic Retriever Quickstart_ page.\n\n**Note**: To use the Semantic Retrieval API, you need to complete the OAuth setup for your Google\nCloud project from your host machine. For detailed instructions, see the\n[Authentication with OAuth quickstart][oauth-quickstart] page.\n\n### Using Tools (MCP Integration)\n\nDocs Agent integrates with external tools using the Model Command Platform\n(MCP). This enables more complex and interactive workflows where the language\nmodel can delegate specific tasks to specialized tools.\n\n1. **Configuration**: You define available MCP tool servers in your\n   [`config.yaml`][config-yaml] file under the `mcp_servers` key. Each entry\n  specifies how Docs Agent connects to a tool server (currently `stdio` or\n  `sse`).\n2. **Tool Discovery**: When you run the `agent tools` command, Docs Agent\n   connects to the configured MCP servers and discovers the available tools and\n  their functions (including required parameters).\n3.  **Function Calling**: This list of tools is provided to the Gemini model.\n  When you provide a prompt (e.g., \"Summarize recent changes in `main.py`\"),\n  the model can decide if executing one of the available tools would help\n  fulfill the prompt. If so, it issues a *function call*.\n4. **Execution**: Docs Agent intercepts this function call, executes the\n   corresponding tool through the appropriate MCP server, and captures the result.\n5. **Response Generation**: The tool's result is sent back to the Gemini model\n  as context. The model then uses this result to generate the final response to\n  your original prompt.\n\nThis mechanism allows Docs Agent to ground in real-time information or actions\nperformed by external tools brought up as MCP servers.\n\n<!-- Reference links -->\n\n[set-up-docs-agent]: ../README.md#set-up-docs-agent\n[files-to-plain-text]: ../docs_agent/preprocess/files_to_plain_text.py\n[populate-vector-database]: ../docs_agent/preprocess/populate_vector_database.py\n[context-source-01]: http://eventhorizontelescope.org\n[related-questions-section]: #using-a-language-model-to-suggest-related-questions\n[submit-a-rewrite]: #enabling-users-to-submit-a-rewrite-of-a-generated-response\n[like-generated-responses]: #enabling-users-to-like-generated-responses\n[populate-db-steps]: #populate-a-new-vector-database-from-markdown-files\n[genai-doc-site]: https://ai.google.dev/docs/gemini_api_overview\n[chroma-docs]: https://docs.trychroma.com/\n[apps-script-readme]: ../apps_script/README.md\n[scripts-readme]: ../docs_agent/preprocess/README.md\n[config-yaml]: ../config.yaml\n[benchmark-test]: ../docs_agent/benchmarks/README.md\n[semantic-api]: https://ai.google.dev/docs/semantic_retriever\n[aqa-model]: https://ai.google.dev/models/gemini#model_variations\n[oauth-quickstart]: https://ai.google.dev/docs/oauth_quickstart\n[inline-passages]: https://ai.google.dev/docs/semantic_retriever#more_options_aqa_using_inline_passages\n[authorize-credentials]: https://ai.google.dev/docs/oauth_quickstart#authorize-credentials\n[preprocess-dir]: ../docs_agent/preproces/\n\n\n=== examples/gemini/python/docs-agent/docs/config-reference.md ===\n# Docs Agent configuration reference\n\nThis page provides a list of additional options that can be specified\nin the Docs Agent configuration file ([`config.yaml`][config-yaml]).\n\n## Web application options\n\n### app_port\n\nThis field sets the port which the Docs Agent web app runs on.\n\n```\napp_port: 5001\n```\n\nBy default, the web app is set to use port 5000.\n\n### app_mode\n\nThis field controls the user interface mode of the web app.\n\nThe options are:\n\n* `widget`: This mode launches a compact widget-style interface, suitable\n  for being embedded within a webpage.\n\n  ```\n  app_mode: \"widget\"\n  ```\n\n* `full`: This special mode is designed to be used with Gemini 1.5 models.\n\n  ```\n  app_mode: \"full\"\n  ```\n\nWhen this field is not specified, the web app is set to use the standard mode.\n\n## User feedback options\n\n### feedback_mode\n\nThis field sets the type of feedback mechanism available to users for providing\nthe quality or relevance of responses.\n\nThe options are:\n\n* `feedback`: This is the default setting.\n\n  ```\n  feedback_mode: \"feedback\"\n  ```\n\n* `rewrite`: This option provides the \"Rewrite this response\" button to allows\n  users to suggest alternative responses.\n\n  ```\n  feedback_mode: \"rewrite\"\n  ```\n\n* `like_and_dislike`: This option provides simple \"Like\" and \"Dislike\" buttons.\n\n  ```\n  feedback_mode: \"like_and_dislike\"\n  ```\n\n## Logging options\n\n### log_level\n\nThis field controls the level of detail captured in the logs generated by Docs\nAgent.\n\nSetting it to `VERBOSE` provides more comprehensive logging information:\n\n```\nlog_level: \"VERBOSE\"\n```\n\nThis field is set to `NORMAL` by default.\n\n### enable_show_logs\n\nSetting this field to `\"True\"` allows logs to be displayed on a web browser\n(which is accessible at `<APP_URL>/logs`):\n\n```\nenable_show_logs: \"True\"\n```\n\n### enable_logs_to_markdown\n\nSetting this field to `\"True\"` saves the generated answers as Markdown pages\non the host machine:\n\n```\nenable_logs_to_markdown: \"True\"\n```\n\n### enable_logs_for_debugging\n\nSetting this field to `\"True\"` generates detailed logs for debugging purposes:\n\n```\nenable_logs_for_debugging: \"True\"\n```\n\n## Database management options\n\n### enable_delete_chunks\n\nSetting this field to `\"True\"` enables the ability to delete outdated, stale\ntext chunks from the vector databases:\n\n```\nenable_delete_chunks: \"True\"\n```\n\n## Secondary database configuration\n\nDocs Agent allows for the use of a secondary database alongside the primary one\nfor providing additional context from a different source.\n\n### secondary_db_type\n\nThis field specifies the type of secondary database to be used:\n\n```\nsecondary_db_type: \"google_semantic_retrieval\"\n```\n\nor\n\n```\nsecondary_db_type: \"chroma\"\n```\n\nWhen `chroma` is specified, the collection in the `vector_stores/chroma`\ndirectory is used as the secondary database.\n\n### secondary_corpus_name\n\nThis field defines the name of the corpus for the secondary database,\nfor example:\n\n```\nsecondary_corpus_name: \"corpora/my-example-corpus\"\n```\n\n### mcp_servers\n\nThis field defines a list of Model Context Protocol (MCP) servers that Docs\nAgent can use. These servers expose external tools that the language model can\nuse when responding to prompts through the `agent tools` command.\nEach entry in the list defines a connection to one MCP server.\n\n```yaml\nmcp_servers:\n  - name: \"my_custom_tool\"  # A unique identifier for this tool server\n    connection_type: \"stdio\"  # Currently 'stdio' or 'sse'\n    command: [\"npx\"] # This can be npx to directly run a MCP server with npx\n    args: [\"<flag>\", \"<address>\"] # Command to use the server for stdio\n    env:\n      <ENV_NAME>: '{ \"headless\": true, \"args\": [] }' # I.E. PUPPETEER_LAUNCH_OPTIONS: '{ \"headless\": true, \"args\": [] }'\n    # url: \"http://localhost:8080/mcp\" # URL for the server (for sse)\n  - name: \"another_tool\"\n    connection_type: \"sse\"\n    url: \"http://localhost:8080/mcp\"\n  - name: \"git\"\n    server_type: \"stdio\"\n    command: \"uv\"\n    name: \"git\"\n    args: [\"--directory\",\"~/mcp_servers/servers/src/git\", \"run\", \"mcp-server-git\"] # Your machine needs the checkout\n```\n<!-- Reference link -->\n\n[config-yaml]: ../config.yaml\n\n\n=== examples/gemini/python/docs-agent/docs/whats-new.md ===\n# What's new in Docs Agent\n\n\n## April 2025\n\n* **Milestone: Introduced Tool Usage through MCP**\n* Added the new `agent tools` CLI command, enabling interaction with the model\n  using external tools.\n* Leverages the Model Context Protocol (MCP) for tool discovery and execution.\n  Define MCP servers in `config.yaml`.\n* This allows the agent to use configured tools.\n* Manages tools through the `ToolManager` and `MCPService`.\n\n## April 2024\n\n* **Focus: Feature enhancements and usability improvements**\n* Expanded CLI functionality with options for managing online corpora and interacting with files.\n* Addressed bug fixes and performed code refactoring for improved stability and maintainability.\n* Added a new chat app template specifically designed for the **Gemini 1.5 model**.\n* Updated GenAI SDK version to `0.5.0`.\n* Introduced a splitter for handling of Fuchsia’s FIDL protocol files in the preprocessing stage.\n\n## March 2024\n\n* **Milestone: Introduction of the Docs Agent CLI**\n* Added the `tellme` command for direct interaction with Gemini from a Linux terminal.\n* Expanded CLI options for corpora management, including creation, deletion, and permission control.\n* Enhanced the chat app UI with a \"loading\" animation and probability-based response pre-screening.\n* Enabled displaying more URLs retrieved from the AQA model in the widget mode.\n* Added support for including URLs as metadata when uploading chunks to online corpora.\n\n## February 2024\n\n* **Focus: Refining AQA model integration**\n* Improved UI rendering of AQA model responses, especially for code segments.\n* Addressed bug fixes to handle unexpected AQA model responses.\n* Generated related questions by using retrieved context instead of a user question.\n* Started logging `answerable_probability` for AQA model responses.\n\n## January 2024\n\n* **Milestone: Docs Agent uses AQA model and Semantric Retrieval API**\n* Started Logs Agent experiments\n* Benchmark score up ~2.5% with enhancements to embeddings\n\n## December 2023\n\n* **Milestone: Docs Agent uses Gemini model.**\n* Prototyping benchmarking: documentation unit tests.\n* Steady traffic since launch, 861 weekly views, December 14.\n\n## November 2023\n\n* Experimented with context reconstruction.\n* Docs Agent now parsing code blocks.\n* Added new condition using a mixture of best practices to improve answers.\n* Added chunking by tokenization.\n\n## October 2023\n\n* **Milestone: Docs Agent supports Google docs, PDFs, and emails.**\n* Drafted Docs Agent security strategy.\n* Drafted Docs Agent + Talking Character design doc.\n* Top of the charts for generative AI samples: 1216 weekly views.\n* Build for AI series: 16000 watches.\n\n## September 2023\n\n* First open-source feature request: support Google docs.\n* **Milestone: Docs Agent published!**\n* Recorded Build for AI series.\n* Implemented hashing to check existing entries and only generate embeddings for\n  new or updated content.\n\n## August 2023\n\n* Docs Agent demo running with Flutter docs.\n* Docs Agent gets necessary approvals for open-sourcing.\n* Special mention: Docs Agent gets it's name.\n* Added support to read frontmatter, starting with titles.\n\n## July 2023\n\n* Light month, as many of us took vacations :).\n* Created `opensource` branch on internal repo for open-source pushes.\n* Reviewed video script for Build for AI series.\n* Security: meeting on using open-source content and security issues.\n\n## June 2023\n\n* Drafted Docs Agent Readme.\n* Created internal repo to set up infrastructure for open-source pushes.\n* First internal customer tried Docs Agent.\n* Compiled list of Todos to open-source Docs Agent.\n\n## May 2023\n\n* Switched from chunking content based on 3000-char limit to chunking by\n  headings.\n* Cleaned up Markdown processing issues.\n* Privacy: clarified in UI how we are using data.\n* Attempted to create a chat bot for Google chat.\n* Added database admin console.\n* Partially implemented rewrite option.\n* Added related questions.\n\n## April 2023\n\n* Created new UI for chat app: Flask app.\n* Added 'fact-checking' section.\n* **Milestone: started the Docs Agent open-source project.**\n\n\n=== examples/gemini/python/docs-agent/docs/create-a-new-task.md ===\n# Create a new Docs Agent task\n\nThis guide provides instructions on how to create a new Docs Agent\ntask file (`.yaml`) for automating a workflow.\n\n## Create a new task\n\nTo create a new task in your Docs Agent setup, follow these steps:\n\n1. Go to your Docs Agent directory, for example:\n\n   ```\n   cd ~/docs_agent\n   ```\n\n2. Go to the `tasks` directory:\n\n   ```\n   cd tasks\n   ```\n\n3. Open a text editor and create a new `yaml` file, for example:\n\n   ```\n   nano my-new-task.yaml\n   ```\n\n4. Copy and paste the following task template:\n\n   ```\n    tasks:\n      - name: \"<TASKNAME>\"\n        model: \"models/gemini-1.5-flash\"\n        description: \"<DESCRIPTION>\"\n        preamble: <”PREAMBLE>”\n        steps:\n          - prompt: \"<PROMPT_1>\"\n          - prompt: \"<PROMPT_2>\"\n          - prompt: \"<PROMPT_3>\"\n   ```\n\n5. Update the task name (`<TASKNAME>`).\n6. (**Optional**) Update the model (see this\n   [Gemini model code][model-code]).\n7. Update the task description (`<DESCRIPTION>`).\n8. (**Optional**) Update the preamble (`<PREAMBLE>`).\n\n   **Note**: The `preamble` field is not required. If it's not used,\n   remove the `preamble` field.\n\n9. Update the prompts (`<PROMPT_#>`).\n10. (**Optional**) Add more prompts under the `steps` section.\n11. Save the file and exit the text editor.\n12. To verify that your new task is available, run the following command:\n\n    ```\n    agent runtask\n    ```\n\n13. Run the new task using the task name:\n\n    ```\n    agent runtask --task <TASKNAME>\n    ```\n\n    For example:\n\n    ```\n    agent runtask --task MyNewExampleTask\n    ```\n\n    If your task accepts custom input, you can run it with the\n    `--custom_input` field, for example:\n\n    ```\n    agent runtask --task MyNewExampleTask --custom_input ~/my_project/my_example_doc.md\n    ```\n\n## A minimum task file\n\nThe example task below is created using only the **required fields**:\n\n```\ntasks:\n  - name: \"MyExampleTask\"\n    model: \"models/gemini-1.5-flash\"\n    description: \"An agent example that is created using only the required fields for a task.\"\n    steps:\n      - prompt: \"This is my first prompt.\"\n      - prompt: \"This is my second prompt.\"\n      - prompt: \"This is my third prompt.\"\n```\n\nA task can have one `prompt` step at a minimum.\n\nFor more examples, see the [`tasks`][tasks-dir] directory.\n\n## More examples for steps\n\nThis section contains more `prompt` examples and optional fields.\n\n### A standard prompt step\n\nA step that runs the `helpme` command:\n\n```\n   steps:\n     - prompt: \"Revise the PSA email draft above to be more concise and better structured.\"\n```\n\n### A POSIX command step\n\nA step that runs a POSIX command:\n\n```\n   steps:\n     - prompt: \"git --no-pager log --since=2024-10-15\"\n       function: \"posix\"\n```\n\n**Important**: To run a POSIX command, the `function` field\nmust be set to `posix`.\n\n### A script step\n\nA step that runs a custom script:\n\n```\n   steps:\n     - prompt: \"extract_image_files.py\"\n       function: \"script\"\n```\n\n**Important**: To run a custom script, the script must be stored in\nthe [`scripts`][scripts-dir] directory of the Docs Agent setup.\n\nYou can provide a `script` step with a custom input string as\narguments to the script using the `script_input` field, for example:\n\n```\n   steps:\n      - prompt: \"extract_image_files.py\"\n        function: \"script\"\n        flags:\n          script_input: \"<INPUT>\"\n          default_input: \"./README.md\"\n```\n\nThis step runs the following commandline:\n\n```sh\n$ python3 scripts/extract_image_files.py <INPUT>\n```\n\n### A step that reads a file\n\nThe `file` flag reads the specified file and added its content\nto the prompt's context.\n\nA step that runs the `helpme` command with the `file` flag:\n\n```\n   steps:\n     - prompt: \"Analyze this file to understand the overall structure and key concepts.\"\n       flags:\n         file: \"/home/user/docs_agent/README.md\"\n```\n\nA step that runs the `helpme` command with the `file` flag and accepts custom input:\n\n```\n   steps:\n     - prompt: \"Analyze this file to understand the overall structure and key concepts.\"\n       flags:\n         file: \"<INPUT>\"\n         default_input: \"/home/user/docs_agent/README.md\"\n```\n\nWhen this step is run, the `<INPUT>` string will be replaced with\nthe value provided in the `--custom_input` field at runtime.\n\nYou can also provide multiple files using a list as shown below:\n\n```\n    steps:\n      - prompt: \"Provide a concise, descriptive alt text for this PNG image.\"\n        flags:\n          file:\n            - \"docs/images/apps-script-screenshot-01.png\"\n            - \"docs/images/docs-agent-ui-screenshot-01.png\"\n            - \"docs/images/docs-agent-embeddings-01.png\"\n```\n\n### A step that reads all files in a directory\n\nThe `allfiles` flag reads all the files in the specified directory\nand added their content to the prompt's context.\n\nA step that runs the `helpme` command with the `allfiles` flag:\n\n```\n   steps:\n     - prompt: \"Analyze the files in this directory to understand the overall structure and key concepts.\"\n       flags:\n         allfiles: \"/home/user/docs_agent/docs\"\n```\n\nA step that runs the `helpme` command with the `allfiles` flag\nand accepts custom input:\n\n```\n   steps:\n     - prompt: \"Analyze the files in this directory to understand the overall structure and key concepts.\"\n       flags:\n         allfiles: \"<INPUT>\"\n         default_input: \"/home/user/docs_agent/docs\"\n```\n\nWhen this step is run, the `<INPUT>` string will be replaced with\nthe value provided in the `--custom_input` field at runtime.\n\n### A step that reads each file in a directory\n\nSimilar to a `foreach` loop, the `perfile` flag reads each file in\nthe specified directory and added the file's content to the prompt's\ncontext. For instance, if there are 5 files in the input directory,\nthe same prompt will run 5 times using each file's content as context.\n\nA step that runs the `helpme` command with the `perfile` flag:\n\n```\n   steps:\n     - prompt: \"Analyze this file to understand the overall structure and key concepts.\"\n       flags:\n         perfile: \"/home/user/docs_agent/docs\"\n```\n\nA step that runs the `helpme` command with the `perfile` flag\nand accepts custom input:\n\n```\n   steps:\n     - prompt: \"Analyze this file to understand the overall structure and key concepts.\"\n       flags:\n         perfile: \"<INPUT>\"\n         default_input: \"/home/user/docs_agent/docs\"\n```\n\nWhen this step is run, the `<INPUT>` string will be replaced with\nthe value provided in the `--custom_input` field at runtime.\n\n### A step that reads a list of file names from an input file\n\nSimilar to the `perfile` flag, the `list_file` flag reads an input\nfile that contains a list of filenames and applies the prompt to\neach file in the list:\n\n```\n   steps:\n     - prompt: \"Write an alt text string for this image.\"\n       flags:\n         list_file: \"out/mylist.txt\"\n```\n\nwhere the `out/mylist.txt` file contains a list of file names in\nplain text as shown below:\n\n```none\n$ cat out/mylist.txt\ndocs/images/apps-script-screenshot-01.png\ndocs/images/docs-agent-ui-screenshot-01.png\ndocs/images/docs-agent-embeddings-01.png\n```\n\n### A step with the name field\n\nA step that runs the `helpme` command and the `name` field\n(which is for display only) is provided:\n\n```\n   steps:\n     - name: \"Revise the PSA email\"\n       prompt: \"Revise the PSA email draft above to be more concise and better structured.\"\n```\n\n### A step with the function field\n\nA step that runs the `helpme` command that explicitly mentions\nwhich `function` to use:\n\n```\n   steps:\n     - prompt: \"Revise the PSA email draft above to be more concise and better structured.\"\n       function: \"helpme\"\n```\n\nWithout the `function` field, the prompt is set to use the `helpme` command by default.\n\n### A question step\n\nA step that runs the `tellme` command:\n\n```\n   steps:\n     - prompt: \"Does Flutter support Material Design 3?\"\n       function: \"tellme\"\n```\n\nUsing the `tellme` command requires **a vector database setup**.\n\n<!-- Referene links -->\n\n[model-code]: https://ai.google.dev/gemini-api/docs/models/gemini\n[tasks-dir]: ../tasks\n[scripts-dir]: ../scripts\n\n\n=== examples/gemini/python/docs-agent/docs/cli-reference.md ===\n# Docs Agent CLI reference\n\nThis page provides a list of the Docs Agent command lines and their usages\nand examples.\n\nThe Docs Agent CLI helps developers to manage the Docs Agent project and\ninteract with language models. It can handle various tasks such as\nprocessing documents, populating vector databases, launching the chatbot,\nrunning benchmark test, sending prompts to language models, and more.\n\n**Important**: All `agent` commands need to run in the `poetry shell`\nenvironment.\n\n## Processing documents\n\n### Chunk Markdown files into small text chunks\n\nThe command below splits Markdown files (and other source files) into small\nchunks of plain text files:\n\n```sh\nagent chunk\n```\n\n### Populate a vector database using text chunks\n\nThe command below populates a vector database using plain text files (created\nby running the `agent chunk` command):\n\n```sh\nagent populate\n```\n\n### Populate a vector database and delete stale text chunks\n\nThe command below deletes stale entries in the existing vector database\nbefore populating it with the new text chunks:\n\n```sh\nagent populate --enable_delete_chunks\n```\n\n### Show the Docs Agent configuration\n\nThe command below prints all the fields and values in the current\n[`config.yaml`][config-yaml] file:\n\n```sh\nagent show-config\n```\n\n### Clean up the Docs Agent development environment\n\nThe command below deletes development databases specified in the\n`config.yaml` file:\n\n```sh\nagent cleanup-dev\n```\n\n### Write logs to a CSV file\n\nThe command below writes the summaries of all captured debugging information\n(in the `logs/debugs` directory) to  a `.csv` file:\n\n```sh\nagent write-logs-to-csv\n```\n\n## Launching the chatbot web app\n\n### Launch the Docs Agent web app\n\nThe command below launches Docs Agent's Flask-based chatbot web application:\n\n```sh\nagent chatbot\n```\n\n### Launch the Docs Agent web app using a different port\n\nThe command below launches the Docs Agent web app to run on port 5005:\n\n```sh\nagent chatbot --port 5005\n```\n\n### Launch the Docs Agent web app as a widget\n\nThe command below launches the Docs Agent web app to use\na widget-friendly template:\n\n```sh\nagent chatbot --app_mode widget\n```\n\n### Launch the Docs Agent web app in full mode\n\nThe command below launches the Docs Agent web app to use\na special template that uses three Gemini models (AQA, Gemini 1.5,\nand Gemini 1.0):\n\n```sh\nagent chatbot --app_mode full\n```\n\n### Launch the Docs Agent web app with a log view enabled\n\nThe command below launches the Docs Agent web app while enabling\na log view page (which is accessible at `<APP_URL>/logs`):\n\n```sh\nagent chatbot --enable_show_logs\n```\n\n## Running benchmark test\n\n### Run the Docs Agent benchmark test\n\nThe command below runs benchmark test using the questions and answers listed\nin the [`benchmarks.yaml`][benchmarks-yaml] file:\n\n```sh\nagent benchmark\n```\n\n## Interacting with language models\n\n### Ask a question\n\nThe command below reads a question from the arguments, asks the Gemini model,\nand prints its response:\n\n```sh\nagent tellme <QUESTION>\n```\n\nReplace `QUESTION` with a question written in plain English, for example:\n\n```sh\nagent tellme does flutter support material design 3?\n```\n\n**Note**: This `agent tellme` command is used to set up the `gemini` command\nin the [Set up Docs Agent CLI][set-up-docs-agent-cli] guide.\n\n### Ask a question to a specific product\n\nThe command below enables you to ask a question to a specific product in your\nDocs Agent setup:\n\n```sh\nagent tellme <QUESTION> --product <PRODUCT>\n```\n\nThe example below asks the question to the `Flutter` product in your\nDocs Agent setup:\n\n```sh\nagent tellme which modules are available? --product=Flutter\n```\n\nYou may also specify multiple products, for example:\n\n```sh\nagent tellme which modules are available? --product=Flutter --product=Angular --product=Android\n```\n\n### Ask for advice\n\nThe command below reads a request and a filename from the arguments,\nasks the Gemini model, and prints its response:\n\n```sh\nagent helpme <REQUEST> --file <PATH_TO_FILE>\n```\n\nReplace `REQUEST` with a prompt and `PATH_TO_FILE` with a file's\nabsolute or relative path, for example:\n\n```sh\nagent helpme write comments for this C++ file? --file ../my-project/test.cc\n```\n\nYou can also provide multiple files for the same request, for example:\n\n```sh\nagent helpme summarize the content of this file? --file ../my-project/example_01.md --file ../my-project/example_02.md --file ~/my-new-project/example.md\n```\n\n### Ask for advice using RAG\n\nThe command below uses a local or online vector database (specified in\nthe `config.yaml` file) to retrieve relevant context for the request:\n\n```sh\nagent helpme <REQUEST> --file <PATH_TO_FILE> --rag\n```\n\n### Ask for advice in a session\n\nThe command below starts a new session (`--new`), which tracks responses,\nbefore running the `agent helpme` command:\n\n```sh\nagent helpme <REQUEST> --file <PATH_TO_FILE> --new\n```\n\nFor example:\n\n```sh\nagent helpme write a draft of all features found in this README file? --file ./README.md --new\n```\n\nAfter starting a session, use the `--cont` flag to include the previous\nresponses as context to the request:\n\n```sh\nagent helpme <REQUEST> --cont\n```\n\nFor example:\n\n```sh\nagent helpme write a concept doc that delves into more details of these features? --cont\n```\n\n### Print the context in the current session\n\nThe command below prints the questions, files, and responses that\nare being used as context in the current session:\n\n```sh\nagent show-session\n```\n\n### Ask the model to perform the request to each file in a directory\n\nThe command below applies the request to each file found in the\nspecified directory:\n\n```sh\nagent helpme <REQUEST> --perfile <PATH_TO_DIRECTORY>\n```\n\nFor example:\n\n```sh\nagent helpme explain what this file does? --perfile ~/my-project --new\n```\n\n### Ask the model to include all files in a directory as context\n\nThe command below includes all files found in the specified directory\nas context to the request:\n\n```sh\nagent helpme <REQUEST> --allfiles <PATH_TO_DIRECTORY>\n```\n\nFor example:\n\n```sh\nagent helpme write a concept doc covering all features in this project? --allfiles ~/my-project --new\n```\n\n### Ask the model to read a list of file names from an input file\n\nSimilar to the `--perfile` flag, the command below reads the input\nfile that contains a list of filenames and applies the request to\neach file in the list:\n\n```sh\nagent helpme <REQUEST> --list_file <PATH_TO_FILE>\n```\n\nFor example:\n\n```sh\nagent helpme write an alt text string for this image? --list_file ./mylist.txt\n```\n\nwhere the `mylist.txt` file contains a list of file names in plain text\nas shown below:\n\n```none\n$ cat mylist.txt\ndocs/images/apps-script-screenshot-01.png\ndocs/images/docs-agent-ui-screenshot-01.png\ndocs/images/docs-agent-embeddings-01.png\n```\n\n### Ask the model to print the output in JSON\n\nThe command below prints the output from the model in JSON format:\n\n```sh\nagent helpme <REQUEST> --response_type json\n```\n\nFor example:\n\n```sh\nagent helpme how do I cook pasta? --response_type json\n```\n\n### Ask the model to run a pre-defined chain of prompts\n\nThe command below runs a task (a sequence of prompts) defined in\na `.yaml` file stored in the [`tasks`][tasks-dir] directory:\n\n```sh\nagent runtask --task <TASK>\n```\n\nFor example:\n\n```sh\nagent runtask --task DraftReleaseNotes\n```\n\n### View the list of available Docs Agent tasks\n\nTo see the list of all tasks available in your project, run\n`agent runtask` without any arguments:\n\n```sh\nagent runtask\n```\n\n### Ask the model to run a task using custom input\n\nIf a task script has a `<INPUT>` placeholder, you can provide\na custom input string to the task:\n\n```sh\nagent runtask --task <TASK> --custom_input <INPUT_STRING>\n```\n\nFor example:\n\n```sh\nagent runtask --task IndexPageGenerator --custom_input ~/my_example/docs/development/\n```\n\n### Ask the model to print the output in plain text\n\nBy default, the `agent runtask` command uses Python's Rich console\nto format its output. You can disable it by using the `--plaintext`\nflag:\n\n```sh\nagent runtask --task <TASK> --plaintext\n```\n\nFor example:\n\n```sh\nagent runtask --task DraftReleaseNotes --plaintext\n```\n\n## Managing online corpora\n\n### List all existing online corpora\n\nThe command below prints the list of all existing online corpora created\nusing the [Semantic Retrieval API][semantic-api]:\n\n```sh\nagent list-corpora\n```\n\n### Share an online corpora with a user\n\nThe command below enables `user01@gmail.com` to read text chunks stored in\n`corpora/example01`:\n\n```sh\nagent share-corpus --name corpora/example01 --user user01@gmail.com --role READER\n```\n\nThe command below enables `user01@gmail.com` to read and write to\n`corpora/example01`:\n\n```sh\nagent share-corpus --name corpora/example01 --user user01@gmail.com --role WRITER\n```\n\n### Share an online corpora with everyone\n\nThe command below enables `EVERYONE` to read text chunks stored in\n`corpora/example01`:\n\n```sh\nagent open-corpus --name corpora/example01\n```\n\n### Remove a user permission from an online corpora\n\nThe command below remove an existing user permission set in `corpora/example01`:\n\n```sh\nagent remove-corpus-permission --name corpora/example01/permissions/123456789123456789\n```\n\n### Delete an online corpora\n\nThe command below deletes an online corpus:\n\n```sh\nagent delete-corpus --name corpora/example01\n```\n\n### Interact with the model using external tools\n\nThe command below sends your prompt to the Gemini model and allows the model to\nuse configured external tools (through MCP servers defined in `config.yaml`) to\nfulfill the request.\n\nNote: You can use a `-v` flag to enable verbose mode to see the tool execution.\n\n```sh\nagent tools <PROMPT>\n```\n\n<!-- Reference links -->\n\n[config-yaml]: ../config.yaml\n[benchmarks-yaml]: ../docs_agent/benchmarks/benchmarks.yaml\n[set-up-docs-agent-cli]: ../docs_agent/interfaces/README.md\n[semantic-api]: https://ai.google.dev/docs/semantic_retriever\n[tasks-dir]: ../tasks\n\n\n=== examples/gemini/python/docs-agent/apps_script/README.md ===\n# Convert Google Docs, PDF, and Gmail to Markdown files\n\nThe collection of scripts in this `apps_script` directory allows you to convert\nthe contents of Google Drive folders and Gmail to Markdown files that are\ncompatible with Docs Agent.\n\nThe steps are:\n\n1. [Prepare a Google Drive folder](#1_prepare-a-google-driver-folder).\n2. [Mount Google Drive on your host machine](#2_mount-google-drive-on-your-host-machine).\n3. [Create an Apps Script project](#3_create-an-apps-script-project).\n4. [Edit and run main.gs on Apps Script](#4_edit-and-run-main_gs-on-apps-script).\n5. [Update config.yaml to include the mounted directory](#5_update-config_yaml-to-include-the-mounted-directory).\n\n## 1. Prepare a Google Drive folder\n\nFirst, create a new folder in Google Drive and add your Google Docs (which will be\nused as source documents to Docs Agent) to the folder.\n\nDo the following:\n\n1. Browser to https://drive.google.com/.\n1. Click **+ New** on the top left corner.\n1. Click **New folder**.\n1. Name your new folder (for example, `my source Google Docs`).\n1. To enter the newly created folder, double click the folder.\n1. Add (or move) your source Google Docs to this new folder.\n\n## 2. Mount Google Drive on your host machine\n\nMount your Google Drive to your host machine, so that it becomes easy to access the\nfolders in Google Drive from your host machine (later in step 5).\n\nThere are a variety of methods and tools available online that enable this setup\n(for example, see [`google-drive-ocamlfuse`][google-drive-ocamlfuse] for Linux machines).\n\n## 3. Create an Apps Script project\n\nCreate a new Apps Script project and copy all the `.gs` scripts in this\n`apps_script` directory to your new Apps Script project.\n\nDo the following:\n\n1. Browse to https://script.google.com/.\n1. Click **New Project**.\n1. At the top of the page, click **Untitled Project** and enter a meaningful\n   title (for example, `gDocs to Docs Agent`).\n1. Click the **+** icon next to **Files**.\n1. Click **Script**.\n1. Name the new script to be one of the `.gs` files in this `apps_script` directory\n   (for example, `drive_to_markdown`).\n1. Copy the content of the `.gs` file to the new script on your Apps Script project.\n1. To save, click the \"Save project\" icon in the toolbar.\n1. Repeat the steps until all the `.gs` files are copied to your Apps Script project.\n1. Click the **+** icon next to **Services**.\n1. Scroll down and click **Drive API**.\n1. Select **v2**.\n1. Click **Add**.\n\nYou are now ready to edit the parameters on the `main.gs` file to select a folder\nin Google Drive and export emails from Gmail.\n\n![Apps Script project](../docs/images/apps-script-screenshot-01.png)\n\n**Figure 1**. A screenshot of an example Apps Script project.\n\n## 4. Edit and run main.gs on Apps Script\n\nEdit the `main.gs` file on your Apps Script project to select which functions\n(features) you want to run.\n\nDo the following:\n\n1. Browse to your project on https://script.google.com/.\n\n1. Open the `main.gs` file.\n\n1. In the `main` function, comment out any functions that you don't want to run\n   (see Figure 1):\n\n   * `convertDriveFolderToMDForDocsAgent(folderInput)`: This function converts\n     the contents of a Google Drive folder to Markdown files (currently only Google\n     Docs and PDF). Make sure to specify a valid Google Drive folder in the `folderInput`\n     variable. Use the name of the folder created in **step 1** above, for example:\n\n     ```\n     var folderInput = \"my source Google Docs\"\n     function main() {\n       convertDriveFolderToMDForDocsAgent(folderInput);\n       //exportEmailsToMarkdown(SEARCH_QUERY, folderOutput);\n     }\n     ```\n\n   * `exportEmailsToMarkdown(SEARCH_QUERY, folderOutput)`: This function converts\n     the emails returned from a Gmail search query into Markdown files. Make sure to\n     specify a search query in the `SEARCH_QUERY` variable. You can test this search\n     query directly in the Gmail search bar. Also, specify an output directory for the\n     resulting emails.\n\n1. To save, click the \"Save project\" icon in the toolbar.\n\n1. Click the \"Run\" icon in the toolbar.\n\n   When this script runs successfully, the Execution log panel prints output similar\n   to the following:\n\n   ```\n   9:55:59 PM\tNotice\tExecution completed\n   ```\n\n   Also, the script creates a new folder in your Google Drive and stores the converted\n   Markdown files in this folder. The name of this new folder has `-output` as a postfix.\n   For example, with the folder name `my source Google Docs`, the name of the new folder\n   is `my source Google Docs-output`.\n\n   With Google Drive mounted on your host machine in step 2, you can now directly access\n   this folder from the host machine, for example:\n\n   ```\n   user@hostname:~/DriveFileStream/My Drive/my source Google Docs-output$ ls\n   Copy_of_My_Google_Docs_To_Be_Converted.md\n   ```\n\n## 5. Update config.yaml to include the mounted directory\n\nOnce you have your Google Drive mounted on the host machine, you can now\nspecify one of its folders as an input source directory for Docs Agent.\n\nDo the following:\n\n1. In the Docs Agent project, open the [`config.yaml`][config-yaml] file\n   with a text editor.\n\n1. Specify your mounted Google Drive folder as an `input` group, for example:\n\n   ```\n   input:\n   - path: \"/usr/local/home/user01/DriveFileStream/My Drive/my source Google Docs-output\"\n     url_prefix: \"docs.google.com\"\n   ```\n\n   You **must** specify a value to the `url_prefix` field, such as `docs.google.com`.\n   Currently this value is used to generate hashes for the content.\n\n1. (**Optional**) Add an additional Google Drive folder for your exported emails,\n   for example:\n\n   ```\n   input:\n   - path: \"/usr/local/home/user01/DriveFileStream/My Drive/my source Google Docs-output\"\n     url_prefix: \"docs.google.com\"\n   - path: \"/usr/local/home/user01/DriveFileStream/My Drive/psa-output\"\n     url_prefix: \"mail.google.com\"\n   ```\n\n1. Save the changes in the `config.yaml` file.\n\nYou're all set with a new documentation source for Docs Agent. You can now follow the\ninstructions in the project's main [`README`][main-readme] file to launch the Docs Agent app.\n\n<!-- Reference links -->\n\n[config-yaml]: ../config.yaml\n[main-readme]: ../README.md\n[google-drive-ocamlfuse]: https://github.com/astrada/google-drive-ocamlfuse\n\n\n=== examples/gemini/python/docs-agent/docs_agent/preprocess/README.md ===\n# Processing source documents in Docs Agent\n\nThis `README` file provides information on the steps involved in the following two Python scripts,\nwhich are used to process source documents into plain text chunks and generate embeddings for\nvector databases:\n\n- [`files_to_plain_text.py`][files-to-plain-text]\n- [`populate_vector_database.py`][populate-vector-database]\n\n![Docs Agent pre-processing flow](../../docs/images/docs-agent-pre-processing-01.png)\n\n**Figure 1**. Docs Agent's pre-processing flow from source documents to the vector database.\n\n**Note**: The `markdown_to_plain_text.py` script is deprecated in favor of\nthe `files_to_plain_text.py` script.\n\n## Docs Agent chunking technique example\n\nThe [`files_to_plain_text.py`][files-to-plain-text] script splits documents\ninto smaller chunks based on Markdown headings (#, ##, and ###).\n\nFor example, consider the following Markdown page:\n\n```\n# Page title\n\nThis is the introduction paragraph of this page.\n\n## Section 1\n\nThis is the paragraph of section 1.\n\n### Sub-section 1.1\n\nThis is the paragraph of sub-section 1.1.\n\n### Sub-section 1.2\n\nThis is the paragraph of sub-section 1.2.\n\n## Section 2\n\nThis is the paragraph of section 2.\n```\n\nThis example Markdown page is split into the following 5 chunks:\n\n```\n# Page title\n\nThis is the introduction paragraph of this page.\n```\n\n```\n## Section 1\n\nThis is the paragraph of section 1.\n```\n\n```\n### Sub-section 1.1\n\nThis is the paragraph of sub-section 1.1.\n```\n\n```\n### Sub-section 1.2\n\nThis is the paragraph of sub-section 1.2.\n```\n\n```\n## Section 2\n\nThis is the paragraph of section 2.\n```\n\nAdditionally, becasue the token size limitation of embedding models, the script\nrecursively splits the chunks above until each chunk's size becomes less than\n5000 bytes (characters).\n\n## Steps in the files_to_plain_text.py script\n\nIn the default setting, when processing Markdown files to plain text using the\n[`files_to_plain_text.py`][files-to-plain-text] script, the following events take place:\n\n1. Read the configuration file ([`config.yaml`][config-yaml]) to identify input and output\n   directories.\n1. Construct an array of input sources (which are the `path` entries).\n1. **For** each input source, do the following:\n   1. Extract all input fields (`path`, `url_prefix`, and more).\n   1. Call the `process_files_from_input()` method using these input fields.\n   1. **For** each sub-path in the input directory and **for** each file in these directories:\n      1. Check if the file extension is `.md` (that is, a Markdown file).\n      1. Construct an output directory that preserves the path structure.\n      1. Read the content of the Markdown file.\n      1. Call the `process_page_and_section_titles()` method to reformat the page and section\n         titles.\n         1. Process Front Matter in Markdown.\n         1. Detect (or construct) the title of the page.\n         1. Detect Markdown headings (#, ##, and ###).\n         1. Convert Markdown headings into plain English (to preserve context when generating\n            embeddings).\n      1. Call the `process_document_into_sections()` method to split the content into small\n         text chunks.\n         1. Create a new empty array.\n         1. Divide the content using Markdown headings (#, ##, and ###).\n         1. Insert each chunk into the array and simplify the heading to # (title).\n         1. Return the array.\n      1. **For** each text chunk, do the following:\n         1. Call the `markdown_to_text()` method to clean up Markdown and HTML syntax.\n            1. Remove `<!-- -->` lines in Markdown.\n            1. Convert Markdown to HTML (which makes the plan text extraction easy).\n            1. Use `BeautifulSoup` to extract plain text from the HTML.\n            1. Remove `[][]` in Markdown.\n            1. Remove `{: }` in Markdown.\n            1. Remove `{. }` in Markdown.\n            1. Remove a single line `sh` in Markdown.\n            1. Remove code text and blocks.\n            1. Return the plain text.\n         1. Construct the text chunk’s metadata (including URL) for the `file_index.json` file.\n         1. Write the text chunk into a file in the output directory.\n\n## Steps in the populate_vector_database.py script\n\nWhen processing plain text chunks to embeddings using the\n[`populate_vector_database.py`][populate-vector-database] script, the following events take place:\n\n1. Read the configuration file ([`config.yaml`][config-yaml]) to identify the plain text directory\n   and Chroma settings.\n1. Set up the Gemini API environment.\n1. Select the embeddings model.\n1. Configure the embedding function (including the API call limit).\n1. **For** each sub-path in the plain text directory and **for** each file in these directories:\n   1. Check if the file extension is `.md` (that is, a Markdown file).\n   1. Read the content of the Markdown file.\n   1. Construct the URL of the text chunk’s source.\n   1. Read the metadata associated with the text chunk file.\n   1. Store the text chunk and metabase to the vector database, which also generates an embedding\n      for the text chunk at the time of insertion.\n   1. Skip if the file size is larger than 5000 bytes (due to the API limit).\n   1. Skip if the text chunk is already in the vector database and the checksum hasn’t changed.\n\n### Delete chunks process\n\nThe process below describes how the delete chunks feature is implemented in the\n`populate_vector_database.py` script:\n\n1. Read all exiting entries in the target database.\n2. Read all candidate entries in the `file_index.json` file (created after running the\n   `agent chunk` command).\n3. For each entry in the existing entries found in step 1:\n\n   Compare the `text_chunk_filename` fields (included in the entry's `metadata`).\n\n   1. If not found in the candidate entires in step 2, delete this entry in the database.\n\n   1. If found, compare  the `md_hash` fields:\n\n      If they are different, delete this entry in the database.\n\n<!-- Reference links -->\n\n[files-to-plain-text]: files_to_plain_text.py\n[populate-vector-database]: populate_vector_database.py\n[config-yaml]: ../../config.yaml\n\n\n=== examples/gemini/python/docs-agent/docs_agent/benchmarks/README.md ===\n# Benchmark test for monitoring the quality of embeddings and AI responses\n\nThis page explains how to run benchmark test to measure and track\nthe quality of embeddings, context chunks, and AI-generated responses.\n\nDocs Agent’s benchmark test currently uses 10 questions and their\ntarget answers curated by technical writers (see\n[`benchmarks.yaml`][benchmarks-yaml]). The benchmark test asks these\n10 questions to an AI language model to generate responses. The test then\ncomputes the dot product of the embeddings (vectors) of these AI-generated\nresponses and the target answer to measure their similarity values\n(see Figure 1).\n\n![Docs Agent benchmark test](../../docs/images/docs-agent-benchmarks-01.png)\n\n**Figure 1**. The dot product of vectors is computed to measure their similarity.\n\n**Note**: The input questions and answers in the\n[`benchmarks.yaml`][benchmarks-yaml] file checked in the Docs Agent project are\nbased on the [FAQ][flutter-faq] page on the Flutter documentation site, whose\nsource Markdown files are available in this [Flutter repository][flutter-git]).\n\n## Set up and run the benchmark test\n\nTo set up and run benchmark test using Docs Agent, the steps are:\n\n1. [Prepare questions and target answers for your source docs](#1_prepare-questions-and-target-answers-for-your-source-docs).\n2. [Set up Docs Agent](#2_set-up-docs-agent).\n3. [Run the benchmark test](#3_run-the-benchmark-test).\n\n### 1. Prepare questions and target answers for your source docs\n\nList questions and target answers for your source docs in the `benchmarks.yaml`\nfile.\n\nAn example of a question and target answer pair:\n\n```none\n  - question: \"Does Flutter support Material Design?\"\n    target_answer: \"Yes! The Flutter and Material teams collaborate closely, and Material is fully supported. For more information, check out the Material 2 and Material 3 widgets in the widget catalog.\"\n```\n\nBased on the information documented in your source docs, come up\nwith a list of questions (`question`) and their expected answers\n(`target_answer`). It’s important that these answers are found in\nthe source docs and are produced by humans, not AI models.\n\nFor instance, the example [`benchmarks.yaml`][benchmarks-yaml] file includes\n10 questions and 10 target answers that are based on the source documents in\nthe [Flutter repository][flutter-git]. So if you plan on running benchmark\ntest using this `benchmarks.yaml` file, you need to configure your\nDocs Agent setup so that it uses the documents in the Flutter repository\nas a knowledge source, for example:\n\n```yaml\ninputs:\n  - path: \"/usr/local/home/user01/website/src\"\n    url_prefix: \"https://docs.flutter.dev\"\n```\n\n(Source: [`config.yaml`][config-yaml])\n\n### 2. Set up Docs Agent\n\nComplete the processing of your source docs into Docs Agent’s vector\ndatabase (by running the `agent chunk` and `agent populate` commands).\n\n**Note**: This benchmark testing uses the same `config.yaml` file as the\nchatbot app (that is, `condition_text`, `vector_db_dir`, and `log_level`\nvariables and so on). For instance, set `log_level` to `NORMAL`\nif you do not wish to see the details of prompts to the AI model while\nthe benchmark test is running.\n\n### 3. Run the benchmark test\n\nTo start benchmark test, run the following command from your Docs Agent\nproject home directory:\n\n```sh\nagent benchmark\n```\n\nThis command computes the similarity value for each question entry\nin the `benchmarks.yaml` file and writes the test results\nto the [`results.out`][results-out] file. If there already\nexists a `results.out` file, its content will be overwritten.\n\nAn example of test results:\n\n```none\nSimilarity (-1, 1)    Question\n==================    ========\n0.9693597667161213    What is inside the Flutter SDK?\n0.8810758779307981    Does Flutter work with any editors or IDEs?\n0.8760932771858571    Does Flutter come with a framework?\n0.8924252745816632    Does Flutter come with widgets?\n0.8637181105900334    Does Flutter support Material Design?\n0.9340505894484676    Does Flutter come with a testing framework?\n0.9192416276439515    Does Flutter come with debugging tools?\n0.7491969164696617    Does Flutter come with a dependency injection framework?\n0.7895399136265219    What technology is Flutter built with?\n0.7802681514431923    What language is Flutter written in?\n```\n\n**Note**: The similarity scores shown in the example above are\ncomputed using only a small set of documents processed from the\nFlutter respository. These scores may vary depending on which\ndocuments are added into Docs Agent's knowledge source.\n\n## How does this benchmark test work?\n\nWhen Docs Agent's benchmark test is run, the following events\ntake place:\n\n1. Read a `question` and `target_answer` entry from the\n   [`benchmarks.yaml`][benchmarks-yaml] file.\n2. Generate an embedding using `target_answer` (Embedding 1).\n3. Ask `question` to the AI model using the RAG technique.\n4. Generate an embedding using the AI-generated response\n   (Embedding 2).\n5. Compute the similarity between Embedding 1 and Embedding 2.\n6. Repeat the steps until all question entries are read.\n7. Print the test results to the [`results.out`][results-out] file.\n\n## How is the similarity value computed?\n\nTo measure the similarity, each benchmark test calculates the\ndot product of the embedding (vector) generated from the target\nanswer and the embedding generated from the AI response.\n\nAn example of a benchmark test result:\n\n```none\nQuestion:\nDoes Flutter come with debugging tools?\n\nTarget answer:\nYes, Flutter comes with Flutter DevTools (also called Dart DevTools). For more information, see Debugging with Flutter and the Flutter DevTools docs.\n\nAI Response:\nYes, Flutter has debugging tools. You can debug your app in a few ways:\n\n • Using DevTools, a suite of debugging and profiling tools that run in a browser and include the Flutter inspector.\n • Using Android Studio's (or IntelliJ's) built-in debugging features, such as the ability to set breakpoints.\n • Using the Flutter inspector, directly available in Android Studio and IntelliJ.\n\nSimilarity:\n0.9192416276439515\n```\n\nThis value estimates the similarity between the human-produced\nand machine-generated answers. The closer the value is to 1,\nthe more similar they are. (For more information , see the\n[Embedding guide][embedding-generation] page on the Gemini API\ndocumentation site.)\n\n<!-- Reference links -->\n\n[benchmarks-yaml]: benchmarks.yaml\n[config-yaml]: ../../config.yaml\n[flutter-faq]: https://docs.flutter.dev/resources/faq\n[flutter-git]: https://github.com/flutter/website/tree/main/src\n[results-out]: results.out\n[embedding-generation]: https://ai.google.dev/docs/embeddings_guide\n\n\n=== examples/gemini/python/docs-agent/docs_agent/interfaces/README.md ===\n# Set up Docs Agent CLI\n\nThis guide provides instructions on setting up Docs Agent's command-line\ninterface (CLI) on your host machine for running Docs Agent tasks.\n\nDocs Agent's `agent runtask` command allows you to run pre-defined chains of\nprompts, which are referred to as **tasks**. These tasks simplify complex\ninteractions by defining a series of steps that the Docs Agent will execute.\nThe tasks are defined in `.yaml` files stored in the [`tasks`][docs-agent-tasks]\ndirectory of your Docs Agent project. The tasks are designed to be reusable and\ncan be used to automate common workflows, such as generating release notes,\nupdating documentation, or analyzing complex information.\n\nTo set up the Docs Agent CLI, the steps are:\n\n1. [Prerequisites](#1-prerequisites)\n2. [Update your host machine's environment](#2-update-your-host-machines-environment)\n3. [Clone the Docs Agent project repository](#3-clone-the-docs-agent-project-repository)\n4. [Try the Docs Agent CLI](#4-try-the-docs-agent-cli)\n\n## 1. Prerequisites\n\nSetting up Docs Agent requires the following prerequisite items:\n\n- A Linux host machine\n\n- A [Google Cloud][google-cloud] project with an API key enabled with the\n  Generative Language API (that is, the [Gemini API][genai-doc-site])\n\n## 2. Update your host machine's environment\n\n1. Update the Linux package repositories on the host machine:\n\n   ```\n   sudo apt update\n   ```\n\n2. Install the following dependencies:\n\n   ```\n   sudo apt install git pipx python3-venv\n   ```\n\n3. Install `poetry`:\n\n   ```\n   pipx install poetry\n   ```\n\n4. To add `$HOME/.local/bin` to your `PATH` variable, run the following\n   command:\n\n   ```\n   pipx ensurepath\n   ```\n\n5. To set the Google API key as a environment variable, add the following\n   line to your `$HOME/.bashrc` file:\n\n   ```\n   export GOOGLE_API_KEY=<YOUR_API_KEY_HERE>\n   ```\n\n   Replace `<YOUR_API_KEY_HERE>` with the API key to the\n   [Gemini API][genai-doc-site].\n\n6. Update your environment:\n\n   ```\n   source ~/.bashrc\n   ```\n\n## 3. Clone the Docs Agent project\n\n**Note**: This guide assumes that you're creating a new project directory\nfrom your `$HOME` directory.\n\n1. Clone the following repo:\n\n   ```\n   git clone https://github.com/google/generative-ai-docs.git\n   ```\n\n2. Go to the Docs Agent project directory:\n\n   ```\n   cd generative-ai-docs/examples/gemini/python/docs-agent\n   ```\n\n3. Install dependencies using `poetry`:\n\n   ```\n   poetry install\n   ```\n\n4. Set up the Poetry environment:\n\n   ```\n   poetry env activate\n   ```\n\n5. Install the `shell` plugin:\n\n   ```\n   poetry self add poetry-plugin-shell\n   ```\n\n## 4. Try the Docs Agent CLI\n\n1. Enter the `poetry shell` environment:\n\n   ```\n   poetry shell\n   ```\n\n   **Important**: You must always enter the `poetry shell` environment\n   to run the `agent` command.\n\n2. Enable autocomplete for Docs Agent CLI options in your environment:\n\n   ```\n   source scripts/autocomplete.sh\n   ```\n\n3. Run the `agent helpme` command, for example:\n\n   ```\n   agent helpme how do I cook pasta?\n   ```\n\n   This command returns the Gemini model's response of your input prompt\n   `how do I cook pasta?`.\n\n4. View the list of Docs Agent tasks available in your setup:\n\n   ```\n   agent runtask\n   ```\n\n   This command prints a list of Docs Agent tasks that you can run.\n   (See the `tasks` directory in your local Docs Agent setup.)\n\n5. Run the `agent runtask` command, for example:\n\n   ```\n   agent runtask --task IndexPageGenerator\n   ```\n\nFor more details on these commands, see the\n[Interacting with language models][cli-reference-helpme] section in\nthe CLI reference page.\n\nFor creating a new task, see [Create a new Docs Agent task][create-a-new-task].\n\n## Appendix\n\n### Authorize credentials for Docs Agent\n\n**Note**: This step may not be necessary if you already have OAuth client\ncredentials (via `gcloud`) stored on your host machine.\n\nThis step is **only necessary** if you plan on using the\n`agent tellme` command to interact with your online corpora on Google Cloud.\n\nDo the following:\n\n1. Download the `client_secret.json` file from your\n   [Google Cloud project][authorize-credentials].\n\n2. Copy the `client_secret.json` file to your host machine.\n\n3. Install the Google Cloud SDK on your host machine:\n\n   ```\n   sudo apt install google-cloud-sdk\n   ```\n\n4. To authenticate credentials, run the following command in the directory of\n   the host machine where the `client_secret.json` file is located:\n\n   ```\n   gcloud auth application-default login --client-id-file=client_secret.json --scopes='https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/generative-language.retriever'\n   ```\n\n   This command opens a browser and asks to log in using your Google account.\n\n5. Follow the instructions on the browser and click **Allow** to authenticate.\n\n   This saves the authenticated credentials for Docs Agent\n   (`application_default_credentials.json`) in the `$HOME/.config/gcloud/`\n   directory of your host machine.\n\n### Set up an alias to the gemini command\n\nThis section provides instructions on setting up the Docs Agent CLI to enable\nyou to ask questions from anywhere in a terminal.\n\nUsing Docs Agent, you can configure your host machine's environment to make\nthe `gemini` command run from anywhere in your terminal. The `gemini` command\n(which is an `alias` to Docs Agent's `agent tellme` command) reads a question\nfrom the arguments, asks the [Gemini AQA][gemini-aqa] model, and prints its\nresponse in the terminal.\n\nThe example below shows that a user can run the `gemini` command directly\nfrom a terminal:\n\n```\nuser@user01:~$ gemini does Flutter support material design 3?\n\nAs of the Flutter 3.16 release, Material 3 is enabled by default.\n\nTo verify this information, see:\n\n • https://docs.flutter.dev/ui/design/material/index#more-information\n\nuser@user01:~$\n```\n\nIn this setup, Docs Agent's AQA model is configured to use an example\nonline corpus. However, using the tools available in the Docs Agent project,\nyou can [create and populate a new corpus][populate-corpus] with your own\ndocuments and adjust your Docs Agent configuration to use that corpus\ninstead – you can also [share the corpus][share-corpus] with other members\nin your team.\n\nTo update your shell environment so that the `gemini` command can be run\nfrom anywhere in the terminal, do the following:\n\n**Note**: If your Docs Agent project is not cloned in the `$HOME` directory,\nyou need to edit the `scripts/tellme.sh` script in your `docs-agent` project\ndirectory.\n\n1. (**Optional**) Open the `scripts/tellme.sh` file using a text editor,\n   for example:\n\n   ```\n   nano scripts/tellme.sh\n   ```\n\n   If necessary, adjust the path (`$HOME/docs-agent`) to match your\n   `docs-agent` project directory on the host machine:\n\n   ```\n   # IF NECESSARY, ADJUST THIS PATH TO YOUR `docs-agent` DIRECTORY.\n   docs_agent_dir=\"$HOME/docs-agent\"\n   ```\n\n   Save the file and close the text editor.\n\n2. Add the following `alias` line to your `$HOME/.bashrc` file:\n\n   ```\n   alias gemini='$HOME/docs-agent/scripts/tellme.sh'\n   ```\n\n   Similarly, if necessary, you need to adjust the path\n  (`$HOME/docs-agent`) to match your the `docs-agent` project directory\n   on the host machine.\n\n3. Update your environment:\n\n   ```\n   source ~/.bashrc\n   ```\n\n4. Now you can run the `gemini` command from anywhere in your terminal:\n\n   ```\n   gemini <QUESTION>\n   ```\n\n   For example:\n\n   ```\n   user@user01:~/temp$ gemini does flutter support material design 3?\n   ```\n\n### Set up your terminal to run the helpme command\n\n**Note**: This is an experimental setup.\n\nThis new feature allows you to freely navigate a codebase setup in your\nterminal and asks Gemini to perform various tasks while automatically\nreferencing the output you see in your terminal.\n\nSimilar to the `agent tellme` command, the `agent helpme` command allows you to\nask a question to Gemini directly from your terminal. However, unlike\nthe `tellme` command, the `helpme` command uses the Gemini Pro model\nand doesn't depend on an online corpus to retrieve relevant context.\nInstead, this `helpme` setup can read directly from the output of your terminal\n(that is, the last 150 lines at the moment) and automatically adds it as context\nto your prompt.\n\nThese tasks include, but not limited to:\n\n- Rewrite `README` file to be instructional and linear.\n- Rewrite `README` file to be more concise and better structured.\n- Format `README` to collect reference links at the bottom.\n- Write a protocol description.\n- Write comments for a C++ source file.\n\n**Note**: Since this setup uses the Gemini Pro model, setting up OAuth on your\nhost machine is **not required**.\n\nTo set up this `helpme` command in your terminal, do the following:\n\n1. (**Optional**) Open the `scripts/helpme.sh` file using a text editor,\n   for example:\n\n   ```\n   nano scripts/helpme.sh\n   ```\n\n   If necessary, adjust the path (`$HOME/docs-agent`) to match your\n   `docs-agent` project directory on the host machine:\n\n   ```\n   # IF NECESSARY, ADJUST THIS PATH TO YOUR `docs-agent` DIRECTORY.\n   docs_agent_dir=\"$HOME/docs-agent\"\n   ```\n\n   Save the file and close the text editor.\n\n2. Add the following `alias` lines to your `$HOME/.bashrc` file:\n\n   ```\n   alias gemini-pro='$HOME/docs-agent/scripts/helpme.sh'\n   alias start_agent='script -f -o 200MiB -O /tmp/docs_agent_console_input'\n   alias stop_agent='exit'\n   ```\n\n   Similarly, if necessary, you need to adjust the path\n  (`$HOME/docs-agent`) to match your the `docs-agent` project directory\n   on the host machine.\n\n3. Update your environment:\n\n   ```\n   source ~/.bashrc\n   ```\n\n4. When you are ready to let Docs Agent to read output from your terminal,\n   run the following command:\n\n   ```\n   start_agent\n   ```\n\n   **Note**: To stop this process, run `stop_agent`.\n\n5. Navigate to a directory in your terminal and use the `cat` command\n   (or `head` or `tail`) to print the content of a file to your terminal.\n\n   (In fact, you can run any command that prints output to the terminal.)\n\n   For example:\n\n   ```\n   user@user01:~/my-example-project$ cat test.cc\n   <prints the test.cc file here>\n   ```\n\n6. To use the latest output from your terminal, run the `gemini-pro` command\n   immediately after the output:\n\n   ```\n   gemini-pro <REQUEST>\n   ```\n\n   For example:\n\n   ```\n   user@user01:~/my-example-project$ cat test.cc\n   <prints the test.cc file here>\n   user@user01:~/my-example-project$ gemini-pro could you help me write comments for this C++ file above?\n   ```\n\n<!-- Reference links -->\n\n[gemini-aqa]: https://ai.google.dev/docs/semantic_retriever\n[populate-corpus]: ../preprocess/README.md\n[share-corpus]: https://ai.google.dev/docs/semantic_retriever#share_the_corpus\n[google-cloud]: https://console.cloud.google.com/\n[oauth-client]: https://ai.google.dev/docs/oauth_quickstart#set-cloud\n[authorize-credentials]: https://ai.google.dev/docs/oauth_quickstart#authorize-credentials\n[genai-doc-site]: https://ai.google.dev/docs/gemini_api_overview\n[cli-reference-helpme]: ../../docs/cli-reference.md#interacting-with-language-models\n[docs-agent-tasks]: ../../tasks\n[create-a-new-task]: ../../docs/create-a-new-task.md\n\n\n=== examples/gemini/javascript/langchain_quickstart_node/README.md ===\n# Gemini and LangChain.js quickstart (Node.js)\n\nThis example shows you how to invoke\n[Gemini](https://ai.google.dev/docs/gemini_api_overview) models using\n[LangChain.js](https://js.langchain.com/docs/get_started/introduction).\n\nTo learn more about the Google AI integration with LangChain.js, see the\nfollowing resources:\n\n* [LangChain.js: Google](https://js.langchain.com/docs/integrations/platforms/google)\n* [LangChain.js: ChatGoogleGenerativeAI](https://js.langchain.com/docs/integrations/chat/google_generativeai)\n* [LangChain.js: Text embedding models: Google AI](https://js.langchain.com/docs/integrations/text_embedding/google_generativeai)\n* [LangChain.js: GoogleGenerativeAIEmbeddings](https://api.js.langchain.com/classes/langchain_google_genai.GoogleGenerativeAIEmbeddings.html)\n\n## Setup\n\n1. Set the `GOOGLE_API_KEY` environment variable, replacing `<API_KEY>` with\nyour [API key](https://ai.google.dev/tutorials/setup):\n   ```\n   export GOOGLE_API_KEY=<API_KEY>\n   ```\n   If you don't already have an API key, you can create one through Google AI\n   Studio: [Get an API key](https://makersuite.google.com/app/apikey).\n\n   Note: If you don't want to set an environment variable, you can pass your API\n   key directly to the model:\n\n   ```javascript\n   const model = new ChatGoogleGenerativeAI({\n     apiKey: '<API_KEY>',\n     // ... other params\n   });\n   ```\n\n2. Download an image for testing:\n   ```\n   curl -o image.jpg https://t0.gstatic.com/licensed-image?q=tbn:ANd9GcQ_Kevbk21QBRy-PgB4kQpS79brbmmEG7m3VOTShAn4PecDU5H5UxrJxE3Dw1JiaG17V88QIol19-3TM2wCHw\n   ```\n\n3. Install the package dependencies:\n   ```\n   npm install\n   ```\n\n## Run\n\n```\nnpm start\n```\n\n## Learn more\n\nYou can also use the\n[Google AI JavaScript SDK](https://github.com/google/generative-ai-js) to\ninteract with Gemini. To learn more about using Gemini in your Node.js\napplications, see\n[Quickstart: Get started with the Gemini API in Node.js applications](https://ai.google.dev/tutorials/node_quickstart).\n\nTo learn more about the Gemini embedding service, see the\n[embeddings guide](https://ai.google.dev/docs/embeddings_guide).\n\n\n\n=== examples/gemini/node/pipet-code-agent/CHANGELOG.md ===\n# Change Log\n\nAll notable changes to the \"pipet-code-agent\" extension are documented in this file.\n\n## v0.0.1\n\n- Initial release. Provides commands for generating code comments and code reviews\n\n\n=== examples/gemini/node/pipet-code-agent/README.md ===\n# Pipet Code Agent\n\nPipet Code Agent is an AI-powered code assistance tool, built as an extension\nfor Microsoft [Visual Studio Code](https://code.visualstudio.com/) (VS Code).\nPipet uses the Google Gemini API to help you write code comments and review your\ncode by adding commands to the command pallete of VS Code.\n\n![pipet-code-agent](./pipet-snippet.png)\n\nPipet is provided as a development project, so you must configure and build\nit if you want to run it in your VS Code instance. For more information\nabout building, configuring, running, and extending this project, see the\n[Build AI Code Assistant with Pipet Code Agent](https://ai.google.dev/examples/pipet-code-agent) tutorial.\n\n## Project setup\n\nThese instructions walk you through getting the Pipet Code Agent project set up\nfor development and testing. The general steps are Installing some prerequisite\nsoftware, setting a few environment variables, cloning the project from the code\nrepository, and running the configuration installation.\n\nNote: You need a Google Gemini API Key to be able to run the project, which you\ncan obtain from the [Google Gemini API](https://ai.google.dev/tutorials/setup) page.\n\n### Install the prerequisites\n\nThe Pipet Code Agent project runs as an extension of Microsoft [Visual Studio\nCode](https://code.visualstudio.com/), and uses\n[Node.js](https://nodejs.org/) and npm to manage packages and run the\napplication. The following installation instructions are for a Linux host\nmachine.\n\nTo install the required software:\n\n1.  Install [Visual Studio Code](https://code.visualstudio.com/download)\n    for your platform.\n1.  Install `node` and `npm` by following the [installation\n    instructions](https://nodejs.org/) for your platform.\n\n### Clone and configure the project\n\nDownload the project code and use the `npm` installation command to download\nthe required dependencies and configure the project. You need\n[git](https://git-scm.com/) source control software to retrieve\nthe project source code.\n\nTo download and configure the project code:\n\n1.  Clone the git repository using the following command.\\\n    `git clone https://github.com/google/generative-ai-docs`\n1.  Optionally, configure your local git repository to use sparse checkout,\nso you have only the files for the Docs Agent project.\\\n    `cd generative-ai-docs/`\\\n    `git sparse-checkout init --cone`\\\n    `git sparse-checkout set examples/gemini/node/pipet-code-agent/`\n1.  Navigate to the Pipet Code Agent project root directory.\\\n    `cd generative-ai-docs/examples/gemini/node/pipet-code-agent/`\n1.  Run the install command to download dependencies and configure the project:\\\n    `npm install`\n\n### Configure and test the extension\n\nYou should now be able to test your installation by running Pipet Code Agent as\na development extension in VS Code on your device. The test opens a separate VS\nCode **Extension Development Host** window where the new extension is available.\nIn this new window, you configure the API Key the extension uses to access the\nGoogle Gemini API.\n\nTo configure and test your setup:\n\n1.  Start the VS Code application.\n1.  In VS Code, create a new window by selecting **File > New Window**.\n1.  Open the Pipet Code Agent project by selecting **File > Open Folder**,\n    and selecting the `pipet-code-agent/` folder.\n1.  Open the `pipet-code-agent/package.json` file.\n1.  Run the extension in debug mode by selecting **Run > Start Debugging**.\n    This step opens a separate VS Code **Extension Development Host** window.\n1.  Open the VS Code settings by selecting **Code > Settings > Settings**.\n1.  Get a [Google Gemini API Key](https://ai.google.dev/tutorials/setup)\n    from the Generative AI Developer site, and copy the key string.\n1.  Set the API key as a configuration setting. In **Search Settings**\n    field, type `pipet`, select the **User** tab, and in the **Google > Gemini\n    Api Key** setting, click the **Edit in settings.json** link, and add your\n    Gemini API key:\\\n    `\"google.gemini.apiKey\": \"your-api-key-here\"`\n1.  Save the changes to the `settings.json` file and close the settings tabs.\n\n**Caution:** Treat your API Key like a password and protect it appropriately. Don't\nembed your key in publicly published code.\n\nTo test the extension commands:\n\n1.  In the VS Code **Extension Development Host** window, select some code\n    in the editor window.\n1.  Open the command palette by selecting **View > Command Palette**.\n1.  In the Command Palette, type `Pipet` and select one of the commands with\n    that prefix.\n\n\n## Resources\n\n- Project code tutorial:\n[Build AI Code Assistant with Pipet Code Agent](https://ai.google.dev/examples/pipet-code-agent) tutorial.\n\n\n=== examples/gemini/node/pipet-code-agent/CONTRIBUTING.md ===\n# How to Contribute\n\nWe would love to accept your patches and contributions to this project.\n\n## Before you begin\n\n### Sign our Contributor License Agreement\n\nContributions to this project must be accompanied by a\n[Contributor License Agreement](https://cla.developers.google.com/about) (CLA).\nYou (or your employer) retain the copyright to your contribution; this simply\ngives us permission to use and redistribute your contributions as part of the\nproject.\n\nIf you or your current employer have already signed the Google CLA (even if it\nwas for a different project), you probably don't need to do it again.\n\nVisit <https://cla.developers.google.com/> to see your current agreements or to\nsign a new one.\n\n### Review our Community Guidelines\n\nThis project follows [Google's Open Source Community\nGuidelines](https://opensource.google/conduct/).\n\n## Contribution process\n\n### Code Reviews\n\nAll submissions, including submissions by project members, require review. We\nuse [GitHub pull requests](https://docs.github.com/articles/about-pull-requests)\nfor this purpose.\n\n=== examples/gemini/node/flutter_theme_agent/CHANGELOG.md ===\n# Change Log\n\nAll notable changes to the \"flutter-theme-agent\" extension will be documented in this file.\n\n## v0.0.1\n\n- Initial release. Provides commands for generating Flutter code for a ThemeData and the following components: ButtonStyle, ColorScheme, TextTheme.\n\n=== examples/gemini/node/flutter_theme_agent/README.md ===\n# Flutter Theme Agent\n\nFlutter Theme Agent is an AI-powered code assistance tool, built as an extension\nfor Microsoft [Visual Studio Code](https://code.visualstudio.com/) (VS Code).\nIt uses the Google Gemini API to help you generate \ncomponents of a Flutter theme, or ThemeData object, including color schemes,\ntext styles, and button styles.\n\n![flutter-theme-agent](./flutter-theme-agent.png)\n\nFlutter Theme Agent is provided as a development project, so you must configure and build\nit if you want to run it in your VS Code instance. For more information\nabout building, configuring, running, and extending this project, see the\n[Build an AI Flutter code generator with Gemini](https://ai.google.dev/examples/flutter-theme-agent) tutorial.\n\n## Project setup\n\nThese instructions walk you through getting the Flutter Theme Agent project set up\nfor development. The general steps are Installing some prerequisite\nsoftware, setting a few environment variables, cloning the project from the code\nrepository, and running the configuration installation.\n\nNote: You need a Google Gemini API Key to be able to run the project, which you\ncan obtain from the [Google Gemini API](https://ai.google.dev/tutorials/setup) page.\n\n### Install the prerequisites\n\nThe Flutter Theme Agent project runs as an extension of Microsoft [Visual Studio\nCode](https://code.visualstudio.com/), and uses\n[Node.js](https://nodejs.org/) and npm to manage packages and run the\napplication. The following installation instructions are for a Linux host\nmachine.\n\nTo install the required software:\n\n1.  Install [Visual Studio Code](https://code.visualstudio.com/download) for your platform.\n1.  Install `node` and `npm` by following the [installation instructions](https://nodejs.org/) for your platform.\n\n\n### Clone and configure the project\n\nDownload the project code and use the `npm` installation command to download\nthe required dependencies and configure the project. You need\n[git](https://git-scm.com/) source control software to retrieve the project\nsource code.\\\nTo download and configure the project code:\n\n1.  Clone the git repository using the following command.\\\n    `git clone https://github.com/google/generative-ai-docs`\n1.  Optionally, configure your local git repository to use sparse checkout,\nso you have only the files for the Docs Agent project.`\ncd generative-ai-docs/\\\ngit sparse-checkout init --cone\\\n    git sparse-checkout set examples/gemini/node/flutter_theme_agent/`\n1.  Navigate to the Flutter Theme Agent project root directory.\\\n    `cd generative-ai-docs/examples/gemini/node/flutter_theme_agent/`\n1.  Run the install command to download dependencies and configure the project:\\\n    `npm install`\n\n### Configure and test the extension\n\nYou should now be able to test your installation by running Flutter Theme Agent\nas a development extension in VS Code on your device. The test opens a separate\nVS Code **Extension Development Host** window where the new extension is\navailable. In this new window, you configure the API Key the extension uses to\naccess the Google Gemini API.\n\nCaution: Treat your API Key like a password and protect it appropriately.\nFor some general best practices on key security, review this\n[support article](https://support.google.com/googleapi/answer/6310037).\n\nTo configure and test your setup:\n\n1.  Start the VS Code application.\n1.  In VS Code, create a new window by selecting **File > New Window**.\n1.  Open the Flutter Theme Agent project by selecting **File > Open Folder**,\n    and selecting the `flutter_theme_agent/` folder.\n1.  In VS Code, open the `flutter_theme_agent/package.json` file.\n1.  Run the extension in debug mode by selecting **Run > Start Debugging**.\n    This step opens a separate VS Code **Extension Development Host** window.\n1.  Open the VS Code settings by selecting **Code > Settings > Settings**.\n1.  Get a\n    [Google Gemini API Key](https://developers.generativeai.google/tutorials/setup)\n    from the Generative AI Developer site, and copy the key string.\n1.  Set the API key as a configuration setting. In **Search Settings**\n    field, type `flutter theme`, select the **User** tab, and in the **Google >\n    Gemini: Api Key** setting, click the **Edit in settings.json** link, and\n    add your Gemini API key:\n      `\"google.ai.apiKey\": \"your-api-key-here\"`\n1.  Save the changes to the `settings.json` file and close the settings tabs.\n\n**Caution:** Treat your API Key like a password and protect it appropriately. Don't\nembed your key in publicly published code.\n\nTo test the extension commands:\n\n1.  In the VS Code **Extension Development Host** window, open a Flutter project.\n1.  In your code, write a comment that describes the component you want to generate code for. For example, `// a color scheme that is pink with beige background` and highlight that comment. \n1.  Open the command palette by selecting **View > Command Palette**.\n1.  In the Command Palette, type `Flutter Theme` and the command for the desired component.\n\n\n## Resources\n\n- Project code tutorial:\n[Build an AI Flutter code generator with Gemini](https://ai.google.dev/examples/flutter-theme-agent) tutorial.\n\n=== examples/gemini/node/flutter_theme_agent/CONTRIBUTING.md ===\n# How to Contribute\n\nWe would love to accept your patches and contributions to this project.\n\n## Before you begin\n\n### Sign our Contributor License Agreement\n\nContributions to this project must be accompanied by a\n[Contributor License Agreement](https://cla.developers.google.com/about) (CLA).\nYou (or your employer) retain the copyright to your contribution; this simply\ngives us permission to use and redistribute your contributions as part of the\nproject.\n\nIf you or your current employer have already signed the Google CLA (even if it\nwas for a different project), you probably don't need to do it again.\n\nVisit <https://cla.developers.google.com/> to see your current agreements or to\nsign a new one.\n\n### Review our Community Guidelines\n\nThis project follows [Google's Open Source Community\nGuidelines](https://opensource.google/conduct/).\n\n## Contribution process\n\n### Code Reviews\n\nAll submissions, including submissions by project members, require review. We\nuse [GitHub pull requests](https://docs.github.com/articles/about-pull-requests)\nfor this purpose.\n\n=== examples/palm/README.md ===\n# PaLM API examples\n\nHerein lies example code referenced by the PaLM API site.\n\nExamples are typically small, single-purpose code used to demonstrate one\nspecific concept. They should still compile but may be very minimal.\n\nLarger examples live in the [`demos/`](../../demos/palm) directory.\n\n\n\n=== site/en/README.md ===\n# Generative AI Developer Docs\n\nThese are the source files for the Generative AI and PaLM API site. The\nstructure from this directory mirrors the site from the root.\n\n\n=== demos/palm/README.md ===\n# PaLM API demos\n\nHerein lies demo apps referenced by the PaLM API site.\n\nDemos are considered to be larger than examples and consist of working apps.\n\nSmaller, specific examples can be found in the\n[`examples/`](../../examples/palm) directory.\n\n## Updates\n\nSome of these code projects have been updated and moved to the /examples/gemini directory, including:\n\n-   **Docs Agent** - /demos/palm/python/docs-agent/ moved to: \n    [/examples/gemini/python/docs-agent/](https://github.com/google/generative-ai-docs/tree/main/examples/gemini/python/docs-agent)\n-  **Pipet Code Agent** - /demos/palm/node/pipet-code-agent/ moved to: \n    [/examples/gemini/node/pipet-code-agent/](https://github.com/google/generative-ai-docs/tree/main/examples/gemini/node/pipet-code-agent)\n\n=== demos/palm/web/mood-food/CODE_OF_CONDUCT.md ===\n# Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to making participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, gender identity and expression, level of\nexperience, education, socio-economic status, nationality, personal appearance,\nrace, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n- Using welcoming and inclusive language\n- Being respectful of differing viewpoints and experiences\n- Gracefully accepting constructive criticism\n- Focusing on what is best for the community\n- Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n- The use of sexualized language or imagery and unwelcome sexual attention or\n  advances\n- Trolling, insulting/derogatory comments, and personal or political attacks\n- Public or private harassment\n- Publishing others' private information, such as a physical or electronic\n  address, without explicit permission\n- Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or reject\ncomments, commits, code, wiki edits, issues, and other contributions that are\nnot aligned to this Code of Conduct, or to ban temporarily or permanently any\ncontributor for other behaviors that they deem inappropriate, threatening,\noffensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies both within project spaces and in public spaces\nwhen an individual is representing the project or its community. Examples of\nrepresenting a project or community include using an official project e-mail\naddress, posting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event. Representation of a project may be\nfurther defined and clarified by project maintainers.\n\nThis Code of Conduct also applies outside the project spaces when the Project\nSteward has a reasonable belief that an individual's behavior may have a\nnegative impact on the project or its community.\n\n## Conflict Resolution\n\nWe do not believe that all conflict is bad; healthy debate and disagreement\noften yield positive results. However, it is never okay to be disrespectful or\nto engage in behavior that violates the project’s code of conduct.\n\nIf you see someone violating the code of conduct, you are encouraged to address\nthe behavior directly with those involved. Many issues can be resolved quickly\nand easily, and this gives people more control over the outcome of their\ndispute. If you are unable to resolve the matter for any reason, or if the\nbehavior is threatening or harassing, report it. We are dedicated to providing\nan environment where participants feel welcome and safe.\n\nReports should be directed to _[PROJECT STEWARD NAME(s) AND EMAIL(s)]_, the\nProject Steward(s) for _[PROJECT NAME]_. It is the Project Steward’s duty to\nreceive and address reported violations of the code of conduct. They will then\nwork with a committee consisting of representatives from the Open Source\nPrograms Office and the Google Open Source Strategy team. If for any reason you\nare uncomfortable reaching out to the Project Steward, please email\nopensource@google.com.\n\nWe will investigate every complaint, but you may not receive a direct response.\nWe will use our discretion in determining when and how to follow up on reported\nincidents, which may range from not taking action to permanent expulsion from\nthe project and project-sponsored spaces. We will notify the accused of the\nreport and provide them an opportunity to discuss it before any action is taken.\nThe identity of the reporter will be omitted from the details of the report\nsupplied to the accused. In potentially harmful situations, such as ongoing\nharassment or threats to anyone's safety, we may take action without notice.\n\n## Attribution\n\nThis Code of Conduct is adapted from the Contributor Covenant, version 1.4,\navailable at\nhttps://www.contributor-covenant.org/version/1/4/code-of-conduct/\n\n\n=== demos/palm/web/mood-food/README.md ===\n# LLM Demo - Mood Food\n\n![mood-food-header](./docs/mood_food_header.png)\n\nMood Food is a chatbot-based web application that can create a recipe based on the user's message. It is powered by PaLM, a large language model from Google. To use Mood Food, simply type in a message describing your mood or what you're in the mood for, and Mood Food will generate a recipe that matches your request.\n\nMood Food is a great way to find new recipes to try, and it's also a fun way to explore different cuisines and ingredients.\n\nSwiggy, an Indian online food ordering and delivery platform, expressed their excitement when considering the use cases made possible by experiences like MoodFood.\n\n**“We're excited about the potential of Generative AI to transform the way we interact with our customers and merchants on our platform. Moodfood has the potential to help us go deeper into the products and services we offer, in a fun and engaging way\" - Madhusudhan Rao, CTO, Swiggy**\n\nGoogle’s Partner Innovation team will also continue to build features and tools in partnership with local markets to expand on the R&D already underway.\n\n\n![mood-food-demo](./docs/mood_food_demo.gif)\n\n## Table of contents\n\n- [LLM Demo - Mood Food](#llm-demo---mood-food)\n  - [Table of contents](#table-of-contents)\n  - [How to install](#how-to-install)\n    - [Install node modules](#install-node-modules)\n    - [Edit environment variables](#edit-environment-variables)\n    - [Develop](#develop)\n    - [Build](#build)\n    - [How to host a static website on Google App Engine.](#how-to-host-a-static-website-on-google-app-engine)\n  - [How it works](#how-it-works)\n    - [LLM's prompt design](#llms-prompt-design)\n    - [Prompt generator #1](#prompt-generator-1)\n    - [Prompt generator #2](#prompt-generator-2)\n    - [Prompt generator #3](#prompt-generator-3)\n    - [Prompt generator #4](#prompt-generator-4)\n    - [LLM's response](#llms-response)\n\n## How to install\n\n### Install node modules\n\n```bash\nyarn\n```\n\n### Edit environment variables\n\nMake sure you have the following environment variables set in the `.env` file:\n\n```bash\nVITE_GOOGLE_GENERATIVE_LANGUAGE_API_KEY=<YOUR_GOOGLE_GENERATIVE_LANGUAGE_API_KEY>\n```\n\n### Develop\n\n```bash\nyarn dev\n```\n\n### Build\n\n```bash\nyarn build\n```\n\n### How to host a static website on Google App Engine.\n\nhttps://cloud.google.com/appengine/docs/legacy/standard/python/getting-started/hosting-a-static-website\n\n## How it works\n\n### LLM's prompt design\n\n![llm-prompt-design-diagram](./docs/llm_prompt_design_diagram.png)\n\n### Prompt generator #1\n\nIn the user's first turn, the user's input message `${msg}` will be formatted into this structure:\n\n```js\n{\n    author: '0',\n    content: `Hello!, the message is \"${msg}\". Answer the recipe in the format I provided. Do not include any words related to politics, religion, or race.`\n}\n```\n\nIn the user's subsequent turns, the user's input message `${msg}` will be formatted into this structure:\n\n```js\n{\n    author: '0',\n    content: `\"${msg}\". Answer the recipe in the format I provided. Do not include any words related to politics, religion, or race.`\n}\n```\n\nHere is the final structure of the prompt sending to the LLM #1:\n\n```js\n{\n    prompt: {\n        context: `I want you to act as a very creative chef who is an expert in foods and ingredients. In every user's message, you have to come up with an unimaginable recipe based on the user's message and any specific interests or preferences they may have. There can be more than one recipe based on the user's message. Answer in markdown format that includes only the following sections: \"reaction\", \"name\", \"ingredients\", \"instructions\", and \"description\". The \"reaction\" should be your humorous response to the user's message in a polite way. The \"name\" should be a possible name that plays with polite puns and does not offend anyone. The \"ingredients\" section should be a list of ingredients with their measurements. The \"instructions\" section should be a step-by-step guide on how to cook the recipe. The \"description\" should be the food description introduced by you as the funny chef. Do not include \"variations\" and \"tips\". Do not use the user's hated ingredients in the recipe. When the user asks for changing the ingredients, please make an update to the latest recipe`,\n        messages: [\n            {\n                author: '0',\n                content: `Hello!, the message is \"${msg}\". Answer the recipe in the format I provided. Do not include any words related to politics, religion, or race.`\n            },\n            ...\n        ]\n    },\n    temperature: 0.75,\n    candidate_count: 1,\n}\n```\n\n- The `context` is the context of the conversation. It is used to give the LLM a better understanding of the conversation.\n- The `messages` is an array of chat messages from past to present alternating between the user (author=0) and the LLM (author=1). The first message is always from the user.\n- The `temperature` is a float number between 0 and 1. The higher the temperature, the more creative the response will be. The lower the temperature, the more likely the response will be a correct one.\n- The `candidate_count` is the number of responses that the LLM will return.\n\n### Prompt generator #2\n\nThis is for LLM #2 (Reaction JSON formatter). It will be used as a subsequent call to LLM #1. In every user's turn, the user's input message and the result from LLM #1 will be formatted into this structure and send to the LLM #2:\n\n````js\n{\n    prompt: {\n        messages: [\n            {\n                author: '0',\n                content: <the_latest_user_msg_llm_1>\n            },\n            {\n                author: '1',\n                content: <the_latest_llm_1_response>\n            },\n            {\n                author: '0',\n    content: 'Rewrite only the \"Reaction\" response into this JSON format: ```{\"reaction\":string}```'\n            }\n        ]\n    },\n    temperature: 0.0,\n    candidate_count: 1\n}\n````\n\n- The `messages` is an array of the latest user-LLM conversation pair concatenated with the author-0 message asking for reaction JSON formatting.\n\n### Prompt generator #3\n\nThis is for LLM #3 (Dish name safeguarding). It will be used as a subsequent call to LLM #1. In every user's turn, the user's input message and the result from LLM #1 will be formatted into this structure and send to the LLM #3:\n\n````js\n{\n    prompt: {\n        messages: [\n            {\n                author: '0',\n                content: <the_latest_user_msg_llm_1>\n            },\n            {\n                author: '1',\n                content: <the_latest_llm_1_response>\n            },\n            {\n                author: '0',\n    content: 'Rewrite only the \"Name\" response into this JSON format: ```{\"recipes\":[{\"name\":string},{...}]}```. Make sure that there are no words related to politics, religion, or race.'\n            }\n        ]\n    },\n    temperature: 0.1,\n    candidate_count: 1\n}\n````\n\n- The `messages` is an array of the latest user-LLM conversation pair concatenated with the author-0 message asking for dish name safeguarding JSON formatting.\n\n### Prompt generator #4\n\nThis is for LLM #4 (Recipes JSON formatter). It will be used as a subsequent call to LLM #1. In every user's turn, the user's input message and the result from LLM #1 will be formatted into this structure and send to the LLM #4:\n\n````js\n{\n    prompt: {\n        messages: [\n            {\n                author: '0',\n                content: <the_latest_user_msg_llm_1>\n            },\n            {\n                author: '1',\n                content: <the_latest_llm_1_response>\n            },\n            {\n                author: '0',\n    content: 'You have to rewrite your response into this JSON format: ```{\"recipes\":[{\"name\":string,\"course\":string,\"ingredients\":[]string,\"instructions\":[]string,\"description\":string},...,{...}]}```'\n            }\n        ]\n    },\n    temperature: 0.0,\n    candidate_count: 1\n}\n````\n\n- The `messages` is an array of the latest user-LLM conversation pair concatenated with the author-0 message asking for recipes JSON formatting.\n\n### LLM's response\n\nThe output of the LLM is in this structure:\n\n```js\n{\n    candidates: [\n        {\n            author: '1',\n            content: 'This is the response content from the LLM.'\n        }\n    ],\n    messages: [\n        ...\n    ]\n}\n```\n\n- The `candidates` is an array of responses from the LLM. This project has only one response per turn (as candidate_count=1).\n- The `messages` is an array of chat messages from past to present alternating between the user (author=0) and the LLM (author=1). The first message is always from the user.\n\n\n=== demos/palm/web/mood-food/CONTRIBUTING.md ===\n# How to Contribute\n\nWe would love to accept your patches and contributions to this project.\n\n## Before you begin\n\n### Sign our Contributor License Agreement\n\nContributions to this project must be accompanied by a\n[Contributor License Agreement](https://cla.developers.google.com/about) (CLA).\nYou (or your employer) retain the copyright to your contribution; this simply\ngives us permission to use and redistribute your contributions as part of the\nproject.\n\nIf you or your current employer have already signed the Google CLA (even if it\nwas for a different project), you probably don't need to do it again.\n\nVisit <https://cla.developers.google.com/> to see your current agreements or to\nsign a new one.\n\n### Review our Community Guidelines\n\nThis project follows [Google's Open Source Community\nGuidelines](https://opensource.google/conduct/).\n\n## Contribution process\n\n### Code Reviews\n\nAll submissions, including submissions by project members, require review. We\nuse [GitHub pull requests](https://docs.github.com/articles/about-pull-requests)\nfor this purpose.\n\n\n=== demos/palm/web/list-it/README.md ===\n# List It\n\nBy Google Creative Lab\n\n## Contents\n\n- [About](#about)\n- [How it Works](#how-it-works)\n- [Requirements](#requirements)\n- [Developer Setup](#developer-setup)\n- [Contributors](#contributors)\n- [License](#license)\n- [Notes](#notes)\n\n## About\n\n_List It_ is a simple app where a user can input a goal or task and have a generative language model output a list of subtasks related to that query.\n\n![List It demo gif](https://storage.googleapis.com/experiments-uploads/list-it/list-it.gif)\n\nThis demo is an example of how you can use the PaLM API to build applications that leverage Google’s state of the art large language models (LLMs).\n\nThe PaLM API consists of two APIs, each with a distinct method for generating content:\n\n- The Chat API can be used to generate candidate `Message` responses to input messages via the `generateMessage()` function.\n- The Text API can be used to generate candidate `TextCompletion` responses to input strings via the `generateText()` function.\n\nThis demo uses the Text API. If you’re looking for a demo that uses the Chat API, see [_Quick, Prompt!_](https://github.com/google/generative-ai-docs/tree/main/demos/palm/web/quick-prompt).\n\n## How it Works\n\nWe can prime the model to behave in a certain way using a carefully crafted string of text called a __prompt__. It’s helpful to think of the model as a highly sophisticated text-completion engine: given the context we provide in our prompt, the model tries to output a feasible continuation or completion of that string.\n\nBelow is an example of a simple text prompt:\n\n```\nFor each animal below, the animal's color is given.\nAnimal: crab\nColor: red\nAnimal: frog\nColor: green\nAnimal: blue jay\nColor: blue\nAnimal: flamingo\nColor:\n```\n\nIf we send the above string to the model, we might expect the model to output “pink” (likely followed by additional animals and their respective colors). Adapting this prompt to generate the color of a different animal is simply a matter of replacing “flamingo” with the desired animal. Each complete (animal, color) pair in the prompt can be thought of as an __example__—it often only takes a few examples to establish a pattern that the model can follow.\n\n_List It_ uses this same mechanism to prime the model to generate a list from a user input. You can find the prompt in `/src/lib/priming.js`.\n\n## Requirements\n\n- Node.js (version 18.15.0 or higher)\n- Firebase project\n\nMake sure you have either `npm` or `yarn` set up on your machine.\n\n## Developer Setup\n\nAlthough the PaLM API provides a [REST resource](https://developers.generativeai.google/api/rest/generativelanguage/models?hl=en), it is best practice to avoid embedding API keys directly into code (or in files inside your application’s source tree). If you want to call the PaLM API from the client side as we do in this demo, we recommend using a Firebase project with the Call PaLM API Securely extension enabled.\n\nTo set up Firebase:\n\n1. Create a Firebase project at https://console.firebase.google.com.\n\n2. Add a web app to your Firebase project and follow the on-screen instructions to add or install the Firebase SDK.\n\n3. Go to https://console.cloud.google.com and select your Firebase project. Then go to _Security > Secret Manger_ using the left-side menu and make sure the Secret Manager API is enabled.\n\n4. If you don’t already have an API key for the PaLM API, follow [these instructions](https://developers.generativeai.google/tutorials/setup) to get one.\n\n5. Install the Call PaLM API Securely extension from the [Firebase Extensions Marketplace](https://extensions.dev/extensions). Follow the on-screen instructions to configure the extension.\n\n    __NOTE__: Your project must be on the Blaze (pay as you go) plan to install the extension.\n\n6. Enable anonymous authentication for your Firebase project by returning to https://console.firebase.google.com and selecting _Build_ in the left panel. Then go to _Authentication > Sign-in method_ and make sure _Anonymous_ is enabled.\n\n7. Return to https://console.cloud.google.com and select your Firebase project. Click _More Products_ at the bottom of the left-side menu, then scroll down and click _Cloud Functions_. Select each function and then click _Permissions_ at the top. Add `allUsers` to the Cloud Functions Invoker role.\n\nThe above instructions assume that this demo will be used for individual/experimental purposes. If you anticipate broader usage, enable App Check in the Firebase extension during installation and see https://firebase.google.com/docs/app-check for an in-depth implementation guide.\n\nTo run the application locally:\n\n1. Clone the repo to your local machine.\n\n2. Run `npm i` or `yarn` in the root folder to install dependencies.\n\n3. Add your Firebase info to `src/lib/firebase.config.js`.\n\n4. Run `npm run dev` or `yarn dev` to start the application. The application will be served on localhost:5555. You can change the port in `vite.config.js` if desired.\n\n## Contributors\n\n- [Aaron Wade](https://github.com/aaron-wade)\n- [Pixel Perfect Development](https://github.com/madebypxlp)\n\n## License\n\n[Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0)\n\n## Notes\n\nThis is not an official Google product, but rather a demo developed by the Google Creative Lab. This repository is meant to provide a snapshot of what is possible at this moment in time, and we do not intend for it to evolve.\n\nWe encourage open sourcing projects as a way of learning from each other. Please respect our and other creators’ rights—including copyright and trademark rights (when present)—when sharing these works or creating derivative work. If you want more info about Google's policies, you can find that [here](https://about.google/brand-resource-center/).\n\n=== examples/gemini/python/docs-agent/scripts/extract_image_files.py ===\n#\n# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\"\"\"\nThis script extracts image paths from markdown, html, or directory of files.\n\nUsage:\n  python extract_image_files.py <input_file>\n\nExample:\n  python extract_image_files.py my_document.md\n  python extract_image_files.py my_document.html\n  python extract_image_files.py my_documents_folder\n\"\"\"\nimport os\nimport sys\nfrom absl import logging\n\nfrom docs_agent.preprocess.extract_image_path import extract_image_path_from_html\nfrom docs_agent.preprocess.extract_image_path import extract_image_path_from_markdown\nfrom docs_agent.utilities.helpers import resolve_path\n\n\ndef main(input: str = sys.argv[1]):\n  \"\"\"\n  Extracts image paths from markdown, html, or directory of files.\n\n  Args:\n      input: The path to the input file.\n  \"\"\"\n  dir_name = \"agent_out\"\n  if input.startswith(\"~/\"):\n    input = os.path.expanduser(input)\n  input = os.path.realpath(os.path.join(os.getcwd(), input))\n  content = \"\"\n  if os.path.isdir(input):\n    for root, _, files in os.walk(resolve_path(input)):\n      for file in files:\n        file_path = os.path.realpath(os.path.join(root, file))\n        content += parse_files(file_path)\n  else:\n    content += parse_files(input)\n  if not os.path.exists(dir_name):\n    os.makedirs(dir_name)\n  save_file(dir_name + \"/image_paths.txt\", content)\n\n\ndef parse_files(input: str) -> str:\n  \"\"\"\n  Parses the input file and extracts image paths.\n\n  Args:\n      input: The path to the input file.\n\n  Returns:\n      A string containing the image paths each on a new line.\n  \"\"\"\n  if input.endswith(\".md\"):\n    file_content = open_file(input)\n    image_paths = extract_image_path_from_markdown(file_content)\n  elif input.endswith(\".html\") or input.endswith(\".htm\"):\n    file_content = open_file(input)\n    image_paths = extract_image_path_from_html(file_content)\n  else:\n    image_paths = []\n    # This can get noisy so better to log as info.\n    logging.info(\"Skipping this file since it is not a markdown or html file: \" + input)\n  content = \"\"\n  for image_path in image_paths:\n    dir_path = os.path.dirname(input)\n    if (image_path.startswith(\"http://\") or image_path.startswith(\"https://\")):\n      logging.warning(f\"Skipping this image path since it is a URL: {image_path}\\n\")\n    if image_path.startswith(\"./\"):\n      image_path = image_path.removeprefix(\"./\")\n      image_path = os.path.join(dir_path, image_path)\n      content += image_path + \"\\n\"\n    elif image_path[0].isalpha():\n      image_path = os.path.join(dir_path, image_path)\n      content += image_path + \"\\n\"\n    elif image_path.startswith(\"/\") and \"/devsite/\" in input:\n      # If the document is part of devsite, the path needs to be trimmed to the\n      # subdirectory (returns devsite tenant path) and then joined with the\n      # image path\n      devsite_path = trim_path_to_subdir(input, \"en/\")\n      image_path = image_path.removeprefix(\"/\")\n      image_path = os.path.join(devsite_path, image_path)\n      content += image_path + \"\\n\"\n    else:\n      logging.error(f\"Skipping this image path because it cannot be parsed: {image_path}\\n\")\n  return content\n\n\ndef open_file(file_path):\n  file_content = \"\"\n  try:\n    with open(file_path, \"r\", encoding=\"utf-8\") as auto:\n      file_content = auto.read()\n      auto.close()\n  except:\n    logging.error(\n        f\"Skipping this file because it cannot be opened: {input}\\n\"\n    )\n  return file_content\n\n\ndef save_file(output_path, content):\n  try:\n    with open(output_path, \"w\", encoding=\"utf-8\") as auto:\n      auto.write(content)\n      auto.close()\n  except:\n    logging.error(\n        f\"Cannot save the file to: {output_path}\\n\"\n    )\n\n\ndef trim_path_to_subdir(full_path, subdir):\n  \"\"\"Trims a full path up to a given subdirectory.\n\n  Args:\n      full_path: The full path to trim.\n      subdir: The subdirectory to trim to (e.g., '/en/').\n\n  Returns:\n      The trimmed path, or the original path if the subdirectory is not found.\n  \"\"\"\n\n  try:\n      index = full_path.index(subdir)\n      return full_path[: index + len(subdir)]\n  except ValueError:\n      return full_path\n\nmain()\n\n=== examples/gemini/python/docs-agent/scripts/extract_replace_image_alt_text.py ===\n#\n# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\"\"\"\nThis script extracts image paths from markdown, html, or directory of files.\n\nUsage:\n  python extract_image_files.py <input_file>\n\nExample:\n  python extract_image_files.py my_document.md\n  python extract_image_files.py my_document.html\n  python extract_image_files.py my_documents_folder\n\"\"\"\n\nimport os\nimport sys\nimport re\n\nfrom absl import logging\nfrom docs_agent.interfaces import run_console as console\nfrom docs_agent.preprocess.extract_image_path import extract_image_path_from_html\nfrom docs_agent.preprocess.extract_image_path import extract_image_path_from_markdown\nfrom docs_agent.utilities.config import return_config_and_product\nfrom docs_agent.utilities.helpers import resolve_path\nimport yaml\n\n\ndef main(input_path: str = sys.argv[1]):\n  \"\"\"\n  Main function to extract image paths and alt text, and update markdown files.\n\n  Args:\n      input_path: The path to the input file or directory.\n  \"\"\"\n  # Create a file containing image paths and alt text\n  create_image_paths_file(input_path, replace_alt_text=True)\n  # Update the markdown files in place with the new image paths and alt text\n  update_markdown_files(yaml_file_path=\"agent_out/file_alt_text.yaml\")\n\n\ndef create_image_paths_file(input_path: str, replace_alt_text: bool = False)-> None:\n  \"\"\"\n  Creates a file containing image paths and alt text.\n\n  Args:\n      input_path: The path to the input file.\n      replace_alt_text: Whether to replace the alt text.\n  \"\"\"\n  dir_name = \"agent_out\"\n  if input_path.startswith(\"~/\"):\n    input_path = os.path.expanduser(input_path)\n  input_path = os.path.realpath(os.path.join(os.getcwd(), input_path))\n  paths_plain_text = \"\"\n  file_alt_text = {}\n  if os.path.isdir(input_path):\n    for root, _, files in os.walk(resolve_path(input_path)):\n      for file in files:\n        file_path = os.path.realpath(os.path.join(root, file))\n        image_obj = parse_files(file_path)\n        for path in image_obj[\"full_image_paths\"]:\n          paths_plain_text += path + \"\\n\"\n        if replace_alt_text:\n          file_alt_text.update(generate_alt_text_dictionary(file_path, replace_alt_text=replace_alt_text))\n  else:\n    image_obj = parse_files(os.path.realpath(input_path))\n    for path in image_obj[\"full_image_paths\"]:\n      paths_plain_text += path + \"\\n\"\n    if replace_alt_text:\n      file_alt_text = generate_alt_text_dictionary(input_path, replace_alt_text=replace_alt_text)\n  if not os.path.exists(dir_name):\n    os.makedirs(dir_name)\n  if replace_alt_text:\n    save_file(dir_name + \"/file_alt_text.yaml\", yaml.dump(file_alt_text))\n  save_file(dir_name + \"/image_paths.txt\", paths_plain_text)\n\n\ndef generate_alt_text_dictionary(input_file: str, replace_alt_text: bool = False)-> dict:\n  \"\"\"\n  Generates a dictionary containing alt text for each image in the input file.\n\n  Args:\n      input_file: The path to the input file.\n      replace_alt_text: Whether to replace the alt text.\n\n  Returns:\n      A dictionary containing the alt text for each image in the input file.\n  \"\"\"\n  prompt = \"\"\"When you generate a response for alt text, your suggestion should\n  not start with Picture of, Image of, or Screenshot of. Your new alt text\n  suggestion must be fewer than 125 characters. Do not exceed 125 characters.\n  Provide the option that is most suitable for alt text. Output only the alt\n  text suggestion. Do not include any explanations or commentary. Do not include\n  end punctuation. Using the above information as context, provide concise,\n  descriptive alt text for this image that captures its essence and is suitable\n  for users with visual impairments. Use any existing alt text found in the\n  information above for context.\"\"\"\n  paths_plain_text = \"\"\n  summary = \"\"\n  file_alt_text = {}\n  loaded_config, product_config = return_config_and_product(\n      config_file=\"config.yaml\", product=[\"\"]\n  )\n  if input_file.endswith(\".md\" or input_file.endswith(\".html\")):\n    # file_content = open_file(input_file)\n    image_obj = parse_files(input_file)\n    if image_obj[\"full_image_paths\"]:\n      print(f\"Generating summary for: {input_file}\")\n      summary = console.ask_model_with_file(product_configs=product_config,\n                                            question=\"Summarize this file.\",\n                                            file=input_file,\n                                            return_output=True)\n    else:\n      print(f\"No images found for: {input_file}\")\n      return file_alt_text\n    alt_texts = []\n    for path in image_obj[\"full_image_paths\"]:\n      paths_plain_text += path + \"\\n\"\n      if replace_alt_text:\n        print(f\"Generating alt text for: {path}\")\n        alt_text = console.ask_model_with_file(product_configs=product_config,\n                                               question= summary + \"\\n\" + prompt,\n                                               file=path,\n                                               return_output=True\n                                               )\n        if alt_text is None:\n          alt_texts.append(\"\")\n        else:\n          alt_texts.append(alt_text.strip())\n    file_alt_text[input_file] = {\"page_summary\": summary.strip(),\n                                 \"image_paths\": image_obj[\"image_paths\"],\n                                 \"full_image_paths\": image_obj[\"full_image_paths\"],\n                                 \"alt_texts\": alt_texts}\n  return file_alt_text\n\n\ndef parse_files(input_file: str) -> dict[list[str], list[str]]:\n  \"\"\"\n  Parses a file (markdown or html) to extract image paths.\n\n  Args:\n      input_file: The path to the input file.\n\n  Returns:\n      A dictionary containing the image paths and full image paths.\n  \"\"\"\n  if input_file.endswith(\".md\"):\n    file_content = open_file(input_file)\n    image_paths = extract_image_path_from_markdown(file_content)\n  elif input_file.endswith(\".html\") or input_file.endswith(\".htm\"):\n    file_content = open_file(input_file)\n    image_paths = extract_image_path_from_html(file_content)\n  else:\n    image_paths = []\n    # This can get noisy so better to log as info.\n    logging.info(\"Skipping this file since it is not a markdown or html file: \" + input_file)\n  image_obj = {}\n  full_image_paths = []\n  for image_path in image_paths:\n    dir_path = os.path.dirname(input_file)\n    if (image_path.startswith(\"http://\") or image_path.startswith(\"https://\")):\n      logging.warning(f\"Skipping this image path since it is a URL: {image_path}\\n\")\n    if image_path.startswith(\"./\"):\n      image_path = image_path.removeprefix(\"./\")\n      image_path = os.path.join(dir_path, image_path)\n      full_image_paths.append(image_path)\n    elif image_path[0].isalpha():\n      image_path = os.path.join(dir_path, image_path)\n      full_image_paths.append(image_path)\n    elif image_path.startswith(\"/\") and \"/devsite/\" in input_file:\n      # If the document is part of devsite, the path needs to be trimmed to the\n      # subdirectory (returns devsite tenant path) and then joined with the\n      # image path\n      devsite_path = trim_path_to_subdir(input_file, \"en/\")\n      image_path = image_path.removeprefix(\"/\")\n      image_path = os.path.join(devsite_path, image_path)\n      full_image_paths.append(image_path)\n    else:\n      logging.error(f\"Skipping this image path because it cannot be parsed: {image_path}\\n\")\n  image_obj[\"full_image_paths\"] = full_image_paths\n  image_obj[\"image_paths\"] = image_paths\n  return image_obj\n\n\ndef open_file(file_path):\n  \"\"\"\n  Opens a file and returns its content.\n\n  Args:\n      file_path: The path to the file.\n\n  Returns:\n      The content of the file as a string, or an empty string if the file\n      cannot be opened.\n  \"\"\"\n  file_content = \"\"\n  try:\n    with open(file_path, \"r\", encoding=\"utf-8\") as auto:\n      file_content = auto.read()\n      auto.close()\n  except:\n    logging.error(\n        f\"Skipping this file because it cannot be opened: {file_path}\\n\"\n    )\n  return file_content\n\n\ndef save_file(output_path, content):\n  \"\"\"\n  Saves content to a file.\n\n  Args:\n      output_path: The path to the output file.\n      content: The content to be written to the file.\n  \"\"\"\n  try:\n    with open(output_path, \"w\", encoding=\"utf-8\") as auto:\n      auto.write(content)\n      auto.close()\n  except:\n    logging.error(\n        f\"Cannot save the file to: {output_path}\\n\"\n    )\n\n\ndef process_markdown_with_yaml(yaml_file_path: str) -> dict[str, str]:\n  \"\"\"\n  Reads a YAML file, processes the referenced Markdown files (replacing\n  image paths and adding alt text), and updates the Markdown files\n  in place.\n\n  Args:\n      yaml_file_path: Path to the YAML file.\n\n  Returns:\n      A dictionary containing the modified markdown content.\n  \"\"\"\n  try:\n    with open(yaml_file_path, \"r\", encoding=\"utf-8\") as yaml_file:\n      yaml_data = yaml.safe_load(yaml_file)\n  except (FileNotFoundError, yaml.YAMLError) as e:\n    print(f\"Error reading or parsing YAML file: {e}\")\n    return {}\n\n  modified_markdown_files = {}\n\n  for markdown_file_path, markdown_data in yaml_data.items():\n    try:\n      with open(markdown_file_path, \"r\", encoding=\"utf-8\") as md_file:\n        markdown_content = md_file.read()\n    except FileNotFoundError as e:\n      print(f\"Error reading Markdown file: {markdown_file_path} - {e}\")\n      # Store empty string for failed files\n      modified_markdown_files[markdown_file_path] = \"\"\n      continue  # Skip to the next Markdown file\n    # Extract relevant data from YAML, with checks for existence\n    if not all(key in markdown_data for key in [\"image_paths\", \"full_image_paths\", \"alt_texts\"]):\n      print(f\"YAML data for {markdown_file_path} is missing required fields.\")\n      modified_markdown_files[markdown_file_path] = \"\"\n      continue\n\n    image_paths = markdown_data[\"image_paths\"]\n    full_image_paths = markdown_data[\"full_image_paths\"]\n    alt_texts = markdown_data[\"alt_texts\"]\n\n    if len(image_paths) != len(full_image_paths) or len(image_paths) != len(alt_texts):\n      print(f\"Inconsistent image data lengths for {markdown_file_path}.\")\n      modified_markdown_files[markdown_file_path] = \"\"\n      continue\n\n    # Create a mapping from short image path to full image path and alt text\n    image_map = {}\n    for i in range(len(image_paths)):\n      image_map[image_paths[i]] = (full_image_paths[i], alt_texts[i])\n\n    # Function to replace image paths and add alt text\n    def replace_image(match):\n      image_path = match.group(1)\n      if image_path in image_map:\n        full_path, alt_text = image_map[image_path]\n        return f\"![{alt_text}]({image_path})\"\n      else:\n        print(f\"Warning: No full image path found for: {image_path} in {markdown_file_path}\")\n        return match.group(0)  # Return the original Markdown\n    # Regex to find Markdown image syntax\n    markdown_content = re.sub(r\"!\\[.*?\\]\\((.*?)\\)\", replace_image, markdown_content)\n    modified_markdown_files[markdown_file_path] = markdown_content\n\n  return modified_markdown_files\n\n\ndef update_markdown_files(yaml_file_path: str) -> None:\n  \"\"\"\n  Updates markdown files with the new image paths and alt text from the YAML file.\n\n  Args:\n      yaml_file_path: Path to the YAML file containing image data.\n  \"\"\"\n  modified_markdown = process_markdown_with_yaml(yaml_file_path)\n\n  for file_path, new_content in modified_markdown.items():\n    if new_content != \"\":  # Only update if processing was successful\n      try:\n        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n          f.write(new_content)\n          print(f\"Successfully updated: {file_path}\")\n      except Exception as e:\n        print(f\"Error writing to {file_path}: {e}\")\n\n\ndef trim_path_to_subdir(full_path, subdir):\n  \"\"\"Trims a full path up to a given subdirectory.\n\n  Args:\n      full_path: The full path to trim.\n      subdir: The subdirectory to trim to (e.g., '/en/').\n\n  Returns:\n      The trimmed path, or the original path if the subdirectory is not found.\n  \"\"\"\n\n  try:\n      index = full_path.index(subdir)\n      return full_path[: index + len(subdir)]\n  except ValueError:\n      return full_path\n\nmain()\n\n=== examples/gemini/python/docs-agent/scripts/update_files_from_yaml.py ===\n#\n# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\"\"\"\nThis script updates markdown files with image paths and alt text from a YAML file.\n\nUsage:\n  python update_files_from_yaml.py\n\nExample:\n  python update_files_from_yaml.py\n\"\"\"\n\nimport re\nimport sys\n\nfrom docs_agent.utilities.helpers import save_file\nimport yaml\n\n\ndef main(input_path: str = sys.argv[1]):\n    \"\"\"Main function to update markdown files.\n\n    Args:\n        input_path: The path to the input file or directory.\n    \"\"\"\n    # Update the markdown files in place with the new image paths and alt text\n    update_markdown_files(yaml_file_path=input_path)\n\n\ndef process_markdown_with_yaml(yaml_file_path: str) -> dict[str, str]:\n    \"\"\"\n    Reads a YAML file, processes the referenced Markdown files (replacing\n    image paths and update alt text with LLM alt text), and updates the Markdown\n    files in place.\n\n    Args:\n        yaml_file_path: Path to the YAML file.\n\n    Returns:\n        A dictionary containing the modified markdown content.\n    \"\"\"\n    # This allows reading in a response from the LLM that is not a valid YAML\n    # file.\n    try:\n        with open(yaml_file_path, \"r\", encoding=\"utf-8\") as file:\n            file_content = file.read()\n    except FileNotFoundError as e:\n        print(f\"Error: YAML file not found: {yaml_file_path} - {e}\")\n        return {}\n\n    # Extract YAML content using regex.\n    match = re.search(r\"```yaml\\n(.*?)\\n```\", file_content, re.DOTALL | re.IGNORECASE)\n    if not match:\n        print(\"Error: No YAML content found within ```yaml ... ``` tags.\")\n        return {}\n\n    yaml_content = match.group(1)\n    try:\n        yaml_data = yaml.safe_load(yaml_content)  # Parse the extracted YAML.\n    except yaml.YAMLError as e:\n        print(f\"Error parsing YAML content: {e}\")\n        return {}\n\n    modified_markdown_files = {}\n\n    # Iterate through the list of files in the YAML\n    if \"files\" not in yaml_data:\n        print(\"Error: YAML file does not contain a 'files' list.\")\n        return {}\n\n    # Process each Markdown file listed in 'files'\n    for file_data in yaml_data[\"files\"]:\n        markdown_file_path = file_data[\"path\"]\n        try:\n            with open(markdown_file_path, \"r\", encoding=\"utf-8\") as md_file:\n                markdown_content = md_file.read()\n        except FileNotFoundError as e:\n            print(f\"Error reading Markdown file: {markdown_file_path} - {e}\")\n            modified_markdown_files[markdown_file_path] = \"\"\n            continue\n\n        image_data = file_data.get(\"images\")\n        # If no image data is found, skip this file.\n        if not image_data or not image_data.get(\"full_image_paths\"):\n            continue\n\n        image_paths = image_data.get(\"image_paths\", [])\n        full_image_paths = image_data.get(\"full_image_paths\", [])\n        alt_texts = image_data.get(\"alt_texts\", [])  # alt_texts, not llm_alt_texts\n        image_titles = image_data.get(\"image_titles\", [])\n        llm_alt_texts = image_data.get(\"llm_alt_texts\", [])\n\n        # If llm_alt_texts are present, use those; otherwise, fall back to alt_texts,\n        # or an empty string if neither exists.\n        final_alt_texts = []\n        for i in range(max(len(image_paths), len(llm_alt_texts), len(alt_texts))):\n            if i < len(llm_alt_texts):\n                final_alt_texts.append(llm_alt_texts[i])\n            elif i < len(alt_texts):\n                final_alt_texts.append(alt_texts[i])\n            else:\n                final_alt_texts.append(\"\")\n        # Ensure image_titles has the same length as other lists\n        final_image_titles = []\n        for i in range(len(image_paths)):\n            if i < len(image_titles):\n                final_image_titles.append(image_titles[i])\n            else:\n                final_image_titles.append(\"\")  # Pad with empty strings\n\n        if not (\n            len(image_paths)\n            == len(full_image_paths)\n            == len(final_alt_texts)\n            == len(final_image_titles)\n        ):\n            print(f\"Inconsistent image data lengths for {markdown_file_path}.\")\n            modified_markdown_files[markdown_file_path] = \"\"\n            continue\n\n        # Build a dictionary mapping image paths to image data\n        # (full image path, alt text, image title)\n        image_map = {}\n        for i in range(len(image_paths)):\n            image_map[image_paths[i]] = (\n                full_image_paths[i],\n                final_alt_texts[i],\n                final_image_titles[i],\n            )\n\n        def replace_image(match):\n            image_path = match.group(2).strip()\n            if image_path in image_map:\n                _, alt_text, image_title = image_map[image_path]\n                # Build the Markdown image tag, handling titles\n                if image_title:\n                    return f'![{alt_text}]({image_path} \"{image_title}\")'\n                else:\n                    return f\"![{alt_text}]({image_path})\"\n            else:\n                print(\n                    f\"Warning: No matching image path found for: {image_path} in {markdown_file_path}\"\n                )\n                return match.group(0)\n\n        # Improved regex to handle existing titles\n        markdown_content = re.sub(\n            r'!\\[(.*?)\\]\\((.*?)(?:\\s+\"(.*?)\")?\\s*\\)', replace_image, markdown_content\n        )\n        modified_markdown_files[markdown_file_path] = markdown_content\n\n    return modified_markdown_files\n\n\ndef update_markdown_files(yaml_file_path: str) -> None:\n    \"\"\"\n    Updates the markdown files with the new image paths and alt text from the\n    YAML file.\n\n    Args:\n        yaml_file_path: Path to the YAML file containing the image data.\n    \"\"\"\n    modified_markdown = process_markdown_with_yaml(yaml_file_path)\n    save_file(output_path=\"agent_out/md_output.yaml\", content=modified_markdown)\n\n    for file_path, new_content in modified_markdown.items():\n        if new_content != \"\":  # Only update if processing was successful\n            try:\n                with open(file_path, \"w\", encoding=\"utf-8\") as f:\n                    f.write(new_content)\n                    print(f\"Successfully updated: {file_path}\")\n            except Exception as e:\n                print(f\"Error writing to {file_path}: {e}\")\n\n\nmain()\n\n\n=== examples/gemini/python/docs-agent/scripts/create_file_dictionary.py ===\n#\n# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\"\"\"\nThis script extracts image paths and alt text from markdown, html, or a directory of files.\n\nUsage:\n  python create_file_dictionary.py <input_file>\n\nExample:\n  python create_file_dictionary.py my_document.md\n  python create_file_dictionary.py my_document.html\n  python create_file_dictionary.py my_documents_folder\n\"\"\"\n\nimport os\nimport sys\n\nfrom docs_agent.preprocess.extract_image_path import parse_md_html_files_for_images\nfrom docs_agent.utilities.helpers import resolve_path\nfrom docs_agent.utilities.helpers import save_file\nfrom docs_agent.utilities.helpers import create_output_directory\n\n\ndef main(input_path: str = sys.argv[1]):\n    \"\"\"Main function to extract image paths and alt text, and update markdown files.\n\n    Args:\n        input_path: The path to the input file or directory.\n    \"\"\"\n    # Create a file containing image paths and current alt text for input md files\n    # extract_image_files(input_path)\n    file_dictionary = walk_directory(input_path)\n    create_output_directory(\"agent_out\")\n    print(f\"Saving file dictionary to: agent_out/file_alt_text.yaml\")\n    save_file(output_path=\"agent_out/file_alt_text.yaml\", content=file_dictionary)\n    # Create a file containing image paths to be given to Docs Agent task\n    save_image_paths(file_dictionary)\n\n\ndef walk_directory(input_path: str) -> dict:\n    \"\"\"Walks through the input path (file or directory) and generates a dictionary\n    containing image paths and alt text for each markdown or html file.\n\n    Args:\n        input_path: The path to the input file or directory.\n\n    Returns:\n        A dictionary containing the files list.\n    \"\"\"\n    if input_path.startswith(\"~/\"):\n        input_path = os.path.expanduser(input_path)\n    input_path = os.path.realpath(os.path.join(os.getcwd(), input_path))\n    files_list = []\n    if os.path.isdir(input_path):\n        for root, _, files in os.walk(resolve_path(input_path)):\n            for file in files:\n                file_path = os.path.realpath(os.path.join(root, file))\n                file_data = generate_dictionary_md_file(file_path)\n                # Prevents empty dictionaries from being added\n                if file_data and \"files\" in file_data:\n                    files_list.append(file_data[\"files\"])\n    else:\n        file_data = generate_dictionary_md_file(input_path)\n        if file_data and \"files\" in file_data:\n            files_list.append(file_data[\"files\"])\n\n    # Return a dictionary containing the files list\n    return {\"files\": files_list}\n\n\ndef generate_dictionary_md_file(input_file: str) -> dict:\n    \"\"\"Generates a dictionary containing alt text for each image in the input file.\n\n    Args:\n        input_file: The path to the input file.\n\n    Returns:\n        A dictionary containing the alt text for each image in the input file.\n    \"\"\"\n    md_obj = {}\n    if input_file.endswith((\".md\", \".html\")):\n        image_obj = parse_md_html_files_for_images(input_file)\n        md_obj[\"files\"] = {\n            \"path\": resolve_path(input_file),\n            \"images\": image_obj[\"images\"],\n        }\n    return md_obj\n\n\ndef save_image_paths(input_dictionary: dict) -> None:\n    \"\"\"Returns the image paths from the input dictionary.\"\"\"\n    image_paths = []\n    for file_data in input_dictionary[\"files\"]:\n        image_paths.extend(file_data[\"images\"][\"full_image_paths\"])\n    create_output_directory(\"agent_out\")\n    save_file(output_path=\"agent_out/image_paths.txt\", content=\"\\n\".join(image_paths))\n\n\nmain()\n\n\n=== examples/gemini/python/docs-agent/docs_agent/memory/logging.py ===\n#\n# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\nfrom datetime import datetime\nimport pytz\nimport os\nimport re\nfrom uuid import UUID\n\n\"\"\"Module to log interactions with the chatbot\"\"\"\n\n\n# Save this question and response pair as a file.\ndef log_question_to_file(user_question: str, response: str, probability: str = \"None\"):\n    filename = (\n        str(user_question)\n        .lower()\n        .replace(\" \", \"-\")\n        .replace(\"?\", \"\")\n        .replace(\"'\", \"\")\n        .replace(\"`\", \"\")\n    )\n    filename = re.sub(\"[^a-zA-Z0-9\\\\-]\", \"\", filename)\n    if len(filename) > 64:\n        filename = filename[:64]\n    log_dir = \"./logs/responses\"\n    log_filename = f\"{log_dir}/{filename}.md\"\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n    with open(log_filename, \"a\", encoding=\"utf-8\") as log_file:\n        log_file.write(\"# \" + user_question.strip() + \"\\n\\n\")\n        log_file.write(response.strip() + \"\\n\\n\")\n        if probability != \"None\":\n            log_file.write(\"(Answerable probability: \" + str(probability) + \")\\n\")\n        log_file.close()\n\n\n# Log the answerable_probability score and question.\ndef log_answerable_probability(user_question: str, probability: str):\n    log_dir = \"./logs\"\n    answerable_list_filename = log_dir + \"/answerable_logs.txt\"\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n    with open(answerable_list_filename, \"a\", encoding=\"utf-8\") as log_file:\n        log_file.write(\n            str(\"{:.16f}\".format(probability)) + \"    \" + user_question.strip() + \"\\n\"\n        )\n        log_file.close()\n\n\n# Save a detailed record of a question and response pair as a file for debugging.\ndef log_debug_info_to_file(\n    uid: UUID,\n    user_question: str,\n    response: str,\n    context: str,\n    top_source_url: str,\n    source_urls: str,\n    probability: str = \"None\",\n    server_url: str = \"None\",\n):\n    # Compose a filename\n    date = datetime.now(tz=pytz.utc)\n    date = date.astimezone(pytz.timezone(\"US/Pacific\"))\n    date_formatted = str(date.strftime(\"%Y-%m-%d-%H-%M-%S\"))\n    question_formatted = (\n        str(user_question)\n        .lower()\n        .replace(\" \", \"-\")\n        .replace(\"?\", \"\")\n        .replace(\"'\", \"\")\n        .replace(\"`\", \"\")\n    )\n    question_formatted = re.sub(\"[^a-zA-Z0-9\\\\-]\", \"\", question_formatted)\n    if len(question_formatted) > 32:\n        question_formatted = question_formatted[:32]\n    filename = date_formatted + \"-\" + question_formatted + \"-\" + str(uid) + \".txt\"\n    # Set the directory location.\n    debug_dir = \"./logs/debugs\"\n    debug_filename = f\"{debug_dir}/{filename}\"\n    if not os.path.exists(debug_dir):\n        os.makedirs(debug_dir)\n    with open(debug_filename, \"w\", encoding=\"utf-8\") as debug_file:\n        debug_file.write(\"UID: \" + str(uid) + \"\\n\")\n        debug_file.write(\"DATE: \" + str(date) + \"\\n\")\n        debug_file.write(\"SERVER URL: \" + server_url.strip() + \"\\n\")\n        debug_file.write(\"\\n\")\n        debug_file.write(\"TOP SOURCE URL: \" + top_source_url.strip() + \"\\n\")\n        debug_file.write(\"ANSWERABLE PROBABILITY: \" + str(probability) + \"\\n\")\n        debug_file.write(\"\\n\")\n        debug_file.write(\"QUESTION: \" + user_question.strip() + \"\\n\\n\")\n        debug_file.write(\"RESPONSE:\\n\\n\")\n        debug_file.write(response.strip() + \"\\n\\n\")\n        debug_file.write(\"CONTEXT:\\n\\n\")\n        debug_file.write(context.strip() + \"\\n\\n\")\n        debug_file.write(\"SOURCE URLS:\\n\\n\")\n        debug_file.write(source_urls.strip() + \"\\n\\n\")\n        debug_file.close()\n\n\n# Save the like and dislike interactions to the file for debugging.\ndef log_feedback_to_file(uid: str, is_like, is_dislike):\n    # Search the debugs directory.\n    debug_dir = \"./logs/debugs\"\n    target_string = str(uid) + \".txt\"\n    debug_filename = \"\"\n    for root, dirs, files in os.walk(debug_dir):\n        for file in files:\n            if file.endswith(target_string):\n                debug_filename = f\"{debug_dir}/{file}\"\n    if debug_filename != \"\":\n        with open(debug_filename, \"a\", encoding=\"utf-8\") as debug_file:\n            if is_like != None:\n                debug_file.write(\"LIKE: \" + str(is_like) + \"\\n\")\n            if is_dislike != None:\n                debug_file.write(\"DISLIKE: \" + str(is_dislike) + \"\\n\")\n            debug_file.close()\n\n\n# Write captured debug logs into a CSV file.\ndef write_logs_to_csv_file(log_date: str = \"None\"):\n    # Compose the output CSV filename.\n    output_filename = \"debug-info-all.csv\"\n    if log_date != \"None\":\n        output_filename = \"debug-info-\" + str(log_date) + \".csv\"\n    # Write a header for this CSV file.\n    log_dir = \"./logs\"\n    out_csv_filename = log_dir + \"/\" + output_filename\n    line = f\"DATE, UID, QUESTION, PROBABILITY, TOP SOURCE URL, DEBUG LINK, FEEDBACK\"\n    with open(out_csv_filename, \"w\", encoding=\"utf-8\") as csv_file:\n        csv_file.write(line + \"\\n\")\n        csv_file.close()\n    # Search the debugs directory.\n    debug_dir = \"./logs/debugs\"\n    debug_filename = \"\"\n    for root, dirs, files in os.walk(debug_dir):\n        for file in files:\n            # Read all files if date is \"None\" else read files from the input date only.\n            ok_to_read = False\n            if file.endswith(\"txt\"):\n                ok_to_read = True\n            if log_date != \"None\":\n                if file.startswith(log_date):\n                    ok_to_read = True\n                else:\n                    ok_to_read = False\n            if ok_to_read:\n                debug_filename = f\"{debug_dir}/{file}\"\n                debug_record = \"\"\n                # Open and read this debug information file.\n                with open(debug_filename, \"r\", encoding=\"utf-8\") as debug_file:\n                    debug_record = debug_file.readlines()\n                    debug_file.close()\n                uid = \"\"\n                date = \"\"\n                server_url = \"None\"\n                top_source_url = \"\"\n                probability = \"\"\n                question = \"\"\n                like = \"None\"\n                dislike = \"None\"\n                filename = str(file)\n                # Scan the lines from thi debug info and extract fields.\n                for line in debug_record:\n                    match_uid = re.search(r\"^UID:\\s+(.*)$\", line)\n                    match_date = re.search(r\"^DATE:\\s+(.*)$\", line)\n                    match_server_url = re.search(r\"^SERVER URL:\\s+(.*)$\", line)\n                    match_top_url = re.search(r\"^TOP SOURCE URL:\\s+(.*)$\", line)\n                    match_prob = re.search(r\"^ANSWERABLE PROBABILITY:\\s+(.*)$\", line)\n                    match_question = re.search(r\"^QUESTION:\\s+(.*)$\", line)\n                    match_like = re.search(r\"^LIKE:\\s+(.*)$\", line)\n                    match_dislike = re.search(r\"^DISLIKE:\\s+(.*)$\", line)\n                    # Extract fields.\n                    if match_uid:\n                        uid = match_uid.group(1)\n                    elif match_date:\n                        date = match_date.group(1)\n                    elif match_server_url:\n                        server_url = match_server_url.group(1)\n                    elif match_top_url:\n                        top_source_url = match_top_url.group(1)\n                    elif match_prob:\n                        probability = match_prob.group(1)\n                    elif match_question:\n                        question = match_question.group(1)\n                    elif match_like:\n                        like = match_like.group(1)\n                    elif match_dislike:\n                        dislike = match_dislike.group(1)\n                # Write a short version of this debug information to the CSV file.\n                debug_file_link = filename\n                if server_url != \"None\":\n                    debug_file_link = server_url + \"debugs/\" + filename\n                feedback = \"None\"\n                if like == \"True\":\n                    feedback = \"Like\"\n                elif dislike == \"True\":\n                    feedback = \"Dislike\"\n                log_debug_info_to_csv_file(\n                    output_filename=output_filename,\n                    date=date,\n                    uid=uid,\n                    question=question,\n                    probability=probability,\n                    top_source_url=top_source_url,\n                    debug_file_link=debug_file_link,\n                    feedback=feedback,\n                )\n\n\n# Save the short version of debug information into a CSV file.\ndef log_debug_info_to_csv_file(\n    output_filename: str,\n    date: str,\n    uid: str,\n    question: str,\n    probability: str = \"None\",\n    top_source_url: str = \"None\",\n    debug_file_link: str = \"None\",\n    feedback: str = \"None\",\n):\n    log_dir = \"./logs\"\n    log_filename = log_dir + \"/\" + str(output_filename)\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n    question_formatted = str(question).lower().replace(\",\", \" \").replace(\";\", \"\")\n    line = f\"{date}, {uid}, {question_formatted}, {probability}, {top_source_url}, {debug_file_link}, {feedback}\"\n    with open(log_filename, \"a\", encoding=\"utf-8\") as log_file:\n        log_file.write(line + \"\\n\")\n        log_file.close()\n\n\n# Print and log the question and response.\ndef log_question(\n    uid,\n    user_question: str,\n    response: str,\n    probability: str = \"None\",\n    save: bool = True,\n    logs_to_markdown: str = \"False\",\n):\n    date_format = \"%m/%d/%Y %H:%M:%S %Z\"\n    date = datetime.now(tz=pytz.utc)\n    date = date.astimezone(pytz.timezone(\"US/Pacific\"))\n    print(\"UID: \" + str(uid))\n    print(\"Question: \" + user_question.strip() + \"\\n\")\n    print(\"Response:\")\n    print(response.strip() + \"\\n\")\n    # For the AQA model, also print the response's answerable_probability\n    if probability != \"None\":\n        print(\"Answerable probability: \" + str(probability) + \"\\n\")\n    if save:\n        log_dir = \"./logs\"\n        log_filename = log_dir + \"/chatui_logs.txt\"\n        if not os.path.exists(log_dir):\n            os.makedirs(log_dir)\n        with open(log_filename, \"a\", encoding=\"utf-8\") as log_file:\n            log_file.write(\n                \"[\" + date.strftime(date_format) + \"][UID \" + str(uid) + \"]\\n\"\n            )\n            log_file.write(\"# \" + user_question.strip() + \"\\n\\n\")\n            log_file.write(response.strip() + \"\\n\\n\")\n            if probability != \"None\":\n                log_file.write(\"Answerable probability: \" + str(probability) + \"\\n\\n\")\n            log_file.close()\n        if probability != \"None\":\n            # Track the answerable_probability scores.\n            log_answerable_probability(user_question, probability)\n        if logs_to_markdown == \"True\":\n            log_question_to_file(user_question, response, probability)\n\n\ndef log_like(is_like, uid, save: bool = True):\n    date_format = \"%m/%d/%Y %H:%M:%S %Z\"\n    date = datetime.now(tz=pytz.utc)\n    date = date.astimezone(pytz.timezone(\"US/Pacific\"))\n    print()\n    print(\"UID: \" + str(uid))\n    print(\"Like: \" + str(is_like))\n    if save:\n        log_dir = \"./logs\"\n        log_filename = log_dir + \"/chatui_logs.txt\"\n        with open(log_filename, \"a\", encoding=\"utf-8\") as log_file:\n            log_file.write(\n                \"[\" + date.strftime(date_format) + \"][UID \" + str(uid) + \"]\\n\"\n            )\n            log_file.write(\"Like: \" + str(is_like) + \"\\n\\n\")\n            log_file.close()\n\n\ndef log_dislike(is_dislike, uid, save: bool = True):\n    date_format = \"%m/%d/%Y %H:%M:%S %Z\"\n    date = datetime.now(tz=pytz.utc)\n    date = date.astimezone(pytz.timezone(\"US/Pacific\"))\n    print()\n    print(\"UID: \" + str(uid))\n    print(\"Dislike: \" + str(is_dislike))\n    if save:\n        log_dir = \"./logs\"\n        log_filename = log_dir + \"/chatui_logs.txt\"\n        with open(log_filename, \"a\", encoding=\"utf-8\") as log_file:\n            log_file.write(\n                \"[\" + date.strftime(date_format) + \"][UID \" + str(uid) + \"]\\n\"\n            )\n            log_file.write(\"Disike: \" + str(is_dislike) + \"\\n\\n\")\n            log_file.close()\n\n\n=== examples/gemini/python/docs-agent/docs_agent/memory/__init__.py ===\n\n\n=== examples/gemini/python/docs-agent/docs_agent/preprocess/__init__.py ===\n\n\n=== examples/gemini/python/docs-agent/docs_agent/preprocess/files_to_plain_text.py ===\n#\n# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n\"\"\"Process Markdown files into plain text\"\"\"\n\nimport shutil\nimport os\nimport re\nimport json\nimport typing\nimport uuid\nfrom absl import logging\n\nimport tqdm\nfrom docs_agent.utilities import config\nfrom docs_agent.utilities.config import ProductConfig, ConfigFile, Input\nfrom docs_agent.models.tokenCount import returnHighestTokens\nfrom docs_agent.utilities.helpers import (\n    resolve_path,\n    add_scheme_url,\n    end_path_backslash,\n    start_path_no_backslash,\n)\nfrom docs_agent.preprocess.splitters import (\n    markdown_splitter,\n    html_splitter,\n    fidl_splitter,\n)\n\n\n# Construct a URL from a URL prefix and a relative path.\ndef construct_a_url(url_prefix: str, relative_path: str):\n    temp_url = end_path_backslash(add_scheme_url(url=url_prefix, scheme=\"https\"))\n    built_url = temp_url + start_path_no_backslash(relative_path)\n    strip_ext_url = re.search(r\"(.*)\\.md$\", built_url)\n    built_url = strip_ext_url[1]\n    return built_url\n\n\n# This function pre-processes files before they are actually chunked.\n# This allows it to resolve includes of includes, Jinja templates, etc...\n# TODO support Jinja, for this need to support data filters as well\n# {% set doc | jsonloads %} and {% set teams | yamlloads %}\n# Returns the temp_output which can then be deleted\ndef pre_process_doc_files(\n    product_config: ProductConfig, inputpathitem: Input, temp_path: str\n) -> str:\n    temp_output = os.path.join(temp_path, product_config.output_path)\n    # Delete directory if it exits, then create it.\n    print(f\"Temp output: {temp_output}\")\n    print(\"===========================================\")\n    if os.path.exists(temp_output):\n        shutil.rmtree(temp_output)\n        os.makedirs(temp_output)\n    else:\n        os.makedirs(temp_output)\n    # Prepare progress bar\n    file_count = sum(\n        len(files) for _, _, files in os.walk(resolve_path(inputpathitem.path))\n    )\n    progress_bar = tqdm.tqdm(\n        total=file_count,\n        position=0,\n        bar_format=\"{percentage:3.0f}% | {n_fmt}/{total_fmt} | {elapsed}/{remaining}| {desc}\",\n    )\n    for root, dirs, files in os.walk(resolve_path(inputpathitem.path)):\n        if inputpathitem.exclude_path is not None:\n            dirs[:] = [d for d in dirs if d not in inputpathitem.exclude_path]\n        for file in files:\n            # Displays status bar\n            progress_bar.set_description_str(\n                f\"Pre-processing file {file}\", refresh=True\n            )\n            progress_bar.update(1)\n            # Process only Markdown files that do not begin with _(those should\n            # be imported)\n            # Construct a new sub-directory for storing output plain text files\n            dir_path = os.path.join(\n                temp_output, os.path.relpath(root, inputpathitem.path)\n            )\n            if not os.path.exists(dir_path):\n                os.makedirs(dir_path)\n            relative_path = make_relative_path(\n                file=file, root=root, inputpath=inputpathitem.path\n            )\n            final_filename = temp_output + \"/\" + relative_path\n            if file.startswith(\"_\") and file.endswith(\".md\"):\n                with open(os.path.join(root, file), \"r\", encoding=\"utf-8\") as auto:\n                    # Read the input Markdown content\n                    content = auto.read()\n                    auto.close()\n                # Process includes lines in Markdown\n                file_with_include = markdown_splitter.process_markdown_includes(\n                    content, root\n                )\n                # Process include lines in HTML\n                file_with_include = html_splitter.process_html_includes(\n                    file_with_include, inputpathitem.include_path_html\n                )\n                with open(final_filename, \"w\", encoding=\"utf-8\") as new_file:\n                    new_file.write(content)\n                    new_file.close()\n            elif file.startswith(\"_\") and (\n                file.endswith(\".html\") or file.endswith(\".htm\")\n            ):\n                with open(os.path.join(root, file), \"r\", encoding=\"utf-8\") as auto:\n                    # Read the input HTML content\n                    content = auto.read()\n                    auto.close()\n                with open(final_filename, \"w\", encoding=\"utf-8\") as new_file:\n                    new_file.write(content)\n                    new_file.close()\n            else:\n                # Just copy files that that we don't need to preprocess\n                # Such as images or files without underscores\n                initial_file = os.path.join(root, file)\n                # Errors with .gsheet, skip gsheet for now\n                if not (file.endswith(\".gsheet\")):\n                    shutil.copyfile(initial_file, final_filename)\n    # Return the temporary directory, which can then be deleted once files are fully processed\n    return temp_output\n\n\n# This function processes a Markdown file and\n# splits it into smaller text chunks.\ndef process_markdown_file(\n    filename: str,\n    root: str,\n    inputpathitem: Input,\n    splitter: str,\n    new_path: str,\n    file: str,\n    namespace_uuid: uuid.UUID,\n    relative_path: str,\n    url_prefix: str,\n):\n    file_metadata = {}\n    # Read the input Markdown content\n    to_file = \"\"\n    with open(filename, \"r\", encoding=\"utf-8\") as auto:\n        to_file = auto.read()\n        auto.close()\n    # Process includes lines in Markdown\n    file_with_include = markdown_splitter.process_markdown_includes(to_file, root)\n    # Process include lines in HTML\n    file_with_include = html_splitter.process_html_includes(\n        file_with_include, inputpathitem.include_path_html\n    )\n    # Estimate of the token count\n    page_token_estimate = returnHighestTokens(file_with_include)\n    # Get the original input path\n    original_input = inputpathitem.path\n    if splitter == \"token_splitter\":\n        # Returns an array of Section objects along with a Page\n        # Object that contains metadata\n        (\n            page_sections,\n            page,\n        ) = markdown_splitter.process_markdown_page(\n            markdown_text=file_with_include, header_id_spaces=\"-\"\n        )\n        # Process this page's sections into plain text chunks.\n        chunk_number = 0\n        for section in page_sections:\n            filename_to_save = make_chunk_name(\n                new_path=new_path,\n                file=file,\n                index=chunk_number,\n                extension=\"md\",\n            )\n            # Get the text chunk filename string (after `docs-agent/data`).\n            text_chunk_filename = get_relative_path_and_filename(filename_to_save)\n            # Generate UUID for each plain text chunk and collect its metadata,\n            # which will be written to the top-level `file_index.json` file.\n            md_hash = uuid.uuid3(namespace_uuid, section.content)\n            uuid_file = uuid.uuid3(namespace_uuid, filename_to_save)\n            origin_uuid = uuid.uuid3(namespace_uuid, relative_path)\n            # If no URL came from frontmatter, assign URL from config\n            if page.URL == \"\":\n                page.URL = end_path_backslash(\n                    add_scheme_url(url=url_prefix, scheme=\"https\")\n                )\n            # Strip extension of .md from url\n            # Makes sure that relative_path starts without backslash\n            # page.url will have backslash\n            built_url = page.URL + start_path_no_backslash(relative_path)\n            strip_ext_url = re.search(r\"(.*)\\.md$\", built_url)\n            built_url = strip_ext_url[1]\n            # Build the valid URL for a section including header\n            # Do not add a # if section 1\n            if section.name_id != \"\" and int(section.level) != 1:\n                built_url = built_url + \"#\" + section.name_id\n            # Adds additional info so that the section can know its origin\n            file_metadata[filename_to_save] = {\n                \"UUID\": str(uuid_file),\n                \"origin_uuid\": str(origin_uuid),\n                \"source\": str(original_input),\n                \"source_file\": str(relative_path),\n                \"page_title\": str(section.page_title),\n                \"section_title\": str(section.section_title),\n                \"section_name_id\": str(section.name_id),\n                \"section_id\": int(section.id),\n                \"section_level\": int(section.level),\n                \"previous_id\": int(section.previous_id),\n                \"URL\": str(built_url),\n                \"md_hash\": str(md_hash),\n                \"text_chunk_filename\": str(text_chunk_filename),\n                \"token_estimate\": float(section.token_count),\n                \"full_token_estimate\": float(page_token_estimate),\n                \"parent_tree\": list(section.parent_tree),\n                \"metadata\": dict(page.metadata),\n            }\n            with open(filename_to_save, \"w\", encoding=\"utf-8\") as new_file:\n                new_file.write(section.content)\n                new_file.close()\n            chunk_number += 1\n    elif splitter == \"process_sections\":\n        # Use a custom Markdown splitter to split a Markdown file\n        # into small text chunks\n        to_file = markdown_splitter.process_markdown_includes(to_file, root)\n        # Add the page title and section title into each text chunk\n        (\n            to_file,\n            metadata,\n        ) = markdown_splitter.process_page_and_section_titles(to_file)\n        # Process this page's sections into plain text chunks.\n        docs = markdown_splitter.process_document_into_sections(to_file)\n        # Process each text chunk.\n        chunk_number = 0\n        for doc in docs:\n            filename_to_save = make_chunk_name(\n                new_path=new_path,\n                file=file,\n                index=chunk_number,\n                extension=\"md\",\n            )\n            # Get the text chunk filename string (after `docs-agent/data`).\n            text_chunk_filename = get_relative_path_and_filename(filename_to_save)\n            # Generate UUID for each plain text chunk and collect its metadata,\n            # which will be written to the top-level `file_index.json` file.\n            md_hash = uuid.uuid3(namespace_uuid, file_with_include)\n            uuid_file = uuid.uuid3(namespace_uuid, filename_to_save)\n            # Clean up Markdown and HTML syntax\n            content = markdown_splitter.markdown_to_text(doc)\n            # Contruct a URL\n            built_url = construct_a_url(url_prefix, relative_path)\n            # Get the page title\n            page_title = \"None\"\n            if \"title\" in metadata:\n                page_title = metadata[\"title\"]\n            # Construct metadata.\n            file_metadata[filename_to_save] = {\n                \"UUID\": str(uuid_file),\n                \"origin_uuid\": str(uuid_file),\n                \"source\": str(original_input),\n                \"source_file\": str(relative_path),\n                \"page_title\": str(page_title),\n                \"section_title\": str(\"None\"),\n                \"section_name_id\": str(\"None\"),\n                \"section_id\": int(1),\n                \"section_level\": int(1),\n                \"previous_id\": int(1),\n                \"URL\": str(built_url),\n                \"md_hash\": str(md_hash),\n                \"text_chunk_filename\": str(text_chunk_filename),\n                \"token_estimate\": float(1.0),\n                \"full_token_estimate\": float(page_token_estimate),\n                \"metadata\": dict(metadata),\n            }\n            with open(filename_to_save, \"w\", encoding=\"utf-8\") as new_file:\n                new_file.write(content)\n                new_file.close()\n            chunk_number += 1\n    else:\n        # Exits if no valid markdown splitter\n        logging.error(\n            f\"Select a valid markdown_splitter option in your configuration for your product\\n\"\n        )\n        exit()\n    return file_metadata\n\n\n# This function processes a FIDL file (.fidl) into small text chunks.\ndef process_fidl_file(\n    filename: str,\n    root: str,\n    inputpathitem: Input,\n    splitter: str,\n    new_path: str,\n    file: str,\n    namespace_uuid: uuid.UUID,\n    relative_path: str,\n    url_prefix: str,\n):\n    # Local variables\n    file_metadata = {}\n    library_name = \"\"\n    filename_prefix = \"index\"\n    chunk_number = 0\n    # Get the original input path\n    original_input = inputpathitem.path\n    # Read the input FIDL content\n    to_file = \"\"\n    with open(filename, \"r\", encoding=\"utf-8\") as auto:\n        to_file = auto.read()\n        auto.close()\n    # Split the FIDL file into a list of FIDL protocols.\n    fidl_protocols = fidl_splitter.split_file_to_protocols(to_file)\n    # Iterate the list of FIDL protocols.\n    for fidl_protocol in fidl_protocols:\n        # Identify the new FIDL chunk file path and name.\n        filename_to_save = make_file_chunk_name(\n            new_path=new_path, filename_prefix=filename_prefix, index=chunk_number\n        )\n        # Get the text chunk filename string (after `docs-agent/data`).\n        text_chunk_filename = get_relative_path_and_filename(filename_to_save)\n        # Prepare metadata for this FIDL protocol chunk.\n        md_hash = uuid.uuid3(namespace_uuid, fidl_protocol)\n        uuid_file = uuid.uuid3(namespace_uuid, filename_to_save)\n        origin_uuid = uuid.uuid3(namespace_uuid, relative_path)\n        # Contruct the URL for this FIDL protocol.\n        match_library = re.search(r\"^Library\\sname:\\s+(.*)\\n\", fidl_protocol)\n        if match_library:\n            library_name = match_library.group(1)\n        # If no library name is found,\n        # the library name from the previous protocol is used.\n        fidl_url = url_prefix + library_name\n        file_metadata[filename_to_save] = {\n            \"UUID\": str(uuid_file),\n            \"origin_uuid\": str(origin_uuid),\n            \"source\": str(original_input),\n            \"source_file\": str(relative_path),\n            \"source_id\": int(chunk_number),\n            \"page_title\": str(library_name),\n            \"section_title\": str(library_name),\n            \"section_name_id\": str(\"None\"),\n            \"section_id\": int(1),\n            \"section_level\": int(1),\n            \"previous_id\": int(1),\n            \"URL\": str(fidl_url),\n            \"md_hash\": str(md_hash),\n            \"text_chunk_filename\": str(text_chunk_filename),\n            \"token_estimate\": float(1.0),\n            \"full_token_estimate\": float(1.0),\n        }\n        # Save the FIDL protocol content as a text chunk.\n        with open(filename_to_save, \"w\", encoding=\"utf-8\") as new_file:\n            new_file.write(fidl_protocol)\n            new_file.close()\n        chunk_number += 1\n    return file_metadata\n\n\n# This function processes a HTML file into small text chunks.\ndef process_html_file(\n    filename: str,\n    root: str,\n    inputpathitem: Input,\n    splitter: str,\n    new_path: str,\n    file: str,\n    namespace_uuid: uuid.UUID,\n    relative_path: str,\n    url_prefix: str,\n):\n    # Local variables\n    file_metadata = {}\n    # Read the input HTML content\n    to_file = \"\"\n    with open(filename, \"r\", encoding=\"utf-8\") as auto:\n        to_file = auto.read()\n        auto.close()\n    # Process includes lines in HTML\n    file_with_include = html_splitter.process_html_includes(\n        to_file, inputpathitem.include_path_html\n    )\n    return file_metadata\n\n\n# This function processes files specified in the `inputs` field\n# in the config.yaml file into small plain text files.\n# Includes are processed again since preprocess resolves the includes in\n# files prefixed with _, which indicates they are not standalone.\n# inputpath is optional to walk a temporary directory that has been pre-processed.\n# If not, it defaults to path of inputpathitem.\ndef process_files_from_input(\n    product_config: ProductConfig,\n    inputpathitem: Input,\n    splitter: str,\n    inputpath: typing.Optional[str] = None,\n    input_path_count: int = 0,\n):\n    # If inputpath isn't specified assign path from item\n    if inputpath is None:\n        inputpath = inputpathitem.path\n    file_count = 0\n    md_count = 0\n    html_count = 0\n    fidl_count = 0\n    file_index = []\n    full_file_metadata = {}\n    resolved_output_path = resolve_path(product_config.output_path)\n    chunk_group_name = \"text_chunks_\" + \"{:03d}\".format(input_path_count)\n    # Get the total file count.\n    file_count = sum(len(files) for _, _, files in os.walk(resolve_path(inputpath)))\n    # Set up a status bar for the terminal display.\n    progress_bar = tqdm.tqdm(\n        total=file_count,\n        position=0,\n        bar_format=\"{percentage:3.0f}% | {n_fmt}/{total_fmt} | {elapsed}/{remaining}| {desc}\",\n    )\n    # Process each input path provided in config.yaml.\n    for root, dirs, files in os.walk(resolve_path(inputpath)):\n        if inputpathitem.exclude_path is not None:\n            dirs[:] = [d for d in dirs if d not in inputpathitem.exclude_path]\n        if inputpathitem.url_prefix is not None:\n            # Makes sure that URL ends in backslash\n            url_prefix = end_path_backslash(inputpathitem.url_prefix)\n            namespace_uuid = uuid.uuid3(uuid.NAMESPACE_DNS, url_prefix)\n        # Process the files found in this input path provided in config.yaml.\n        for file in files:\n            # Displays status bar\n            progress_bar.set_description_str(f\"Processing file {file}\", refresh=True)\n            progress_bar.update(1)\n            # Skip this file if it starts with `_`.\n            if file.startswith(\"_\"):\n                continue\n            # Get the full path to this input file.\n            filename_to_open = os.path.join(root, file)\n            # Construct a new sub-directory for storing output plain text files.\n            new_path = (\n                resolved_output_path\n                + \"/\"\n                + chunk_group_name\n                + re.sub(resolve_path(inputpath), \"\", os.path.join(root, \"\"))\n            )\n            is_exist = os.path.exists(new_path)\n            if not is_exist:\n                os.makedirs(new_path)\n            # Get the relative path to this input file.\n            relative_path = make_relative_path(\n                file=file, root=root, inputpath=inputpath\n            )\n            # Select Splitter mode: Markdown, FIDL, or HTML.\n            if splitter == \"token_splitter\" or splitter == \"process_sections\":\n                if file.endswith(\".md\"):\n                    # Add filename to a list\n                    file_index.append(relative_path)\n                    # Increment the Markdown file count.\n                    md_count += 1\n                    # Process a Markdown file.\n                    this_file_metadata = process_markdown_file(\n                        filename_to_open,\n                        root,\n                        inputpathitem,\n                        splitter,\n                        new_path,\n                        file,\n                        namespace_uuid,\n                        relative_path,\n                        url_prefix,\n                    )\n                    # Merge this file's metadata to the global metadata.\n                    full_file_metadata.update(this_file_metadata)\n            elif splitter == \"fidl_splitter\":\n                if file.endswith(\".fidl\"):\n                    # Add filename to a list\n                    file_index.append(relative_path)\n                    # Increment the FIDL file count.\n                    fidl_count += 1\n                    # Process a FIDL protocol file.\n                    this_file_metadata = process_fidl_file(\n                        filename_to_open,\n                        root,\n                        inputpathitem,\n                        splitter,\n                        new_path,\n                        file,\n                        namespace_uuid,\n                        relative_path,\n                        url_prefix,\n                    )\n                    # Merge this file's metadata to the global metadata.\n                    full_file_metadata.update(this_file_metadata)\n            else:\n                if file.endswith(\".htm\") or file.endswith(\".html\"):\n                    # Add filename to a list\n                    file_index.append(relative_path)\n                    # Increment the HTML file count.\n                    html_count += 1\n                    # Process a HTML file.\n                    this_file_metadata = process_html_file(\n                        filename_to_open,\n                        root,\n                        inputpathitem,\n                        splitter,\n                        new_path,\n                        file,\n                        namespace_uuid,\n                        relative_path,\n                        url_prefix,\n                    )\n                    # Merge this file's metadata to the global metadata.\n                    full_file_metadata.update(this_file_metadata)\n\n    # The processing of input files is finished.\n    progress_bar.set_description_str(f\"Finished processing files.\", refresh=False)\n    # Count all processed files.\n    file_count = md_count + html_count + fidl_count\n    # Print the summary of the processed files.\n    print()\n    print(\"Processed \" + str(file_count) + \" files from the source: \" + str(inputpath))\n    print(str(md_count) + \" Markdown files.\")\n    print(str(html_count) + \" HTML files.\")\n    if fidl_count > 0:\n        print(str(fidl_count) + \" FIDL files.\")\n    print()\n    return file_count, md_count, html_count, file_index, full_file_metadata\n\n\n# Write the recorded input variables into a file: `file_index.json`\ndef save_file_index_json(output_path, output_content):\n    json_out_file = resolve_path(output_path) + \"/file_index.json\"\n    with open(json_out_file, \"w\", encoding=\"utf-8\") as outfile:\n        json.dump(output_content, outfile)\n    # print(\"Created \" + json_out_file + \" to store the complete list of processed files.\")\n\n\n# Given a file, root, and inputpath, make a relative path\ndef make_relative_path(\n    file: str, inputpath: str, root: typing.Optional[str] = None\n) -> str:\n    file_slash = \"/\" + file\n    if root is None:\n        relative_path = os.path.relpath(file_slash, inputpath)\n    else:\n        relative_path = os.path.relpath(root + file_slash, inputpath)\n    return relative_path\n\n\n# Given a path, filename_prefix, chunk index, and an optional path extension (to save chunk)\n# Create a file chunk name\ndef make_file_chunk_name(\n    new_path: str, filename_prefix: str, index: int, extension: str = \"md\"\n) -> str:\n    filename_to_save = filename_prefix + \"_\" + str(index) + \".\" + extension\n    full_filename = os.path.join(new_path, filename_to_save)\n    return full_filename\n\n\n# Given a path, file, chunk index, and an optional path extension (to save chunk)\n# Create a chunk name\ndef make_chunk_name(new_path: str, file: str, index: int, extension: str = \"md\") -> str:\n    new_filename = os.path.join(new_path, file)\n    filename_to_save = new_filename\n    # Grab the filename without the .md extension\n    match = re.search(r\"(.*)\\.md$\", new_filename)\n    if match:\n        new_filename_no_ext = match[1]\n        # Save the filename appended with an index.\n        filename_to_save = new_filename_no_ext + \"_\" + str(index) + \".\" + extension\n    return filename_to_save\n\n\n# Return the relative path after the `docs-agent/data` path\ndef get_relative_path_and_filename(full_path: str):\n    path_and_filename = full_path\n    match = re.search(r\".*\\/docs-agent\\/data\\/(.*)$\", full_path)\n    if match:\n        path_and_filename = match[1]\n    return path_and_filename\n\n\n# Given a path, it resolves the path to an absolute path, and if it exists,\n# deletes it, before re-creating it (essentially making a fresh directory)\n# It then returns the absolute path name\ndef resolve_and_clear_path(path: str) -> str:\n    resolved_output_path = resolve_path(path)\n    # Remove the existing output, to make sure stale files are removed\n    if os.path.exists(resolved_output_path):\n        shutil.rmtree(resolved_output_path)\n    os.makedirs(resolved_output_path, exist_ok=True)\n    return resolved_output_path\n\n\n# Processes all inputs from a given ProductConfig object\ndef process_inputs_from_product(input_product: ProductConfig, temp_process_path: str):\n    source_file_index = {}\n    total_file_count = 0\n    total_md_count = 0\n    total_html_count = 0\n    final_file_metadata = {}\n    input_path_count = 0\n    for input_path_item in input_product.inputs:\n        print(f\"\\nInput path {input_path_count}: {input_path_item.path}\")\n        temp_output = pre_process_doc_files(\n            product_config=input_product,\n            inputpathitem=input_path_item,\n            temp_path=temp_process_path,\n        )\n        # Process Markdown files in the `input` path, when using pre_proces_doc_files\n        # temp_output should be used as inputpath parameter\n        (\n            file_count,\n            md_count,\n            html_count,\n            file_index,\n            full_file_metadata,\n        ) = process_files_from_input(\n            product_config=input_product,\n            inputpathitem=input_path_item,\n            inputpath=temp_output,\n            splitter=input_product.markdown_splitter,\n            input_path_count=input_path_count,\n        )\n        # Clear the temp_output\n        shutil.rmtree(temp_output)\n        input_path = input_path_item.path\n        if not input_path.endswith(\"/\"):\n            input_path = input_path + \"/\"\n        input_path = resolve_path(input_path)\n        # Record the input variables used in this path.\n        file_list = {}\n        for file in file_index:\n            file_obj = {file: {\"source\": input_path, \"URL\": input_path_item.url_prefix}}\n            file_list[file] = file_obj\n        # Make a single dictionary per product, append each input\n        final_file_metadata = final_file_metadata | full_file_metadata\n        # source_file_index[input_product.product_name] = full_file_metadata\n        total_file_count += file_count\n        total_md_count += md_count\n        total_html_count += html_count\n        input_path_count += 1\n    source_file_index[input_product.product_name] = final_file_metadata\n    # Write the recorded input variables into `file_index.json`.\n    save_file_index_json(\n        output_path=input_product.output_path, output_content=source_file_index\n    )\n    print(\n        \"\\n[Summary]\"\n        + f\"\\nProduct: {input_product.product_name}\"\n        + \"\\nSources: \"\n        + str(len(input_product.inputs))\n        + \"\\nTotal number of processed source files: \"\n        + str(total_file_count)\n        + \"\\nMarkdown files: \"\n        + str(total_md_count)\n        + \"\\nHTML files: \"\n        + str(total_html_count)\n    )\n\n\n# Print the size distribution map of created text chunks.\ndef get_chunk_size_distribution_from_product(input_product: ProductConfig):\n    chunk_size_map = {\n        \"50\": 0,\n        \"500\": 0,\n        \"1000\": 0,\n        \"1500\": 0,\n        \"2000\": 0,\n        \"2500\": 0,\n        \"3000\": 0,\n        \"4000\": 0,\n        \"5000\": 0,\n        \"6000\": 0,\n    }\n    total_file_count = 0\n    chunk_dir = input_product.output_path\n    for root, dirs, files in os.walk(resolve_path(chunk_dir)):\n        for file in files:\n            this_filename = os.path.join(root, file)\n            if this_filename.endswith(\".md\"):\n                file_stats = os.stat(this_filename)\n                chunk_size = int(file_stats.st_size)\n                if chunk_size <= 50:\n                    count = chunk_size_map[\"50\"]\n                    chunk_size_map[\"50\"] = count + 1\n                elif chunk_size > 50 and chunk_size <= 500:\n                    count = chunk_size_map[\"500\"]\n                    chunk_size_map[\"500\"] = count + 1\n                elif chunk_size > 500 and chunk_size <= 1000:\n                    count = chunk_size_map[\"1000\"]\n                    chunk_size_map[\"1000\"] = count + 1\n                elif chunk_size > 1000 and chunk_size <= 1500:\n                    count = chunk_size_map[\"1500\"]\n                    chunk_size_map[\"1500\"] = count + 1\n                elif chunk_size > 1500 and chunk_size <= 2000:\n                    count = chunk_size_map[\"2000\"]\n                    chunk_size_map[\"2000\"] = count + 1\n                elif chunk_size > 2000 and chunk_size <= 2500:\n                    count = chunk_size_map[\"2500\"]\n                    chunk_size_map[\"2500\"] = count + 1\n                elif chunk_size > 2000 and chunk_size <= 3000:\n                    count = chunk_size_map[\"3000\"]\n                    chunk_size_map[\"3000\"] = count + 1\n                elif chunk_size > 3000 and chunk_size <= 4000:\n                    count = chunk_size_map[\"4000\"]\n                    chunk_size_map[\"4000\"] = count + 1\n                elif chunk_size > 4000 and chunk_size <= 5000:\n                    count = chunk_size_map[\"5000\"]\n                    chunk_size_map[\"5000\"] = count + 1\n                else:\n                    count = chunk_size_map[\"6000\"]\n                    chunk_size_map[\"6000\"] = count + 1\n                total_file_count += 1\n\n    # Print the distribution result.\n    print(\"\\nSpread of text chunk sizes and counts:\")\n    prev_size = 0\n    for key in list(chunk_size_map):\n        count = chunk_size_map[key]\n        if int(key) == 50:\n            print(f\"- Chunks smaller than {key} bytes: {count}\")\n        elif int(key) == 6000:\n            print(f\"- Chunks larger than {key} bytes: {count}\")\n        else:\n            print(f\"- Chunks between {prev_size} and {key} bytes: {count}\")\n        prev_size = int(key)\n    print(f\"\\nTotal number of chunks: {total_file_count}\")\n\n\n# Given a ReadConfig object, process all products\n# Default Read config defaults to source of project with config.yaml\n# temp_process_path is where temporary files will be processed and then deleted\n# defaults to /tmp\ndef process_all_products(\n    config_file: ConfigFile = config.ReadConfig().returnProducts(),\n    temp_process_path: str = \"/tmp\",\n):\n    print(f\"Starting chunker for {str(len(config_file.products))} products.\\n\")\n    for index, product in enumerate(config_file.products):\n        print(f\"===========================================\")\n        print(f\"Processing product: {product.product_name}\")\n        # logging.error(f\"Index: {index}\")\n        # if index != 0:\n        #     old_entries = read_file_index_json(output_path=input_product.output_path)\n        #     logging.error(old_entries)\n        # else:\n        #     old_entries = None\n        print(\"Output directory: \" + resolve_and_clear_path(product.output_path))\n        print(\"Processing files from \" + str(len(product.inputs)) + \" sources.\")\n        process_inputs_from_product(\n            input_product=product, temp_process_path=temp_process_path\n        )\n\n        # Print the distribution map of text chunk sizes.\n        get_chunk_size_distribution_from_product(input_product=product)\n\n\ndef main():\n    #### Main ####\n    process_all_products()\n\n\nif __name__ == \"__main__\":\n    main()\n\n\n=== examples/gemini/python/docs-agent/docs_agent/preprocess/extract_image_path.py ===\n#\n# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\nimport os\n\nfrom absl import logging\nfrom bs4 import BeautifulSoup as bs4\nfrom docs_agent.utilities.helpers import open_file\nfrom docs_agent.utilities.helpers import trim_path_to_subdir\nimport markdown\nfrom markdown.extensions import Extension\nfrom markdown.treeprocessors import Treeprocessor\n\n\nclass ImgExtractor(Treeprocessor):\n    \"\"\"\n    This class is a Markdown treeprocessor that extracts all images from a\n    Markdown document and appends them to the markdown.images list.\n    \"\"\"\n\n    def run(self, doc):\n        \"\"\"Find all images and append to markdown.images.\"\"\"\n        self.md.images = []\n        self.md.alt_texts = []\n        self.md.image_titles = []\n        for image in doc.findall(\".//img\"):\n            self.md.images.append(image.get(\"src\"))\n            self.md.alt_texts.append(image.get(\"alt\"))\n            if image.get(\"title\") is not None:\n                self.md.image_titles.append(image.get(\"title\"))\n            else:\n                self.md.image_titles.append(\"\")\n\n\nclass ImgExtExtension(Extension):\n    \"\"\"\n    This class is a Markdown extension that registers the ImgExtractor\n    treeprocessor.\n    \"\"\"\n\n    def extendMarkdown(self, md):\n        \"\"\"Register the ImgExtractor treeprocessor with the Markdown instance.\"\"\"\n        img_ext = ImgExtractor(md)\n        md.treeprocessors.register(img_ext, \"img_ext\", 15)\n\n\ndef extract_image_path_from_markdown(markdown_text: str) -> list[str]:\n    \"\"\"Extracts all image paths from a markdown text.\"\"\"\n    md = markdown.Markdown(extensions=[ImgExtExtension()])\n    md.convert(markdown_text)\n    return md.images\n\n\ndef extract_image_alt_text_from_markdown(markdown_text: str) -> list[str]:\n    \"\"\"Extracts all image paths from a markdown text.\"\"\"\n    md = markdown.Markdown(extensions=[ImgExtExtension()])\n    md.convert(markdown_text)\n    return md.alt_texts\n\n\ndef extract_image_title_from_markdown(markdown_text: str) -> list[str]:\n    \"\"\"Extracts all image paths from a markdown text.\"\"\"\n    md = markdown.Markdown(extensions=[ImgExtExtension()])\n    md.convert(markdown_text)\n    return md.image_titles\n\n\ndef extract_image_path_from_html(html_text: str) -> list[str]:\n    \"\"\"Extracts all image paths from a html page.\"\"\"\n    soup = bs4(html_text, \"html.parser\")\n    images = []\n    for img in soup.findAll(\"img\"):\n        images.append(img[\"src\"])\n    return images\n\n\ndef extract_image_alt_text_from_html(html_text: str) -> list[str]:\n    \"\"\"Extracts all image paths from a html page.\"\"\"\n    soup = bs4(html_text, \"html.parser\")\n    alt_text = []\n    for img in soup.findAll(\"img\"):\n        alt_text.append(img[\"alt\"])\n    return alt_text\n\n\ndef extract_image_title_from_html(html_text: str) -> list[str]:\n    \"\"\"Extracts all image paths from a html page.\"\"\"\n    soup = bs4(html_text, \"html.parser\")\n    title = []\n    for img in soup.findAll(\"img\"):\n        title.append(img[\"title\"])\n    return title\n\n\ndef parse_md_html_files_for_images(input_file: str) -> dict[list[str], list[str]]:\n    \"\"\"\n    Parses a file (markdown or html) to extract image paths.\n\n    Args:\n        input_file: The path to the input file.\n\n    Returns:\n        A dictionary containing the image paths, full image paths, and current\n        alt text.\n    \"\"\"\n    image_titles = []\n    alt_texts = []\n    image_paths = []\n    if input_file.endswith(\".md\"):\n        file_content = open_file(input_file)\n        image_paths = extract_image_path_from_markdown(file_content)\n        alt_texts = extract_image_alt_text_from_markdown(file_content)\n        image_titles = extract_image_title_from_markdown(file_content)\n    elif input_file.endswith(\".html\") or input_file.endswith(\".htm\"):\n        file_content = open_file(input_file)\n        image_paths = extract_image_path_from_html(file_content)\n        alt_texts = extract_image_alt_text_from_html(file_content)\n        image_titles = extract_image_title_from_html(file_content)\n    else:\n        # This can get noisy so better to log as info.\n        logging.info(\n            \"Skipping this file since it is not a markdown or html file: \" + input_file\n        )\n    image_def = {}\n    full_image_paths = []\n    for image_path in image_paths:\n        dir_path = os.path.dirname(input_file)\n        if image_path.startswith(\"http://\") or image_path.startswith(\"https://\"):\n            logging.warning(\n                f\"Skipping this image path since it is a URL: {image_path}\\n\"\n            )\n        if image_path.startswith(\"./\"):\n            image_path = image_path.removeprefix(\"./\")\n            image_path = os.path.join(dir_path, image_path)\n            full_image_paths.append(image_path)\n        elif image_path[0].isalpha():\n            image_path = os.path.join(dir_path, image_path)\n            full_image_paths.append(image_path)\n        elif image_path.startswith(\"/\") and \"/devsite/\" in input_file:\n            # If the document is part of devsite, the path needs to be trimmed to the\n            # subdirectory (returns devsite tenant path) and then joined with the\n            # image path\n            devsite_path = trim_path_to_subdir(input_file, \"en/\")\n            image_path = image_path.removeprefix(\"/\")\n            image_path = os.path.join(devsite_path, image_path)\n            full_image_paths.append(image_path)\n        else:\n            logging.error(\n                f\"Skipping this image path because it cannot be parsed: {image_path}\\n\"\n            )\n    image_def[\"full_image_paths\"] = full_image_paths\n    image_def[\"image_paths\"] = image_paths\n    image_def[\"alt_texts\"] = alt_texts\n    image_def[\"image_titles\"] = image_titles\n    image_obj = {\"images\": image_def}\n    return image_obj\n\n\n=== examples/gemini/python/docs-agent/docs_agent/preprocess/populate_vector_database.py ===\n#\n# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n\"\"\"Populate vector databases with embeddings generated from text chunks.\"\"\"\n\nimport json\nimport os\nimport re\nimport sys\n\nfrom absl import logging\n\nimport flatdict\nimport tqdm\n\nfrom docs_agent.preprocess.splitters import markdown_splitter\nfrom docs_agent.storage.google_semantic_retriever import SemanticRetriever\nfrom docs_agent.utilities import config\nfrom docs_agent.utilities.config import ConfigFile\nfrom docs_agent.utilities.config import ProductConfig\nfrom docs_agent.utilities.helpers import end_path_backslash\nfrom docs_agent.utilities.helpers import resolve_path\nfrom docs_agent.storage.chroma import  ChromaEnhanced\n\n\nclass chromaAddSection:\n    def __init__(\n        self, section: markdown_splitter.Section, doc_title: str, metadata: dict = {}\n    ):\n        self.section = section\n        self.doc_title = doc_title\n        self.metadata = metadata\n\n\n# Get the total number of files in a directory and its subdirectories.\ndef get_file_count_in_a_dir(path):\n    file_count = sum(len(files) for _, _, files in os.walk(path))\n    return file_count\n\n\n# Return the relative path after the `docs-agent/data` path\ndef get_relative_path_and_filename(full_path: str):\n    path_and_filename = full_path\n    match = re.search(r\".*\\/docs-agent\\/data\\/(.*)$\", full_path)\n    if match:\n        path_and_filename = match[1]\n    return path_and_filename\n\n\n# Prepare progres bars for showing files being processed and uploaded.\ndef init_progress_bars(file_count):\n    print()\n    main = tqdm.tqdm(\n        total=file_count,\n        position=0,\n        bar_format=\"{percentage:3.0f}% | {n_fmt}/{total_fmt} | {elapsed}/{remaining} | {desc}\",\n    )\n    new_file = tqdm.tqdm(position=1, desc=\"Total new files 0\", bar_format=\"{desc}\")\n    unchanged_file = tqdm.tqdm(\n        position=2, desc=\"Total unchanged files 0\", bar_format=\"{desc}\"\n    )\n    return main, new_file, unchanged_file\n\n\n# Open a file and return its content.\ndef get_file_content(full_path):\n    content_file = \"\"\n    with open(full_path, \"r\", encoding=\"utf-8\") as auto:\n        content_file = auto.read()\n        content_file.strip()\n        auto.close()\n    return content_file\n\n# Upload a text chunk to an online stroage using the Semantic Retrieval API.\ndef upload_an_entry_to_a_corpus(\n    semantic, corpus_name, document_name_in_corpus, this_item, is_this_first_chunk\n):\n    document_name = document_name_in_corpus\n    # Check if a document for this chunk exists.\n    if is_this_first_chunk == True:\n        origin_uuid = \"\"\n        if hasattr(this_item.section, \"origin_uuid\"):\n            origin_uuid = this_item.section.origin_uuid\n        try:\n            # Create a new document\n            document_name = semantic.create_a_doc(\n                corpus_name=corpus_name,\n                page_title=this_item.section.page_title,\n                uuid=origin_uuid,\n            )\n        except:\n            logging.error(\n                f\"Cannot create a new document using the Semantic Retrieval API: {str(this_item.section.page_title)}\"\n            )\n    uuid_dict = {\"UUID\": this_item.section.uuid}\n    dict_with_uuid = this_item.metadata | uuid_dict\n    try:\n        # Create a new chunk\n        semantic.create_a_chunk(\n            doc_name=document_name,\n            text=this_item.section.content,\n            metadata=dict_with_uuid,\n        )\n        logging.info(\"Added the text chunk using the Semantic Retrieval API.\")\n    except:\n        logging.error(dict_with_uuid)\n        logging.error(this_item.section)\n        logging.error(\"Cannot add the text chunk using the Semantic Retrieval API.\")\n    return document_name\n\n\n# Delete entries in the Chroma database if we cannot find matches in the current dataset.\ndef delete_unmatched_entries_in_chroma(\n    product_config: ProductConfig, chroma_client, collection\n):\n    print()\n    print(f\"Scanning the Chroma database to identify entries to be deleted.\")\n    # Arrays to store IDs, text chunk filename, and md hashes of\n    # the existing entries in the local Chroma vector database.\n    existing_online_entry_ids = []\n    existing_online_entry_text_chunk_filenames = []\n    existing_online_entry_md_hashes = []\n    # Get all entries in the vector database.\n    all_entries = collection.get()\n    for entry in all_entries[\"ids\"]:\n        # logging.error(f\"ID: {entry}\")\n        existing_online_entry_ids.append(str(entry))\n    for entry in all_entries[\"metadatas\"]:\n        # logging.error(f\"Metadata: {entry}\")\n        text_chunk_filename = \"\"\n        md_hash = \"\"\n        if \"text_chunk_filename\" in entry:\n            text_chunk_filename = entry[\"text_chunk_filename\"]\n        if \"md_hash\" in entry:\n            md_hash = entry[\"md_hash\"]\n        # logging.error(f\"Text chunk filename: {text_chunk_filename}\")\n        # logging.error(f\"MD HASH: {md_hash}\")\n        existing_online_entry_text_chunk_filenames.append(str(text_chunk_filename))\n        existing_online_entry_md_hashes.append(str(md_hash))\n\n    # Examine the new candidate entries in the current `data` directory.\n    candidate_entries = {}\n    (index_object, full_index_path) = load_index(input_path=product_config.output_path)\n    for product in index_object:\n        dictionary_input = index_object[product]\n    # Extract the text chunk name and hash from each chunk data.\n    for item in dictionary_input:\n        chunk_data = dictionary_input[item]\n        text_chunk_filename = \"\"\n        text_chunk_md_hash = \"\"\n        # print(f\"Candidate text chunk data: {chunk_data}\")\n        if \"text_chunk_filename\" in chunk_data:\n            text_chunk_filename = chunk_data[\"text_chunk_filename\"]\n        if \"md_hash\" in chunk_data:\n            text_chunk_md_hash = chunk_data[\"md_hash\"]\n        # print(f\"Candidate text chunk filename: {text_chunk_filename}\")\n        if text_chunk_filename != \"\":\n            candidate_entries[text_chunk_filename] = text_chunk_md_hash\n\n    # Compare the existing online entries to the candidate entries.\n    to_be_deleted_online_entry_ids = []\n    index = 0\n    for index, item in enumerate(existing_online_entry_text_chunk_filenames):\n        existing_text_chunk = item\n        existing_md_hash = existing_online_entry_md_hashes[index]\n        existing_id = existing_online_entry_ids[index]\n        if existing_text_chunk in candidate_entries:\n            candidate_md_hash = candidate_entries[existing_text_chunk]\n            if existing_md_hash != candidate_md_hash:\n                logging.info(\n                    f\"The entry {existing_text_chunk} in the Chroma database \"\n                    + \"will be deleted because its content has changed.\"\n                )\n                to_be_deleted_online_entry_ids.append(existing_id)\n        else:\n            logging.info(\n                f\"The entry {existing_text_chunk} in the Chroma database \"\n                + \"will be deleted because it is no longer found in the current dataset.\"\n            )\n            to_be_deleted_online_entry_ids.append(existing_id)\n\n    # Delete identified entries in the Chroma database.\n    if to_be_deleted_online_entry_ids:\n        collection.delete(ids=to_be_deleted_online_entry_ids)\n        deleted_entries_count = len(to_be_deleted_online_entry_ids)\n        print(f\"Deleted entries count: {deleted_entries_count}\")\n    else:\n        print(f\"Keeping all existing entries in the Chroma database.\")\n    return to_be_deleted_online_entry_ids\n\n\n# Delete entries in the online corpus if we cannot find matches in the current dataset.\ndef delete_unmatched_entries_in_online_corpus(\n    product_config: ProductConfig, semantic_object, corpus_name\n):\n    print()\n    print(f\"Scanning the online corpus to identify chunks to be deleted.\")\n    print(f\"(This may take some time.)\")\n    # Get all chunks in the online corpus.\n    all_chunks = []\n    all_docs = semantic_object.get_all_docs(corpus_name=corpus_name, print_output=False)\n    for doc in all_docs:\n        doc_name = str(doc.name)\n        chunks = semantic_object.get_all_chunks(doc_name=doc_name, print_output=False)\n        for chunk in chunks:\n            all_chunks.append(chunk)\n\n    # Examine the new candidate entries in the current `data` directory.\n    candidate_entries = {}\n    (index_object, full_index_path) = load_index(input_path=product_config.output_path)\n    for product in index_object:\n        dictionary_input = index_object[product]\n    # Extract the text chunk name and hash from each chunk data.\n    for item in dictionary_input:\n        chunk_data = dictionary_input[item]\n        text_chunk_filename = \"\"\n        text_chunk_md_hash = \"\"\n        # print(f\"Candidate text chunk data: {chunk_data}\")\n        if \"text_chunk_filename\" in chunk_data:\n            text_chunk_filename = chunk_data[\"text_chunk_filename\"]\n        if \"md_hash\" in chunk_data:\n            text_chunk_md_hash = chunk_data[\"md_hash\"]\n        # print(f\"Candidate text chunk filename: {text_chunk_filename}\")\n        if text_chunk_filename != \"\":\n            candidate_entries[text_chunk_filename] = text_chunk_md_hash\n\n    # Compare the existing online entries to the candidate entries.\n    to_be_deleted_online_chunk_names = []\n    for chunk in all_chunks:\n        existing_chunk_name = chunk.name\n        existing_md_hash = \"\"\n        existing_text_chunk_filename = \"\"\n        metadata = chunk.custom_metadata\n        for item in metadata:\n            if item.key == \"md_hash\":\n                # print(f\"md_hash: {item.string_value}\")\n                existing_md_hash = item.string_value\n            elif item.key == \"text_chunk_filename\":\n                # print(f\"text_chunk_filename: {item.string_value}\")\n                existing_text_chunk_filename = item.string_value\n        if existing_text_chunk_filename in candidate_entries:\n            candidate_md_hash = candidate_entries[existing_text_chunk_filename]\n            if existing_md_hash != candidate_md_hash:\n                logging.info(\n                    f\"{existing_text_chunk_filename} in the online corpus \"\n                    + \"will be deleted because its content has changed.\"\n                )\n                to_be_deleted_online_chunk_names.append(existing_chunk_name)\n        else:\n            logging.info(\n                f\"{existing_text_chunk_filename} in the online corpus will be \"\n                + \"deleted because it is no longer found in the current dataset.\"\n            )\n            to_be_deleted_online_chunk_names.append(existing_chunk_name)\n\n    # Delete identified chunks in the online corpus.\n    if to_be_deleted_online_chunk_names:\n        # Initialize a progress bar object.\n        progress_bar = tqdm.tqdm(\n            position=0, desc=\"Deleting the chunk\", bar_format=\"{desc}\"\n        )\n        # Loop for deleting chunks online.\n        for chunk_name in to_be_deleted_online_chunk_names:\n            # progress_bar.update(1)\n            progress_bar.set_description_str(\n                f\"Deleting the chunk {chunk_name}\", refresh=True\n            )\n            semantic_object.delete_a_chunk(chunk_name)\n        delete_count = len(to_be_deleted_online_chunk_names)\n        progress_bar.set_description_str(\n            f\"Deleted chunks count: {delete_count}\", refresh=False\n        )\n    else:\n        print(f\"Keeping all existing chunks in the online corpus.\")\n    return to_be_deleted_online_chunk_names\n\n\n# Read plain text files (.md) from an input dir and\n# add their content to the vector database.\n# Embeddings are generated automatically as they are added to the database.\ndef populateToDbFromProduct(product_config: ProductConfig):\n    \"\"\"Populates the vector database with product documentation.\n    Args:\n        product_config: A ProductConfig object containing configuration details.\n    \"\"\"\n    logging.info(\"Starting populateToDbFromProduct\")\n    # Initialize variables\n    chroma_collection = None\n    semantic = None\n    corpus_name = \"\"\n\n    # Initialize Chroma database and collection\n    for db_conf in product_config.db_configs:\n        if \"chroma\" in db_conf.db_type:\n            logging.info(\"Initializing Chroma.\")\n            try:\n                chroma = ChromaEnhanced(\n                    chroma_dir=resolve_path(db_conf.vector_db_dir),\n                    models_config=product_config.models,\n                )\n                logging.info(f\"Attempting to get or create collection '{db_conf.collection_name}'\")\n                chroma_collection = chroma.client.get_or_create_collection(\n                    name=db_conf.collection_name,\n                    embedding_function=chroma.embedding_function_instance,\n                )\n                logging.info(f\"Successfully got or created collection '{db_conf.collection_name}'\")\n                # Delete unmatched entries in Chroma\n                if (\n                    hasattr(product_config, \"enable_delete_chunks\")\n                    and product_config.enable_delete_chunks == \"True\"\n                ):\n                    delete_unmatched_entries_in_chroma(\n                        product_config, chroma.client, chroma_collection\n                    )\n                break\n            except Exception as e:\n                logging.error(f\"Failed to initialize Chroma DB or collection '{db_conf.collection_name}': {e}\", exc_info=True)\n                return\n\n    # Initialize Semantic Retrieval API (if enabled)\n    if (\"google_semantic_retriever\" in product_config.db_type):\n        logging.info(\"Initializing the Semantic Retrieval API for an online storage.\")\n        semantic = SemanticRetriever()\n        for db_conf in product_config.db_configs:\n            if \"google_semantic_retriever\" in db_conf.db_type:\n                corpus_name = db_conf.corpus_name\n                try:\n                    if not semantic.does_this_corpus_exist(corpus_name):\n                        semantic.create_a_new_corpus(db_conf.corpus_display, corpus_name)\n                    elif (\n                        hasattr(product_config, \"enable_delete_chunks\")\n                        and product_config.enable_delete_chunks == \"True\"\n                    ):\n                        delete_unmatched_entries_in_online_corpus(\n                            product_config, semantic, corpus_name\n                        )\n                    break\n                except Exception as e:\n                    logging.error(f\"Failed to initialize Semantic Retriever Corpus '{corpus_name}': {e}\", exc_info=True)\n                    semantic = None\n                break\n\n    # Check for Chroma collection initialization\n    if chroma_collection is None and any(\"chroma\" in db_conf.db_type for db_conf in product_config.db_configs):\n        logging.error(\"Chroma collection could not be initialized. Aborting population.\")\n        return\n\n    # Load the index file\n    logging.info(f\"Loading file index... {product_config.output_path}\")\n    index, full_index_path = load_index(input_path=product_config.output_path)\n    logging.info(\"File index loaded.\")\n    # Resolve the output path\n    resolved_walk_path = resolve_path(product_config.output_path)\n    logging.info(f\"Starting file processing in directory: {resolved_walk_path}\")\n    if not os.path.isdir(resolved_walk_path):\n        logging.error(f\"Target directory does not exist or is not a directory: {resolved_walk_path}\")\n        return\n\n    # Get the file count in the directory\n    file_count = get_file_count_in_a_dir(resolved_walk_path)\n    logging.info(f\"Using os.walk file count ({file_count}) for main progress bar.\")\n    # Initialize progress bars\n    progress_bar, progress_new_file, progress_unchanged_file = init_progress_bars(file_count)\n\n    # Counters\n    total_files_processed = 0\n    new_count = 0\n    unchanged_count = 0\n    skipped_invalid_uuid_count = 0\n    skipped_other_count = 0\n\n    # Semantic Retriever state\n    document_name_in_corpus = \"\"\n    dict_document_names_in_corpus = {}\n\n    # Loop through the files in the directory\n    for root, dirs, files in os.walk(resolved_walk_path):\n        for file in files:\n            # Update main progress bar based on os.walk count total\n            progress_bar.update(1)\n            progress_bar.set_description_str(f\"Processing file {file}\", refresh=True)\n            full_file_name = os.path.join(root, file)\n            # Skip the index file itself\n            if full_file_name == full_index_path:\n                continue\n            if file.endswith(\".md\"):\n                try:\n                    content_file = get_file_content(full_file_name)\n                    chroma_add_item = findFileinDict(\n                        input_file_name=full_file_name,\n                        index_object=index,\n                        content_file=content_file,\n                    )\n                    # Check for invalid content\n                    if not chroma_add_item.section.content:\n                        logging.warning(f\"Skipping {file}: Content is empty.\")\n                        skipped_other_count += 1\n                        continue\n                    if len(chroma_add_item.section.content) >= 10000:\n                        logging.warning(f\"Skipping {file}: Content too large ({len(chroma_add_item.section.content)} bytes).\")\n                        skipped_other_count += 1\n                        continue\n                    if not chroma_add_item.section.md_hash:\n                         logging.warning(f\"Skipping {file}: Missing md_hash in index data.\")\n                         skipped_other_count += 1\n                         continue\n\n                    # Check for invalid UUID\n                    uuid_value = chroma_add_item.section.uuid\n                    if not isinstance(uuid_value, str) or not uuid_value:\n                        logging.error(f\"File {file}: Invalid UUID detected ({repr(uuid_value)}). Skipping operation for this file.\")\n                        skipped_invalid_uuid_count += 1\n                        continue\n                    id_to_not_change = []\n                    # Check for Chroma collection existence\n                    if chroma_collection:\n                        try:\n                            ids_to_check = [uuid_value]\n                            get_result = chroma_collection.get(\n                                ids=ids_to_check,\n                                where={\"md_hash\": {\"$eq\": chroma_add_item.section.md_hash}},\n                                include=[],\n                            )\n                            id_to_not_change = get_result[\"ids\"]\n                        except Exception as e:\n                            if \"does not exist\" in str(e).lower():\n                                 id_to_not_change = []\n                            else:\n                                 logging.warning(f\"File {file}: Error in Chroma to get for ID {uuid_value}: {e}\")\n                                 id_to_not_change = []\n\n                    # Check for existing entry with same hash\n                    if id_to_not_change:\n                        # Exists with same hash -> Unchanged\n                        qty_change = len(id_to_not_change)\n                        unchanged_count += qty_change\n                        total_files_processed += qty_change\n                        progress_unchanged_file.update(qty_change)\n                        progress_unchanged_file.set_description_str(f\"Total unchanged files {unchanged_count}\", refresh=True)\n                    else:\n                        # New or updated entry\n                        if chroma_collection:\n                            try:\n                                doc_list = [chroma_add_item.section.content]\n                                meta_list = [chroma_add_item.metadata]\n                                id_list = [uuid_value]\n                                # Upsert the entry\n                                chroma_collection.upsert(\n                                    documents=doc_list,\n                                    metadatas=meta_list,\n                                    ids=id_list,\n                                )\n                                new_count += 1\n                                total_files_processed += 1\n                                progress_new_file.update(1)\n                                progress_new_file.set_description_str(f\"Total new/updated files {new_count}\", refresh=True)\n\n                            except Exception as e:\n                                # Keep this error log\n                                logging.error(f\"Error during collection.upsert for ID {uuid_value}: {e}\", exc_info=True)\n                                skipped_other_count += 1\n                        else:\n                             logging.warning(f\"File {file}: Skipping add/upsert because Chroma collection is not available.\")\n                             skipped_other_count += 1\n\n                        # Check for Semantic Retriever initialization\n                        if semantic and corpus_name:\n                            file_page_prefix = full_file_name\n                            is_this_first_chunk = True\n                            match_file_page = re.search(r\"(.*)_\\d+\\.md$\", full_file_name)\n                            if match_file_page:\n                                file_page_prefix = match_file_page.group(1)\n                                if file_page_prefix in dict_document_names_in_corpus:\n                                    document_name_in_corpus = dict_document_names_in_corpus[file_page_prefix]\n                                    is_this_first_chunk = False\n                                else:\n                                     document_name_in_corpus = \"\"\n\n                            try:\n                                document_name = upload_an_entry_to_a_corpus(\n                                    semantic,\n                                    corpus_name,\n                                    document_name_in_corpus,\n                                    chroma_add_item,\n                                    is_this_first_chunk,\n                                )\n                                dict_document_names_in_corpus[file_page_prefix] = document_name\n                            except Exception as e:\n                                logging.error(f\"Failed to upload chunk for {file} to Semantic Retriever: {e}\", exc_info=True)\n\n                except Exception as e:\n                    # Keep this error log for file-level processing errors\n                    logging.error(f\"Error processing file {full_file_name}: {e}\", exc_info=True)\n                    skipped_other_count += 1\n            else:\n                 # Skip non-markdown files\n                 pass\n\n    # Close all progress bars\n    progress_bar.set_description_str(f\"Finished processing.\", refresh=True)\n    progress_bar.close()\n    progress_new_file.close()\n    progress_unchanged_file.close()\n\n    # Simplified final summary print\n    print(f\"\\nProcessing Summary:\")\n    print(f\"  Total files found for database: {total_files_processed}\")\n    print(f\"  New or updated files:   {new_count}\")\n    print(f\"  Unchanged files:     {unchanged_count}\")\n    # Optionally report skipped counts if they are non-zero, otherwise omit for cleaner output\n    if skipped_invalid_uuid_count > 0:\n        print(f\"  Skipped (Invalid UUID):  {skipped_invalid_uuid_count}\")\n    if skipped_other_count > 0:\n        print(f\"  Skipped (Other reasons): {skipped_other_count}\")\n\n    print(f\"\\nFinished processing and generating embeddings for all files.\")\n    if any(\"chroma\" in db_conf.db_type for db_conf in product_config.db_configs):\n        print(\"Finalized generation of embeddings for all files in Chroma DB.\")\n\n\ndef findFileinDict(input_file_name: str, index_object, content_file):\n    metadata_dict_final = {}\n    for product in index_object:\n        dictionary_input = index_object[product]\n    if input_file_name in dictionary_input:\n        chunk_data = dictionary_input[input_file_name]\n        # Extract the text chunk name from the index object.\n        text_chunk_filename = \"\"\n        if \"text_chunk_filename\" in chunk_data:\n            text_chunk_filename = chunk_data[\"text_chunk_filename\"]\n            # logging.error(f\"Chunk name: {text_chunk_filename}\")\n        # If metadata exists, add these to a dictionary that is then\n        # merged with other metadata values\n        if \"metadata\" in dictionary_input[input_file_name]:\n            # Save and flatten dictionary\n            metadata_dict_extra = extract_extra_metadata(\n                input_dictionary=dictionary_input[input_file_name][\"metadata\"]\n            )\n        else:\n            metadata_dict_extra = {}\n        section = markdown_splitter.DictionarytoSection(\n            dictionary_input[input_file_name]\n        )\n        if \"URL\" in metadata_dict_extra:\n            section.url = metadata_dict_extra[\"URL\"]\n        # Merges dictionaries with main metadata and additional metadata\n        section.content = content_file\n        # Combines Section db in dictionary with extra\n        metadata_dict_final = section.encodeToChromaDBNoContent() | metadata_dict_extra\n        # Add the text chunk filename to the metadata.\n        if text_chunk_filename != \"\":\n            metadata_dict_final[\"text_chunk_filename\"] = text_chunk_filename\n        # Overide title if it exists from frontmatter\n        if \"title\" in metadata_dict_final:\n            doc_title = str(metadata_dict_final[\"title\"])\n        else:\n            doc_title = section.createChunkTitle()\n        # print(\"Title: \" + doc_title)\n    else:\n        doc_title = \"\"\n        section = markdown_splitter.DictionarytoSection(metadata_dict_final)\n        logging.info(f\"{input_file_name} not found.\")\n    chroma_add = chromaAddSection(\n        section=section, metadata=metadata_dict_final, doc_title=doc_title\n    )\n    return chroma_add\n\n\n# Load the file index information from the file_index.json file.\ndef load_index(\n    input_path: str, input_index_name: str = \"file_index.json\"\n) -> tuple[dict, str]:\n    \"\"\"Loads the file index.\n    Args:\n        input_path: The path to the input directory.\n\n    Returns:\n        A tuple containing the loaded index and the full index path.\n    \"\"\"\n    full_index_path = resolve_path(end_path_backslash(input_path) + input_index_name)\n    try:\n        with open(full_index_path, \"r\", encoding=\"utf-8\") as index_file:\n            logging.info(\"Using file index: \" + full_index_path + \"\\n\")\n            index = json.load(index_file)\n            return index, full_index_path\n    except FileNotFoundError:\n        logging.error(\n            f\"The file {full_index_path} does not exist. Re-chunk your project with docsAgent chunk\"\n        )\n        return sys.exit(1)\n\n\n# Given a ReadConfig object, process all products\n# Default Read config defaults to source of project with config.yaml\n# temp_process_path is where temporary files will be processed and then deleted\n# defaults to /tmp\ndef process_all_products(\n    config_file: ConfigFile = config.ReadConfig().returnProducts(),\n):\n    print(\n        f\"Starting to verify files to populate database for {str(len(config_file.products))} products.\\n\"\n    )\n    for product in config_file.products:\n        print(f\"===========================================\")\n        print(f\"Processing product: {product.product_name}\")\n        print(f\"Input directory: {resolve_path(product.output_path)}\")\n        print(f\"Database operation db type: {product.db_type}\")\n        print()\n        for item in product.db_configs:\n            print(f\"{item}\")\n        print(f\"===========================================\")\n        populateToDbFromProduct(product_config=product)\n\n\ndef extract_extra_metadata(input_dictionary):\n    metadata_dict_extra = flatdict.FlatterDict(\n        input_dictionary,\n        delimiter=\"_\",\n    )\n    metadata_dict_extra = dict(metadata_dict_extra)\n    return metadata_dict_extra\n\n\n=== examples/gemini/python/docs-agent/docs_agent/preprocess/splitters/fidl_splitter.py ===\n#\n# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\nimport re\nimport os\nfrom absl import logging\n\n\n# Get the byte size of lines.\ndef get_byte_size(lines):\n    buffer_size = 0\n    for line in lines:\n        buffer_size += len(line.encode(\"utf-8\"))\n    return buffer_size\n\n\n# Prepare a FIDL protocol into a text chunk to be stored.\ndef construct_a_chunk(library_name: str, protocol_name: str, lines):\n    content_to_store = \"\"\n    content_to_store += \"Library name: \" + library_name + \"\\n\"\n    content_to_store += \"Protocol name: \" + protocol_name + \"\\n\\n\"\n    content_to_store += (\n        \"In Fuchsia's \"\n        + library_name\n        + \" FIDL library, the \"\n        + protocol_name\n        + \" protocol interface is defined as the following:\\n\\n\"\n    )\n    content_to_store += \"<code>\\n\"\n    for line in lines:\n        content_to_store += line + \"\\n\"\n    content_to_store += \"</code>\\n\"\n    return content_to_store\n\n\n# Divide a large protocol into two text chunks.\ndef divide_a_protocol(lines):\n    half_point = len(lines) // 2\n    first_half = lines[:half_point]\n    second_half = lines[half_point:]\n    return first_half, second_half\n\n\n# Recursively process a FIDL protocol into text chunks.\ndef construct_chunks(library_name: str, protocol_name: str, lines):\n    contents = []\n    buffer_size = get_byte_size(lines)\n    if int(buffer_size) > 5000:\n        # If the protocol is larget than 5KB, divide it into two.\n        logging.info(\n            \"Found a text chunk (\"\n            + str(protocol_name)\n            + \") is greater than 6KB (size: \"\n            + str(buffer_size)\n            + \").\"\n        )\n        (first_half, second_half) = divide_a_protocol(lines)\n        first_content = construct_chunks(library_name, protocol_name, first_half)\n        second_content = construct_chunks(library_name, protocol_name, second_half)\n        contents += first_content\n        contents += second_content\n    else:\n        # Prepare a text chunk that describes a FIDL protocol.\n        content = construct_a_chunk(library_name, protocol_name, lines)\n        logging.info(\n            \"Created a text chunk for \"\n            + str(protocol_name)\n            + \" (size: \"\n            + str(buffer_size)\n            + \").\"\n        )\n        contents.append(content)\n    return contents\n\n\n# Split a FIDL file into protocols as text chunks.\ndef split_file_to_protocols(this_file):\n    protocols = []\n    line_buffer = []\n    protocol_name = \"\"\n    library_name = \"\"\n    index = 0\n    for line in this_file.split(\"\\n\"):\n        match_protocol = re.search(r\"^closed\\s+protocol\\s+(.*)\\s+\\{\", line)\n        match_library = re.search(r\"^library\\s+(.*);\", line)\n        match_comment = re.search(r\"^\\s*\\/\\/\\/\\s+(.*)\", line)\n        match_new_line = re.search(r\"^\\s*$\", line)\n        match_end_bracket = re.search(r\"^};\", line)\n        if match_protocol:\n            # print(\"MATCHED [Protocol]: \" + match_protocol.group(1))\n            protocol_name = match_protocol.group(1)\n            line_buffer.append(line)\n        elif match_library:\n            # print(\"MATCHED [Library]: \" + match_library.group(1))\n            library_name = match_library.group(1)\n        elif match_comment:\n            # print(\"MATCHED [Comment]: \" + match_comment.group(1))\n            line_buffer.append(line)\n        elif match_new_line:\n            # print(\"MATCHED [New line]\")\n            line_buffer.append(line)\n        elif match_end_bracket:\n            # print(\"MATCHED [End bracket]\")\n            line_buffer.append(line)\n            if library_name != \"\" and protocol_name != \"\":\n                # Prepre a captured FIDL protocl into small text chunks.\n                contents = construct_chunks(library_name, protocol_name, line_buffer)\n                for content in contents:\n                    protocols.append(content)\n            # Clear the line butter and protocol name when an end bracket is found.\n            line_buffer.clear()\n            protocol_name = \"\"\n        else:\n            line_buffer.append(line)\n        index += 0\n    return protocols\n\n\n=== examples/gemini/python/docs-agent/docs_agent/preprocess/splitters/html_splitter.py ===\n#\n# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\nimport re, os\nfrom docs_agent.preprocess.splitters import markdown_splitter\n\n\n# This function replaces HTML's includes sections with content.\ndef process_html_includes(html_text, root):\n    updated_html = \"\"\n    for line in html_text.split(\"\\n\"):\n        # Replaces HTML includes (Jinja) with content (html include can happen\n        # with indents)\n        try:\n            include_match = re.search('{% include \"(.*?)\" %}', line)\n            include_file = os.path.abspath(root + \"/\" + include_match[1])\n            # Tries to open include and errors if it doesn't exist\n            try:\n                html_include = markdown_splitter.verify_file(include_file)\n                if html_include is str:\n                    updated_html += html_include + \"\\n\"\n                else:\n                    updated_html += \"\\n\"\n            except FileNotFoundError:\n                # If the file doesn't exist, remove the include statement to\n                # avoid polluting content\n                updated_html += \"\\n\"\n        except:\n            updated_html += line + \"\\n\"\n    return updated_html\n\n\n=== examples/gemini/python/docs-agent/docs_agent/preprocess/splitters/__init__.py ===\n\n\n=== examples/gemini/python/docs-agent/docs_agent/preprocess/splitters/markdown_splitter.py ===\n#\n# Copyright 2023 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\nimport typing\nimport markdown\nimport bs4\nimport re, os\nfrom absl import logging\nfrom docs_agent.models import tokenCount\nimport frontmatter\nfrom docs_agent.utilities.helpers import add_scheme_url\n\n\nclass Section:\n    def __init__(\n        self,\n        id: int,\n        name_id: str,\n        page_title: str,\n        section_title: str,\n        level: int,\n        previous_id: int,\n        parent_tree: list[int],\n        token_count: float,\n        content: str,\n        url: typing.Optional[str] = None,\n        origin_uuid: typing.Optional[str] = None,\n        md_hash: typing.Optional[str] = None,\n        uuid: typing.Optional[str] = None,\n    ):\n        self.id = id\n        self.name_id = name_id\n        self.page_title = page_title\n        self.section_title = section_title\n        self.level = level\n        self.previous_id = previous_id\n        self.parent_tree = parent_tree\n        self.token_count = token_count\n        self.content = content\n        self.url = url\n        self.origin_uuid = origin_uuid\n        self.md_hash = md_hash\n        self.uuid = uuid\n\n    def __str__(self):\n        return f\"UUID: {self.uuid}\\n\\\nID: {self.id}\\n\\\nName ID: {self.name_id}\\n\\\nOrigin UUID: {self.origin_uuid}\\n\\\nPage title: {self.page_title}\\n\\\nSection title: {self.section_title}\\n\\\nURL: {self.url}\\n\\\nLevel: {self.level}\\n\\\nParent ID: {self.previous_id}\\n\\\nParent tree: {self.parent_tree}\\n\\\nTokens: {self.token_count}\\n\\\nContent hash: {self.md_hash}\\n\"\n\n    # Updates the content of a section using page and section title\n    def updateContentTemplate(self):\n        new_content = f\"The section titled {self.section_title} is from the page titled {self.page_title} and has this content:\\n{self.content}\"\n        self.content = new_content\n        return self\n\n    # Given a section, return the id of the parent. If no, parent returns 0\n    # 0 is equivalent to the top of the page\n    def returnDirectParentId(self):\n        parent_tree = eval(self.parent_tree)\n        # Prepare direct_parent variable\n        if len(parent_tree) > 1:\n            direct_parent = parent_tree[len(parent_tree) - 1]\n        # If the curr_parent_tree has a len of 0, this means that no parents\n        if len(parent_tree) == 0:\n            no_parent = True\n            direct_parent = 0\n        else:\n            no_parent = False\n            direct_parent = parent_tree[len(parent_tree) - 1]\n        return direct_parent\n\n    def encodeToChromaDBNoContent(self):\n        metadata = {}\n        metadata.update({\"section_id\": int(self.id)})\n        metadata.update({\"section_name_id\": str(self.name_id)})\n        metadata.update({\"section_title\": str(self.section_title)})\n        metadata.update({\"page_title\": str(self.page_title)})\n        metadata.update({\"section_level\": int(self.level)})\n        metadata.update({\"previous_id\": int(self.previous_id)})\n        # Lists like parent_tree need to be converted to str\n        metadata.update({\"parent_tree\": str(self.parent_tree)})\n        metadata.update({\"token_estimate\": float(self.token_count)})\n        metadata.update({\"origin_uuid\": str(self.origin_uuid)})\n        metadata.update({\"md_hash\": str(self.md_hash)})\n        metadata.update({\"url\": str(self.url)})\n        return metadata\n\n    def createChunkTitle(self):\n        if self.page_title == self.section_title:\n            doc_title = self.page_title\n        else:\n            doc_title = f\"{self.page_title} - {self.section_title}\"\n        return doc_title\n\n    def return_id(self):\n        return self.id\n\n\ndef DictionarytoSection(metadata: dict) -> Section:\n    if \"section_id\" in metadata and metadata[\"section_id\"] != '':\n        section_id = int(metadata[\"section_id\"])\n    else:\n        section_id = \"\"\n    if \"section_name_id\" in metadata:\n        section_name_id = str(metadata[\"section_name_id\"])\n    else:\n        section_name_id = \"\"\n    if \"section_title\" in metadata:\n        section_title = str(metadata[\"section_title\"])\n    else:\n        section_title = \"\"\n    if \"page_title\" in metadata:\n        page_title = str(metadata[\"page_title\"])\n    else:\n        page_title = \"\"\n    if \"section_level\" in metadata and metadata[\"section_level\"] != '':\n        section_level = int(metadata[\"section_level\"])\n    else:\n        section_level = \"\"\n    if \"previous_id\" in metadata and metadata[\"previous_id\"] != '':\n        previous_id = int(metadata[\"previous_id\"])\n    else:\n        previous_id = \"\"\n    if \"parent_tree\" in metadata:\n        parent_tree = metadata[\"parent_tree\"]\n    else:\n        parent_tree = []\n    if \"token_estimate\" in metadata and metadata[\"token_estimate\"] != '':\n        token_estimate = int(metadata[\"token_estimate\"])\n    else:\n        token_estimate = \"\"\n    if \"content\" in metadata:\n        content = str(metadata[\"content\"])\n    else:\n        content = \"\"\n    if \"URL\" in metadata:\n        url = str(metadata[\"URL\"])\n    elif \"url\" in metadata:\n        url = str(metadata[\"url\"])\n    else:\n        url = \"\"\n    if \"origin_uuid\" in metadata:\n        origin_uuid = str(metadata[\"origin_uuid\"])\n    else:\n        origin_uuid = \"\"\n    if \"md_hash\" in metadata:\n        md_hash = str(metadata[\"md_hash\"])\n    else:\n        md_hash = \"\"\n    if \"UUID\" in metadata:\n        UUID = str(metadata[\"UUID\"])\n    else:\n        UUID = \"\"\n    section = Section(\n        id=section_id,\n        name_id=section_name_id,\n        page_title=page_title,\n        section_title=section_title,\n        level=section_level,\n        previous_id=previous_id,\n        parent_tree=parent_tree,\n        token_count=token_estimate,\n        content=content,\n        url=url,\n        origin_uuid=origin_uuid,\n        md_hash=md_hash,\n        uuid=UUID,\n    )\n    return section\n\n\nclass Page:\n    def __init__(\n        self,\n        title: str,\n        URL: str,\n        section_count: int,\n        metadata: typing.Optional[dict] = None,\n    ):\n        self.title = title\n        self.URL = URL\n        self.section_count = section_count\n        self.metadata = metadata\n\n    def __str__(self):\n        return f\"This is a page with the following properties:\\n\\\nTitle: {self.title}\\n\\\nURL: {self.URL}\\n\\\nSection Count: {self.section_count}\\n\\\nMetadata: {self.metadata}\\n\"\n\n\n# This function converts a Markdown string to plain text.\ndef markdown_to_text(markdown_string):\n    # Remove <!-- --> lines in Markdown\n    markdown_string = re.sub(r\"<\\!--(.*?)-->\", \"\", markdown_string)\n    # md -> html -> text since BeautifulSoup can extract text cleanly\n    html = markdown.markdown(markdown_string)\n    # Extract text\n    soup = bs4.BeautifulSoup(html, \"html.parser\")\n    text = \"\".join(soup.find_all(string=True))\n    # Remove [][] in Markdown\n    text = re.sub(r\"\\[(.*?)\\]\\[(.*?)\\]\", \"\\\\1\", text)\n    # Remove {: } in Markdown\n    text = re.sub(r\"\\{:(.*?)\\}\", \"\", text)\n    # Remove {. } in Markdown\n    text = re.sub(r\"\\{.(.*?)\\}\", \"\", text)\n    # Remove a single line `sh` in Markdown\n    text = re.sub(r\"(?m)^sh$\", \"\", text)\n    # Remove a single line ````sh` in Markdown\n    # text = re.sub(r'(?m)^```sh$', '', text)\n    # Remove code snippet tags\n    # text = re.sub(r\"<pre>(.*?)</pre>\", \"\\\\1\", text)\n    # text = re.sub(r\"<code>(.*?)</code>\", \"\\\\1\", text)\n    # Remove variable tags\n    text = re.sub(r\"(?m)<var>(.*?)</var>\", \"\\\\1\", text)\n    text = re.sub(\n        r\"(^|)(Important|Note|Caution|Tip|Warning|Important|Key Point|Key Term):\\s?\",\n        \"\",\n        text,\n    )\n    text = re.sub(\n        r\"(^|)(Objective|Success|Beta|Preview|Deprecated):\\s?\",\n        \"\",\n        text,\n    )\n    text = re.sub(r\"(Project|Book):(.*)\\n\", \"\", text)\n    text = text.strip() + \"\\n\"\n    return text\n\n\n# This function makes a plain text chunk. It can transform markdown headers\n# into plain text for files that can fit in a single chunk or multiple chunks\n# Takes an input of a markdown_text and header_id_spaces on how to treat spaces\n# from Header names to header ids. For example if header_id_spaces=\"-\",\n# ## My section header will get a header id of my-section-header\n# This will try to give more granural context on urls by appending #my-section-header\n# to URL links\ndef make_markdown_chunk(markdown_text, header_id_spaces):\n    section_markdown = \"\"\n    remaining_markdown = \"\"\n    section_title = \"\"\n    section_id = \"\"\n    section_level = \"\"\n    first_header = True\n    section_done = False\n    # Regular expression to read a header level, title, and an optional anchor id\n    regex_headers = r\"^(\\#*)\\s+(.[^\\{]*)(.*?)$\"\n    # Regular expression to read an anchor id, format can be {#header-id} or\n    # {:#header-id}\n    regex_anchors = r\"(?:\\{\\#|\\{:\\#)(.*)\\}\"\n    # Regular expression to read a special RFC title case (with jinja variables)\n    regex_rfc_title = r\"^\\{\\{\\s+(.*)\\.(.*)\\s+\\}\\}$\"\n    # Regular expression to find parantheses as those are not valid in headers\n    regex_section_name = r\"(.[^\\(]*)\"\n    regex_headers_compiled = re.compile(regex_headers)\n    regex_anchors_compiled = re.compile(regex_anchors)\n    regex_section_name_compiled = re.compile(regex_section_name)\n    regex_rfc_compiled = re.compile(regex_rfc_title)\n    for line in markdown_text.split(\"\\n\"):\n        if line.startswith(\"#\") and first_header == True:\n            # Looks for a header in the format of ## Header name {#header-id} or\n            # Just a ## Header name\n            # Level 1 doesn't require header ids as these are page anchors\n            first_header = False\n            match = regex_headers_compiled.search(line)\n            if match:\n                if match[1]:\n                    section_level = len(match[1])\n                if match[2]:\n                    section_title = match[2]\n                    section_id = re.sub(\n                        \" \", header_id_spaces, section_title.lower().strip()\n                    )\n                    section_id = clean_section_id(section_id)\n                    if regex_section_name_compiled.search(section_id):\n                        section_id = regex_section_name_compiled.search(section_id)[1]\n                if match[3]:\n                    match_id = regex_anchors_compiled.search(match[3])\n                    if match_id:\n                        section_id = clean_section_id(match_id[1])\n                    # Checks for the special RFC case to assign a title of RFC\n                    # These headers don't have ids as there is no full header title\n                    match_rfc = regex_rfc_compiled.search(match[2] + match[3])\n                    if match_rfc:\n                        section_title = \"RFC (request for comment)\"\n                # Removing this line as this can be added (if needed) once retrieved from the db\n                # section_markdown += section_intro.format(section_title=section_title)\n        elif len(section_markdown) > 100:\n            # Temp solution: Do not create a chunk if the size is less than 100 chars.\n            if line.startswith(\"#\") and first_header == False:\n                section_done = True\n                remaining_markdown += line + \"\\n\"\n            elif not (line.startswith(\"#\")) and section_done:\n                remaining_markdown += line + \"\\n\"\n            else:\n                section_markdown += line + \"\\n\"\n        else:\n            section_markdown += line + \"\\n\"\n    section_level = level_to_int(section_level)\n    return (\n        section_id,\n        section_level,\n        section_title,\n        section_markdown,\n        remaining_markdown,\n    )\n\n\n# Returns an int of a level to avoid blank string\ndef level_to_int(level) -> int:\n    if level == \"\":\n        level = 0\n    else:\n        level = int(level)\n    return level\n\n\n# In a regular child level the length of the parent_tree should be greater\n# than the current level, so for example a header 2 (level 2) may have a\n# parent_tree of [0, 1], in this case we want to append the previous previous_id\n# Conditions to be aware of:\n# If headers are out of order, you may end up with an array level with\n# the same value, such as a header 4 that ends with a parent_tree of\n# [0, 1, 25, 25] indicates that you jumped from a header 2, right into a 4\ndef build_parent_tree(\n    parent_tree: list[int], level: int, previous_id: int\n) -> list[int]:\n    if len(parent_tree) != level:\n        first = True\n        while len(parent_tree) != level:\n            if len(parent_tree) >= level:\n                parent_tree.pop()\n            elif len(parent_tree) <= level:\n                parent_tree.append(previous_id)\n    return parent_tree\n\n\n# This function cleans section ids from special characters\ndef clean_section_id(section_id: str) -> str:\n    section_id = re.sub(\"'\", \"\", section_id)\n    section_id = re.sub(\"`\", \"\", section_id)\n    section_id = re.sub(r\"\\.\", \"\", section_id)\n    section_id = re.sub(\",\", \"\", section_id)\n    section_id = re.sub(\"#\", \"\", section_id)\n    section_id = re.sub(r\"\\?\", \"\", section_id)\n    section_id = re.sub(r\"\\/\", \"\", section_id)\n    section_id = re.sub(r\"\\{\", \"\", section_id)\n    section_id = re.sub(r\"\\}\", \"\", section_id)\n    section_id = re.sub(\":\", \"\", section_id)\n    return section_id\n\n\n# This function replaces Markdown's includes sections with content.\ndef process_markdown_includes(markdown_text, root):\n    updated_markdown = \"\"\n    for line in markdown_text.split(\"\\n\"):\n        # Replaces Markdown includes with content\n        if line.startswith(\"<<\"):\n            try:\n                include_match = re.search(\"^<<(.*?)>>\", line)\n                include_file = os.path.abspath(root + \"/\" + include_match[1])\n                with open(include_file, \"r\", encoding=\"utf-8\") as md_include:\n                    for md_line in md_include:\n                        updated_markdown += md_line + \"\\n\"\n            except:\n                updated_markdown += line + \"\\n\"\n        else:\n            updated_markdown += line + \"\\n\"\n    return updated_markdown\n\n\n# Function to verify that include exists and exports its content if it exists\ndef verify_file(file):\n    try:\n        with open(file, \"r\", encoding=\"utf-8\") as mdfile:\n            output = mdfile.read()\n            mdfile.close()\n            return output\n    except FileNotFoundError:\n        logging.error(f\"[FileNotFound] Missing the include file: {file}\")\n\n\n# Takes in current section, then returns an array of\n# sections that it split by lines\ndef split_sections_by_lines(section: Section):\n    buffer = []\n    for line in section.content.split(\"\\n\"):\n        # Special case if line is too long - tends to be comma seperated lists\n        if get_byte_size(line) > 5000:\n            for item in line.split(\",\"):\n                item = item + \",\"\n                buffer.append(item)\n        else:\n            buffer.append(line)\n    chunks = construct_chunks(buffer)\n    page_sections = []\n    chunk_count = 0\n    for chunk in chunks:\n        # Calculate tokens for new chunk\n        token_count = tokenCount.returnHighestTokens(chunk)\n        # Section id needs to get bumped up\n        new_section = Section(\n            (section.id + chunk_count),\n            section.name_id,\n            section.page_title,\n            section.section_title,\n            section.level,\n            section.previous_id,\n            section.parent_tree.copy(),\n            token_count,\n            markdown_to_text(chunk),\n        )\n        chunk_count += 1\n        page_sections.append(new_section)\n    return page_sections\n    # return page_sections, remaining_content\n\n\n# This function converts Markdown page (#), section (##), and subsection (###)\n# headings into plain English.\ndef process_markdown_page(markdown_text, header_id_spaces: str = \"_\"):\n    page_metadata = {}\n    remaining_content = markdown_text\n    page_title = \"\"\n    page_sections = []\n    page_url = \"\"\n    # Processes the frontmatter in a markdown file\n    data = frontmatter.loads(markdown_text)\n    if \"title\" in data:\n        page_title = data[\"title\"]\n        remaining_content = data.content\n        page_metadata = data.metadata\n    if \"URL\" in data:\n        page_url = add_scheme_url(url=data[\"URL\"], scheme=\"https\")\n    section_id = 0\n    previous_id = 1\n    parent_level = 0\n    # For each header level the header ID is added, position 0 is header, pos 1 ##, pos 3 ###, etc...\n    parent_tree = [0]\n    while remaining_content != \"\":\n        name_id, level, title, content, remaining_content = make_markdown_chunk(\n            markdown_text=remaining_content, header_id_spaces=header_id_spaces\n        )\n        # Ensure parent_level is an int\n        parent_level = int(parent_level)\n        # Indicates the first encountered header since parent_level and parent_tree have base values\n        if parent_level == 0 and parent_tree == [0] and \"title\" not in data:\n            page_title = title\n        # Builds the parent tree based on current section level and the previous_id\n        parent_tree = build_parent_tree(parent_tree, level, previous_id)\n        plain_text_content = markdown_to_text(content)\n        token_count = tokenCount.returnHighestTokens(plain_text_content)\n        # This goes up as sections start at 1\n        section_id += 1\n        # Initializes a Section, content may be replaced if too large\n        # Copy ensures parent_tree doesn't get overwritten\n        section = Section(\n            section_id,\n            name_id,\n            page_title,\n            title,\n            level,\n            previous_id,\n            parent_tree.copy(),\n            token_count,\n            plain_text_content,\n        )\n        # If content is larger than 5KB - split by lines\n        if len(plain_text_content.encode(\"utf-8\")) > 5000:\n            # Return an array of sections that were split and the remain content\n            logging.info(\"Chunk is too big - splitting by lines\")\n            new_sections = split_sections_by_lines(section=section)\n            # Merge the list of sections and bump up the section_id.\n            # Length has to be reduced by 1 since original chunk was already\n            # counted\n            section_id = section_id + (len(new_sections)-1)\n            page_sections += new_sections\n        # Create a Section object for sections under 6k of the doc.\n        else:\n            # If less than 5kb - append to a list of section objects\n            page_sections.append(section)\n        # Prepare previous_id for next section\n        previous_id = int(section_id)\n        parent_level = int(level)\n    sect_count = len(page_sections)\n    page = Page(page_title, page_url, sect_count, page_metadata)\n    # Return an array of Section objects with a single Page object\n    return page_sections, page\n\n\n# This function converts Markdown page (#), section (##), and subsection (###)\n# headings into plain English.\ndef process_page_and_section_titles(markdown_text):\n    updated_markdown = \"\"\n    page_title = \"\"\n    section_title = \"\"\n    subsection_title = \"\"\n    new_line = \"\"\n    metadata = {}\n    # Processes the frontmatter in a markdown file\n    data = frontmatter.loads(markdown_text)\n    if \"title\" in data:\n        page_title = data[\"title\"]\n        markdown_text = data.content\n        metadata = data.metadata\n    if \"URL\" in data:\n        metadata[\"URL\"] = add_scheme_url(url=data[\"URL\"], scheme=\"https\")\n    for line in markdown_text.split(\"\\n\"):\n        new_line = \"\"\n        skip_this_line = False\n        if line.startswith(\"#\"):\n            match = re.search(r\"^(\\#*)\\s+(.*)$\", line)\n            heading = \"\"\n            captured_title = \"\"\n            if match:\n                heading = match[1]\n                # Remove {: } in devsite Markdown\n                captured_title = re.sub(r\"\\{:(.*?)\\}\", \"\", match[2])\n                # Special case of RFC pages.\n                if re.search(r\"^\\{\\{\\s+(.*)\\.(.*)\\s+\\}\\}$\", captured_title):\n                    heading = \"\"\n                    page_title = \"RFC\"\n                    skip_this_line = True\n\n            # Detect Markdown heading levels\n            if heading == \"#\":\n                page_title = captured_title.strip()\n                metadata[\"title\"] = page_title\n                subsection_title = \"\"\n                section_title = \"\"\n            elif heading == \"##\":\n                section_title = captured_title.strip()\n                subsection_title = \"\"\n            elif heading == \"###\":\n                subsection_title = captured_title.strip()\n\n            # Convert Markdown headings into plain English\n            # (but keep `#` for the `process_document_into_sections()`\n            # function to detect these headings for splitting).\n            if page_title:\n                new_line = (\n                    '# The \"'\n                    + page_title\n                    + '\" page includes the following information:\\n\\n'\n                )\n\n            if section_title:\n                new_line = (\n                    '# The \"'\n                    + page_title\n                    + '\" page has the \"'\n                    + section_title\n                    + '\" section that includes the following information:\\n'\n                )\n\n            if subsection_title:\n                new_line = (\n                    '# On the \"'\n                    + page_title\n                    + '\" page, the \"'\n                    + section_title\n                    + '\" section has the \"'\n                    + subsection_title\n                    + '\" subsection that includes the following information:\\n'\n                )\n\n        if skip_this_line is False:\n            if new_line:\n                updated_markdown += new_line + \"\\n\"\n            else:\n                updated_markdown += line + \"\\n\"\n    return updated_markdown, metadata\n\n\n# This function divides Markdown content into sections and\n# returns an array containing these sections.\n# But this function requires pre-processed Markdown headings from\n# the `process_page_and_section_titles()` function, which simplifies\n# three levels of Markdown headings (#, ##, and ###) into just a single #.\ndef process_document_into_sections(markdown_text):\n    sections = []\n    buffer = []\n    first_section = True\n    for line in markdown_text.split(\"\\n\"):\n        if line.startswith(\"#\"):\n            match = re.search(r\"^(\\#*)\\s+(.*)$\", line)\n            heading = \"\"\n            if match:\n                heading = match[1]\n            if heading == \"#\":\n                if first_section is True:\n                    # Ignore the first detection of `#`.\n                    first_section = False\n                else:\n                    # When a new `#` is detected, store the text in `buffer` into\n                    # an array entry and clear the buffer for the next section.\n                    contents = construct_chunks(buffer)\n                    for content in contents:\n                        sections.append(content)\n                    buffer.clear()\n        buffer.append(line)\n    # Add the last section on the page.\n    contents = construct_chunks(buffer)\n    for content in contents:\n        sections.append(content)\n    return sections\n\n\n# Process an array of Markdwon text into an array of string buffers\n# whose size is smaller than 5KB.\ndef construct_chunks(lines):\n    contents = []\n    buffer_size = get_byte_size(lines)\n    if int(buffer_size) > 5000:\n        # If the protocol is larger than 5KB, divide it into two.\n        logging.info(\n            \"Found a text chunk greater than 5KB (size: \" + str(buffer_size) + \").\"\n        )\n        (first_half, second_half) = divide_an_array(lines)\n        first_content = construct_chunks(first_half)\n        second_content = construct_chunks(second_half)\n        contents += first_content\n        contents += second_content\n    else:\n        chunk = convert_array_to_buffer(lines)\n        contents.append(chunk)\n    return contents\n\n\n# Convert an array into a string buffer.\ndef convert_array_to_buffer(lines):\n    content = \"\"\n    for line in lines:\n        content += line + \"\\n\"\n    return content\n\n\n# Get the byte size of lines.\ndef get_byte_size(lines):\n    buffer_size = 0\n    for line in lines:\n        buffer_size += len(line.encode(\"utf-8\"))\n    return buffer_size\n\n\n# Divide a large array into two arrays.\ndef divide_an_array(lines):\n    half_point = len(lines) // 2\n    first_half = lines[:half_point]\n    second_half = lines[half_point:]\n    return first_half, second_half\n\n\n=== examples/gemini/python/docs-agent/docs_agent/agents/__init__.py ===\n\n",
  "file_count": 54,
  "total_size": 288725
}