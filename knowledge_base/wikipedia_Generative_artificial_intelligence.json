{
  "id": "wikipedia_Generative_artificial_intelligence",
  "title": "Generative artificial intelligence",
  "url": "https://en.wikipedia.org/wiki/Generative_artificial_intelligence",
  "content": "Generative artificial intelligence (Generative AI, GenAI,[1] or GAI) is a subfield of artificial intelligence that uses generative models to produce text, images, videos, or other forms of data.[2][3][4] These models learn the underlying patterns and structures of their training data and use them to produce new data[5][6] based on the input, which often comes in the form of natural language prompts.[7][8]\n\nGenerative AI tools have become more common since the AI boom in the 2020s. This boom was made possible by improvements in transformer-based deep neural networks, particularly large language models (LLMs). Major tools include chatbots such as ChatGPT, Copilot, Gemini, Claude, Grok, and DeepSeek; text-to-image models such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video models such as Veo and Sora.[9][10][11][12][13] Technology companies developing generative AI include OpenAI, xAI, Anthropic, Meta AI, Microsoft, Google, DeepSeek, and Baidu.[7][14][15]\n\nGenerative AI is used across many industries, including software development,[16] healthcare,[17] finance,[18] entertainment,[19] customer service,[20] sales and marketing,[21] art, writing,[22] fashion,[23] and product design.[24] The production of generative AI systems requires large scale data centers using specialized chips which require a lot of electricity for processing and water for cooling.[25]\n\nGenerative AI has raised many ethical questions and governance challenges as it can be used for cybercrime, or to deceive or manipulate people through fake news or deepfakes.[26][27] Even if used ethically, it may lead to mass replacement of human jobs.[28] The tools themselves have been criticized as violating intellectual property laws, since they are trained on copyrighted works.[29]  The material and energy intensity of the AI systems has raised concerns about the environmental impact of AI, especially in light of the challenges created by the energy transition.\n\nThe first example of an algorithmically generated media is likely the Markov chain. Markov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906,[30][31] and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is trained on a text corpus, it can then be used as a probabilistic text generator.[32][33]\n\nComputers were needed to go beyond Markov chains. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.[34]\n\nThe terms generative AI planning or generative planning were used in the 1980s and 1990s to refer to AI planning systems, especially computer-aided process planning, used to generate sequences of actions to reach a specified goal.[35][36] Generative AI planning systems used symbolic AI methods such as state space search and constraint satisfaction and were a \"relatively mature\" technology by the early 1990s. They were used to generate crisis action plans for military use,[37] process plans for manufacturing[35] and decision plans such as in prototype autonomous spacecraft.[38]\n\nSince its inception, the field of machine learning has used both discriminative models and generative models to model and predict data. Beginning in the late 2000s, the emergence of deep learning drove progress, and research in image classification, speech recognition, natural language processing and other tasks. Neural networks in this era were typically trained as discriminative models due to the difficulty of generative modeling.[39]\n\nIn 2014, advancements such as the variational autoencoder and generative adversarial network produced the first practical deep neural networks capable of learning generative models, as opposed to discriminative ones, for complex data such as images. These deep generative models were the first to output not only class labels for images but also entire images.\n\nIn 2017, the Transformer network enabled advancements in generative models compared to older long short-term memory (LSTM) models,[40] leading to the first generative pre-trained transformer (GPT), known as GPT-1, in 2018.[41] This was followed in 2019 by GPT-2, which demonstrated the ability to generalize unsupervised to many different tasks as a Foundation model.[42]\n\nThe new generative models introduced during this period allowed for large neural networks to be trained using unsupervised learning or semi-supervised learning, rather than the supervised learning typical of discriminative models. Unsupervised learning removed the need for humans to manually label data, allowing for larger networks to be trained.[43]\n\nIn March 2020, the release of 15.ai, a free web application created by an anonymous MIT researcher that could generate convincing character voices using minimal training data, marked one of the earliest popular use cases of generative AI.[44] The platform is credited as the first mainstream service to popularize AI voice cloning (audio deepfakes) in memes and content creation, influencing subsequent developments in voice AI technology.[45][46]\n\nIn 2021, the emergence of DALL-E, a transformer-based pixel generative model, marked an advance in AI-generated imagery.[47] This was followed by the releases of Midjourney and Stable Diffusion in 2022, which further democratized access to high-quality artificial intelligence art creation from natural language prompts.[48] These systems demonstrated unprecedented capabilities in generating photorealistic images, artwork, and designs based on text descriptions, leading to widespread adoption among artists, designers, and the general public.\n\nIn late 2022, the public release of ChatGPT revolutionized the accessibility and application of generative AI for general-purpose text-based tasks.[49] The system's ability to engage in natural conversations, generate creative content, assist with coding, and perform various analytical tasks captured global attention and sparked widespread discussion about AI's potential impact on work, education, and creativity.[50][51]\n\nIn March 2023, GPT-4's release represented another jump in generative AI capabilities. A team from Microsoft Research controversially argued that it \"could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system.\"[52] However, this assessment was contested by other scholars who maintained that generative AI remained \"still far from reaching the benchmark of 'general human intelligence'\" as of 2023.[53] Later in 2023, Meta released ImageBind, an AI model combining multiple modalities including text, images, video, thermal data, 3D data, audio, and motion, paving the way for more immersive generative AI applications.[54]\n\nIn December 2023, Google unveiled Gemini, a multimodal AI model available in four versions: Ultra, Pro, Flash, and Nano.[55] The company integrated Gemini Pro into its Bard chatbot and announced plans for \"Bard Advanced\" powered by the larger Gemini Ultra model.[56] In February 2024, Google unified Bard and Duet AI under the Gemini brand, launching a mobile app on Android and integrating the service into the Google app on iOS.[57]\n\nIn March 2024, Anthropic released the Claude 3 family of large language models, including Claude 3 Haiku, Sonnet, and Opus.[58] The models demonstrated significant improvements in capabilities across various benchmarks, with Claude 3 Opus notably outperforming leading models from OpenAI and Google.[59] In June 2024, Anthropic released Claude 3.5 Sonnet, which demonstrated improved performance compared to the larger Claude 3 Opus, particularly in areas such as coding, multistep workflows, and image analysis.[60]\n\nAsiaâ€“Pacific countries are significantly more optimistic than Western societies about generative AI and show higher adoption rates. Despite expressing concerns about privacy and the pace of change, in a 2024 survey, 68% of Asia-Pacific respondents believed that AI was having a positive impact on the world, compared to 57% globally.[61] According to a survey by SAS and Coleman Parkes Research, China in particular has emerged as a global leader in generative AI adoption, with 83% of Chinese respondents using the technology, exceeding both the global average of 54% and the U.S. rate of 65%. This leadership is further evidenced by China's intellectual property developments in the field, with a UN report revealing that Chinese entities filed over 38,000 generative AI patents from 2014 to 2023, substantially surpassing the United States in patent applications.[62] A 2024 survey on the Chinese social app Soul reported that 18% of respondents born after 2000 used generative AI \"almost every day\", and that over 60% of respondents like or love AI-generated content, while less than 3% dislike or hate it.[63]\n\nBy mid 2025, despite continued consumer growth, many companies were increasingly abandoning generative AI pilot projects as they had difficulties with integration, data quality and unmet returns, leading analysts to characterize the period as entering the Gartner hype cycle's \"trough of disillusionment\" phase.[64][65]\n\nNotable types of generative AI models include generative pre-trained transformers (GPTs), generative adversarial networks (GANs), and variational autoencoders (VAEs). Generative AI systems are multimodal if they can process multiple types of inputs or generate multiple types of outputs.[66] For example, GPT-4o can both process and generate text, images and audio.[67]\n\nGenerative AI has made its appearance in a wide variety of industries, radically changing the dynamics of content creation, analysis, and delivery. In healthcare,[68] for instance, generative AI accelerates drug discovery by creating molecular structures with target characteristics[69] and generates radiology images for train...",
  "source_type": "wikipedia_article",
  "domain": "general_knowledge",
  "keywords": [
    "wikipedia",
    "ai",
    "programming",
    "technology",
    "generative artificial intelligence"
  ],
  "retrieval_tags": [
    "wikipedia",
    "article",
    "ai",
    "programming",
    "knowledge"
  ]
}